{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data import random_split\n",
    "import math\n",
    "from torch_geometric.utils import to_dense_adj, add_self_loops\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_verilog_file(file_name):\n",
    "    \n",
    "    ground_truth_labels = [0,1,2,3,4,5,6,7,8,9,10,11,12,13] # no xor , no ALU\n",
    "    labels_torch = torch.tensor(ground_truth_labels)\n",
    "\n",
    "    # One-hot encode the labels\n",
    "    one_hot_labels = F.one_hot(labels_torch, num_classes=14)\n",
    "\n",
    "\n",
    "    label_mapping = {\n",
    "        'adder': 0, 'comparator': 1, 'decoder': 2,\n",
    "        'encoder': 3, 'mult': 4, 'mux': 5, 'pe': 6, 'sub': 7, 'and': 8, 'or': 9, 'not': 10, 'nand': 11, 'nor': 12, 'xnor': 13\n",
    "    }\n",
    "    \n",
    "    pattern = r\"([a-zA-Z]+)(\\d+)?\"\n",
    "    match = re.match(pattern, file_name)\n",
    "    if match:\n",
    "        base_name = match.group(1)\n",
    "        if base_name in label_mapping:\n",
    "            return one_hot_labels[label_mapping[base_name]].tolist()\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label_to_verilog_file(input_file_path, output_folder):\n",
    "    if input_file_path.endswith('.txt'):\n",
    "        with open(input_file_path, \"r\") as file:\n",
    "            loaded_data = json.load(file)\n",
    "            label = label_verilog_file(os.path.basename(input_file_path))\n",
    "            if label is not None and [label] not in loaded_data:  # Check if label already exists\n",
    "                loaded_data.append([label])  # Add label as the third list\n",
    "                output_file_path = os.path.join(output_folder, os.path.basename(input_file_path))\n",
    "                with open(output_file_path, \"w\") as output_file:\n",
    "                    json.dump(loaded_data, output_file)\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_dataset(input_folder, output_folder):\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "    if os.path.isfile(file_path):\n",
    "        if not add_label_to_verilog_file(file_path, output_folder):\n",
    "            print(f\"Failed to label: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracting_attributes(verilog_file):\n",
    "    try:\n",
    "        if os.path.isfile(verilog_file):\n",
    "            with open(verilog_file, \"r\") as file:\n",
    "                \n",
    "                loaded_data = json.load(file)\n",
    "                print(loaded_data)\n",
    "                nodes = loaded_data[0]\n",
    "                edges = loaded_data[1]\n",
    "                label = loaded_data[2]\n",
    "                \n",
    "                x = torch.tensor(nodes, dtype=torch.float)\n",
    "                edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "                y = torch.tensor(label, dtype=torch.float)\n",
    "                num_nodes = x.size(0)\n",
    "                \n",
    "                # Create batch assignment vector (assuming one graph per file)\n",
    "                batch = torch.zeros(num_nodes, dtype=torch.long)\n",
    "                data = Data(x=x, edge_index=edge_index, y = y, batch = batch)\n",
    "                return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_in_folder(input_folder):\n",
    "    file_list = []\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            file_list.append(file_path)\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (gcn1): GCNConv(20, 64)\n",
       "  (r1): ReLU()\n",
       "  (gcn2): GCNConv(64, 64)\n",
       "  (r2): ReLU()\n",
       "  (gcn3): GCNConv(64, 128)\n",
       "  (linear): Linear(in_features=128, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from torch_geometric.nn import GCNConv\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        \n",
    "        num_node_features = 20\n",
    "        num_output_classes = 14\n",
    "        \n",
    "        # num_channels = 32\n",
    "        \n",
    "        self.gcn1 = GCNConv(num_node_features, 64)\n",
    "        self.r1 = nn.ReLU()\n",
    "        self.gcn2 = GCNConv(64, 64)\n",
    "        self.r2 = nn.ReLU()\n",
    "        self.gcn3 = GCNConv(64, 128)\n",
    "        # self.r3 = nn.ReLU()\n",
    "        # self.gcn4 = GCNConv(128, 128)\n",
    "        self.linear = nn.Linear(in_features=128, out_features=num_output_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "    \n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = self.r1(x)\n",
    "        x = self.gcn2(x, edge_index)\n",
    "        x = self.r2(x)\n",
    "        x = self.gcn3(x, edge_index)\n",
    "        # x = self.r3(x)\n",
    "        # x = self.gcn4(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = F.dropout(x, p = 0.4, training=self.training)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        probs = F.log_softmax(x, dim=-1)\n",
    "        \n",
    "        return probs\n",
    "        \n",
    "        \n",
    "        \n",
    "        # KNN\n",
    "        # embeddings\n",
    "        # PCA\n",
    "GCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_test(test_file):\n",
    "    if test_file.endswith('.txt'):\n",
    "        with open(test_file, \"r\") as file:\n",
    "            loaded_data = json.load(file)\n",
    "            label = label_verilog_file(os.path.basename(test_file))\n",
    "            if label is not None and [label] not in loaded_data:  # Check if label already exists\n",
    "                loaded_data.append([label])  # Add label as the third list\n",
    "            return loaded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracting_attributes(verilog_file):\n",
    "    try:\n",
    "                nodes = verilog_file[0]\n",
    "                edges = verilog_file[1]\n",
    "                label = verilog_file[2]\n",
    "                \n",
    "                x = torch.tensor(nodes, dtype=torch.float)\n",
    "                edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "                y = torch.tensor(label, dtype=torch.float)\n",
    "                num_nodes = x.size(0)\n",
    "                \n",
    "                # Create batch assignment vector (assuming one graph per file)\n",
    "                batch = torch.zeros(num_nodes, dtype=torch.long)\n",
    "                data = Data(x=x, edge_index=edge_index, y = y, batch = batch)\n",
    "                return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_infer(pred_label):\n",
    "    label_mapping = {\n",
    "        'adder': 0, 'comparator': 1, 'decoder': 2,\n",
    "        'encoder': 3, 'mult': 4, 'mux': 5, 'pe': 6, 'sub': 7, 'and': 8, 'or': 9, 'not': 10, 'nand': 11, 'nor': 12, 'xnor': 13\n",
    "    }\n",
    "    label = [k for k, v in label_mapping.items() if v == pred_label]\n",
    "    return label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(data):\n",
    "    gcn = GCN()\n",
    "    gcn.load_state_dict(torch.load('gcn_model89-72-0001-200.pth'))\n",
    "    out = gcn(data.x, data.edge_index, data.batch) \n",
    "    pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    pred_label = (pred.tolist())[0]\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbconvert import ScriptExporter\n",
    "\n",
    "def convert_notebook_to_script(notebook_filename, script_filename):\n",
    "    exporter = ScriptExporter()\n",
    "    output, _ = exporter.from_filename(notebook_filename)\n",
    "    with open(script_filename, 'w') as f:\n",
    "        f.write(output)\n",
    "\n",
    "convert_notebook_to_script('GNN_utils.ipynb', 'GNN_utils.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
