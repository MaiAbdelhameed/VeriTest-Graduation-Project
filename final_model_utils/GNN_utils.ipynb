{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data import random_split\n",
    "import math\n",
    "from torch_geometric.utils import to_dense_adj, add_self_loops\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracting_attributes(verilog_file):\n",
    "    try:\n",
    "        if os.path.isfile(verilog_file):\n",
    "            with open(verilog_file, \"r\") as file:\n",
    "                \n",
    "                loaded_data = json.load(file)\n",
    "                print(loaded_data)\n",
    "                nodes = loaded_data[0]\n",
    "                edges = loaded_data[1]\n",
    "                label = loaded_data[2]\n",
    "                \n",
    "                x = torch.tensor(nodes, dtype=torch.float)\n",
    "                edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "                y = torch.tensor(label, dtype=torch.float)\n",
    "                num_nodes = x.size(0)\n",
    "                \n",
    "                # Create batch assignment vector (assuming one graph per file)\n",
    "                batch = torch.zeros(num_nodes, dtype=torch.long)\n",
    "                data = Data(x=x, edge_index=edge_index, y = y, batch = batch)\n",
    "                return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (gcn1): GCNConv(20, 64)\n",
       "  (r1): ReLU()\n",
       "  (gcn2): GCNConv(64, 64)\n",
       "  (r2): ReLU()\n",
       "  (gcn3): GCNConv(64, 128)\n",
       "  (linear): Linear(in_features=128, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from torch_geometric.nn import GCNConv\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        \n",
    "        num_node_features = 20\n",
    "        num_output_classes = 14\n",
    "        \n",
    "        # num_channels = 32\n",
    "        \n",
    "        self.gcn1 = GCNConv(num_node_features, 64)\n",
    "        self.r1 = nn.ReLU()\n",
    "        self.gcn2 = GCNConv(64, 64)\n",
    "        self.r2 = nn.ReLU()\n",
    "        self.gcn3 = GCNConv(64, 128)\n",
    "        # self.r3 = nn.ReLU()\n",
    "        # self.gcn4 = GCNConv(128, 128)\n",
    "        self.linear = nn.Linear(in_features=128, out_features=num_output_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "    \n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = self.r1(x)\n",
    "        x = self.gcn2(x, edge_index)\n",
    "        x = self.r2(x)\n",
    "        x = self.gcn3(x, edge_index)\n",
    "        # x = self.r3(x)\n",
    "        # x = self.gcn4(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = F.dropout(x, p = 0.4, training=self.training)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        probs = F.log_softmax(x, dim=-1)\n",
    "        \n",
    "        return probs\n",
    "        \n",
    "        \n",
    "        \n",
    "        # KNN\n",
    "        # embeddings\n",
    "        # PCA\n",
    "GCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_test(test_file):\n",
    "    if test_file.endswith('.txt'):\n",
    "        with open(test_file, \"r\") as file:\n",
    "            loaded_data = json.load(file)\n",
    "            return loaded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracting_attributes(verilog_file):\n",
    "    try:\n",
    "                nodes = verilog_file[0]\n",
    "                edges = verilog_file[1]\n",
    "                label =  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "                \n",
    "                x = torch.tensor(nodes, dtype=torch.float)\n",
    "                edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "                y = torch.tensor(label, dtype=torch.float)\n",
    "                num_nodes = x.size(0)\n",
    "                \n",
    "                # Create batch assignment vector (assuming one graph per file)\n",
    "                batch = torch.zeros(num_nodes, dtype=torch.long)\n",
    "                data = Data(x=x, edge_index=edge_index, y = y, batch = batch)\n",
    "                return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_infer(pred_label):\n",
    "    label_mapping = {\n",
    "        'adder': 0, 'comparator': 1, 'decoder': 2,\n",
    "        'encoder': 3, 'mult': 4, 'mux': 5, 'pe': 6, 'sub': 7, 'and': 8, 'or': 9, 'not': 10, 'nand': 11, 'nor': 12, 'xnor': 13\n",
    "    }\n",
    "    label = [k for k, v in label_mapping.items() if v == pred_label]\n",
    "    return label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(data):\n",
    "    gcn = GCN()\n",
    "    gcn.load_state_dict(torch.load('gcn_model89-72-0001-200.pth'))\n",
    "    out = gcn(data.x, data.edge_index, data.batch) \n",
    "    pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    pred_label = (pred.tolist())[0]\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbconvert import ScriptExporter\n",
    "\n",
    "def convert_notebook_to_script(notebook_filename, script_filename):\n",
    "    exporter = ScriptExporter()\n",
    "    output, _ = exporter.from_filename(notebook_filename)\n",
    "    with open(script_filename, 'w') as f:\n",
    "        f.write(output)\n",
    "\n",
    "convert_notebook_to_script('GNN_utils.ipynb', 'GNN_utils.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
