{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "%pip install torch_geometric -q\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_verilog_file(file_name):\n",
    "    \n",
    "    ground_truth_labels = [0,1,2,3,4,5,6,7,8,9,10,11,12,13] # no xor , no ALU\n",
    "    labels_torch = torch.tensor(ground_truth_labels)\n",
    "\n",
    "    # One-hot encode the labels\n",
    "    one_hot_labels = F.one_hot(labels_torch, num_classes=14)\n",
    "\n",
    "\n",
    "    label_mapping = {\n",
    "        'adder': 0, 'comparator': 1, 'decoder': 2,\n",
    "        'encoder': 3, 'mult': 4, 'mux': 5, 'pe': 6, 'sub': 7, 'and': 8, 'or': 9, 'not': 10, 'nand': 11, 'nor': 12, 'xnor': 13\n",
    "    }\n",
    "    \n",
    "    pattern = r\"([a-zA-Z]+)(\\d+)?\"\n",
    "    match = re.match(pattern, file_name)\n",
    "    if match:\n",
    "        base_name = match.group(1)\n",
    "        if base_name in label_mapping:\n",
    "            return one_hot_labels[label_mapping[base_name]].tolist()\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label_to_verilog_file(input_file_path, output_folder):\n",
    "    if input_file_path.endswith('.txt'):\n",
    "        with open(input_file_path, \"r\") as file:\n",
    "            loaded_data = json.load(file)\n",
    "            label = label_verilog_file(os.path.basename(input_file_path))\n",
    "            if label is not None and [label] not in loaded_data:  # Check if label already exists\n",
    "                loaded_data.append([label])  # Add label as the third list\n",
    "                output_file_path = os.path.join(output_folder, os.path.basename(input_file_path))\n",
    "                with open(output_file_path, \"w\") as output_file:\n",
    "                    json.dump(loaded_data, output_file)\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_dataset(input_folder, output_folder):\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "    if os.path.isfile(file_path):\n",
    "        if not add_label_to_verilog_file(file_path, output_folder):\n",
    "            print(f\"Failed to label: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracting_attributes(verilog_file):\n",
    "    try:\n",
    "        if os.path.isfile(verilog_file):\n",
    "            with open(verilog_file, \"r\") as file:\n",
    "                \n",
    "                loaded_data = json.load(file)\n",
    "                print(loaded_data)\n",
    "                nodes = loaded_data[0]\n",
    "                edges = loaded_data[1]\n",
    "                label = loaded_data[2]\n",
    "                \n",
    "                x = torch.tensor(nodes, dtype=torch.float)\n",
    "                edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "                y = torch.tensor(label, dtype=torch.float)\n",
    "                num_nodes = x.size(0)\n",
    "                \n",
    "                # Create batch assignment vector (assuming one graph per file)\n",
    "                batch = torch.zeros(num_nodes, dtype=torch.long)\n",
    "                data = Data(x=x, edge_index=edge_index, y = y, batch = batch)\n",
    "                return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_in_folder(input_folder):\n",
    "    file_list = []\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            file_list.append(file_path)\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook preprocessing_utils.ipynb to script\n",
      "[NbConvertApp] Writing 3453 bytes to preprocessing_utils.py\n"
     ]
    }
   ],
   "source": [
    "def create_py():\n",
    "    !jupyter nbconvert --to script preprocessing_utils.ipynb\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    create_py()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
