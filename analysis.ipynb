{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import shutil\n",
    "input_folder = \"encoded_yosys_files\"\n",
    "output_folder = \"done\"\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n",
      "<class 'str'>\n",
      "encoded_yosys_files\\adder10_synth.txt\n"
     ]
    }
   ],
   "source": [
    "# Use list comprehension to create a list of file paths\n",
    "verilog_files = [os.path.join(input_folder, filename) for filename in os.listdir(input_folder) if filename.endswith('.txt')]\n",
    "\n",
    "# Print the list of file paths\n",
    "print(len(verilog_files))\n",
    "print(type(verilog_files[0]))\n",
    "print(verilog_files[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adder 28\n",
      "and 30\n",
      "comparator 22\n",
      "decoder 32\n",
      "encoder 25\n",
      "mult 29\n",
      "mux 27\n",
      "nand 31\n",
      "nor 30\n",
      "not 16\n",
      "or 27\n",
      "pe 21\n",
      "seg 9\n",
      "sub 11\n",
      "xnor 30\n",
      "xor 28\n"
     ]
    }
   ],
   "source": [
    "with open(\"labels_dict.txt\", 'r') as file:\n",
    "    data = file.read()\n",
    "data_dict = json.loads(data)\n",
    "for key, value in data_dict.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes_files_list = []\n",
    "num_edges_files_list = []\n",
    "for file in verilog_files:\n",
    "    with open(file, \"r\") as file:\n",
    "        loaded_data = json.load(file)\n",
    "        num_nodes_files_list.append(len(loaded_data[0]))\n",
    "        num_edges_files_list.append(len(loaded_data[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average_connections = sum(num_connections_list) / len(num_connections_list)\n",
    "# max_connections = max(num_connections_list)\n",
    "# min_connections = min(num_connections_list)\n",
    "\n",
    "# print(\"Average connections: \", average_connections)\n",
    "# print(\"Max connections: \", max_connections)\n",
    "# print(\"Min connections: \", min_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average_size = sum(size_list) / len(size_list)\n",
    "# max_size = max(size_list)\n",
    "# min_size = min(size_list)\n",
    "\n",
    "# print(\"Average node size: \", average_size)\n",
    "# print(\"Max node size: \", max_size)\n",
    "# print(\"Min node size: \", min_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of nodes:  50.686868686868685\n",
      "Max number of nodes:  1731\n",
      "Min number of nodes:  2\n"
     ]
    }
   ],
   "source": [
    "avergae_num_nodes = sum(num_nodes_files_list) / len(num_nodes_files_list)\n",
    "max_num_nodes = max(num_nodes_files_list)\n",
    "min_num_nodes = min(num_nodes_files_list)\n",
    "\n",
    "print(\"Average number of nodes: \", avergae_num_nodes)\n",
    "print(\"Max number of nodes: \", max_num_nodes)\n",
    "print(\"Min number of nodes: \", min_num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of edges:  17.93771626297578\n",
      "Max number of edges:  208\n",
      "Min number of edges:  2\n"
     ]
    }
   ],
   "source": [
    "average_edges = sum(num_edges_files_list) / len(num_edges_files_list)\n",
    "max_edges = max(num_edges_files_list)\n",
    "min_edges = min(num_edges_files_list)\n",
    "\n",
    "print(\"Average number of edges: \", average_edges)\n",
    "print(\"Max number of edges: \", max_edges)\n",
    "print(\"Min number of edges: \", min_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20072"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_nodes = sum(num_nodes_files_list)\n",
    "sum_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dict = dict()\n",
    "for key in data_dict.keys():\n",
    "    num_nodes = 0\n",
    "    num_edges = 0\n",
    "    num_files = 0\n",
    "    # node_sizes = []\n",
    "    for file_path in verilog_files:\n",
    "        st = file_path.split(\"\\\\\")[1].split(\".\")[0]\n",
    "        # print(st)\n",
    "        pattern = f\"^({key})\\d+\"\n",
    "        # print(pattern)\n",
    "        if re.match(pattern, st):\n",
    "            # print(\"hi\")\n",
    "            num_files += 1\n",
    "            with open(file_path, \"r\") as file:\n",
    "                loaded_data = json.load(file)\n",
    "                num_nodes += len(loaded_data[0])\n",
    "                num_edges += len(loaded_data[1][0])\n",
    "                # for sublist in loaded_data[0]:\n",
    "                #     node_sizes.append(sublist[3])\n",
    "                \n",
    "    files_dict[key] = {\n",
    "        \"num_nodes\": num_nodes,\n",
    "        \"num_edges\": num_edges,\n",
    "        \"average_nodes\": round(num_nodes / num_files,2),\n",
    "        \"average_edges\": round(num_edges / num_files,2),\n",
    "        \"num_files\": num_files,\n",
    "        \"percentage_nodes\" : round(num_nodes / sum_nodes * 100,2),\n",
    "        \"percentage_edges\" : round(num_edges / sum(num_edges_files_list) * 1000,2),\n",
    "        \"percentage_files\" : round(num_files / len(verilog_files) * 100,2)\n",
    "    }\n",
    "# files_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes_sizes_dict = dict()\n",
    "# for key in data_dict.keys():\n",
    "#     node_sizes = []\n",
    "#     node_connections = []\n",
    "#     for file_path in verilog_files:\n",
    "#         st = file_path.split(\"\\\\\")[1].split(\".\")[0]\n",
    "#         pattern = f\"^({key})\\d+\"\n",
    "#         if re.match(pattern, st):\n",
    "#             with open(file_path, \"r\") as file:\n",
    "#                 loaded_data = json.load(file)\n",
    "#                 for sublist in loaded_data[0]:\n",
    "#                     node_sizes.append(sublist[3])\n",
    "#                     node_connections.append(sublist[2])\n",
    "                \n",
    "#     nodes_sizes_dict[key] = {\n",
    "#         \"node connections list\": str(node_connections),\n",
    "#         \"node size list\" : str(node_sizes)\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = input  output  reg  wire  operation  no_op  add  and  or  xor  xnor  nor  nand  not  case  concat  conditional  constVal  mult  mux  power  shift  subtr  \n",
    "# index         0       1     2    3     4          5    6    7    8   9    10    11    12    13   14    15        16         17       18     19    20    21    22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done\\\\adder10_synth.txt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_files = [os.path.join(output_folder, filename) for filename in os.listdir(input_folder) if filename.endswith('.txt')]\n",
    "encoded_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_files_info = dict()\n",
    "input_count = 0\n",
    "output_count = 0\n",
    "reg_count = 0\n",
    "wire_count = 0\n",
    "subtr_count = 0\n",
    "shift_count = 0\n",
    "power_count = 0\n",
    "mux_count = 0\n",
    "mult_count = 0\n",
    "constVal_count = 0\n",
    "conditional_count = 0\n",
    "concat_count = 0\n",
    "case_count = 0\n",
    "not_count = 0\n",
    "nand_count = 0\n",
    "nor_count = 0\n",
    "xnor_count = 0\n",
    "xor_count = 0\n",
    "or_count = 0\n",
    "and_count = 0\n",
    "add_count = 0\n",
    "for key in data_dict.keys():\n",
    "    key_dict = dict()\n",
    "    for file_path in encoded_files:\n",
    "        st = file_path.split(\"\\\\\")[1].split(\".\")[0]\n",
    "        pattern = f\"^({key})\\d+\"\n",
    "        if re.match(pattern, st):\n",
    "            with open(file_path, \"r\") as file:\n",
    "                loaded_data = json.load(file)\n",
    "                for sublist in loaded_data[0]:\n",
    "                    # print(sublist)\n",
    "                    # break\n",
    "                    if sublist[0]: # input\n",
    "                        key_dict[\"input\"] = key_dict.get(\"input\", 0) + 1\n",
    "                        input_count +=1\n",
    "                        \n",
    "                    elif sublist[1]: #output\n",
    "                        key_dict[\"output\"] = key_dict.get(\"output\", 0) + 1\n",
    "                        output_count += 1\n",
    "                        \n",
    "                    elif sublist[2]: #reg\n",
    "                        key_dict[\"reg\"] = key_dict.get(\"reg\", 0) + 1\n",
    "                        reg_count +=1\n",
    "                        \n",
    "                    elif sublist[3]: #wire\n",
    "                        key_dict[\"wire\"] = key_dict.get(\"wire\", 0) + 1\n",
    "                        wire_count +=1\n",
    "                        \n",
    "                    elif sublist[4]:\n",
    "                        key_dict[\"subtr\"] = key_dict.get(\"subtr\", 0) + 1\n",
    "                        subtr_count += 1\n",
    "                        \n",
    "                    elif sublist[5]:\n",
    "                        key_dict[\"shift\"] = key_dict.get(\"shift\", 0) + 1\n",
    "                        shift_count +=1\n",
    "                        \n",
    "                    elif sublist[6]:\n",
    "                        key_dict[\"mux\"] = key_dict.get(\"mux\", 0) + 1\n",
    "                        mux_count+=1\n",
    "                        \n",
    "                    elif sublist[7]:\n",
    "                        key_dict[\"mult\"] = key_dict.get(\"mult\", 0) + 1\n",
    "                        mult_count+=1\n",
    "                        \n",
    "                    elif sublist[8]:\n",
    "                        key_dict[\"constVal\"] = key_dict.get(\"constVal\", 0) + 1\n",
    "                        constVal_count+=1\n",
    "                        \n",
    "                    elif sublist[9]:\n",
    "                        key_dict[\"conditional\"] = key_dict.get(\"conditional\", 0) + 1\n",
    "                        conditional_count+=1\n",
    "                        \n",
    "                    elif sublist[10]:\n",
    "                        key_dict[\"concat\"] = key_dict.get(\"concat\", 0) + 1\n",
    "                        concat_count +=1\n",
    "                        \n",
    "                    elif sublist[11]:\n",
    "                        key_dict[\"case\"] = key_dict.get(\"case\", 0) + 1\n",
    "                        case_count+=1\n",
    "                        \n",
    "                    elif sublist[12]:\n",
    "                        key_dict[\"not\"] = key_dict.get(\"not\", 0) + 1\n",
    "                        not_count+=1\n",
    "                        \n",
    "                    elif sublist[13]:\n",
    "                        key_dict[\"nand\"] = key_dict.get(\"nand\", 0) + 1\n",
    "                        nand_count+=1\n",
    "                        \n",
    "                    elif sublist[14]:\n",
    "                        key_dict[\"nor\"] = key_dict.get(\"nor\", 0) + 1\n",
    "                        nor_count+=1\n",
    "                        \n",
    "                    elif sublist[15]:\n",
    "                        key_dict[\"xnor\"] = key_dict.get(\"xnor\", 0) + 1\n",
    "                        xnor_count+=1\n",
    "                        \n",
    "                    elif sublist[16]:\n",
    "                        key_dict[\"xor\"] = key_dict.get(\"xor\", 0) + 1\n",
    "                        xor_count+=1\n",
    "                        \n",
    "                    elif sublist[17]:\n",
    "                        key_dict[\"or\"] = key_dict.get(\"or\", 0) + 1\n",
    "                        or_count+=1\n",
    "                        \n",
    "                    elif sublist[18]:\n",
    "                        key_dict[\"and\"] = key_dict.get(\"and\", 0) + 1\n",
    "                        and_count+=1\n",
    "                        \n",
    "                    elif sublist[19]:\n",
    "                        key_dict[\"add\"] = key_dict.get(\"add\", 0) + 1\n",
    "                        add_count+=1\n",
    "                        \n",
    "                    else: \n",
    "                        print(\"eh el habal da\")\n",
    "                        \n",
    "    nodes_files_info[key] = key_dict\n",
    "                \n",
    "    \n",
    "# files_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Nodes Count =  649\n",
      "Output Nodes Count =  394\n",
      "Reg Nodes Count =  58\n",
      "Wire Nodes Count =  96\n",
      "\n",
      "Subtr Nodes Count =  0\n",
      "Shift Nodes Count =  17\n",
      "Power Nodes Count =  0\n",
      "Mux Nodes Count =  262\n",
      "Mult Nodes Count =  7\n",
      "ConstVal Nodes Count =  984\n",
      "Conditional Nodes Count =  322\n",
      "Concat Nodes Count =  64\n",
      "Case Nodes Count =  69\n",
      "Not Nodes Count =  253\n",
      "Nand Nodes Count =  9\n",
      "Nor Nodes Count =  4\n",
      "Xnor Nodes Count =  6\n",
      "Xor Nodes Count =  133\n",
      "Or Nodes Count =  282\n",
      "And Nodes Count =  635\n",
      "Add Nodes Count =  16\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Nodes Count = \", input_count)\n",
    "print(\"Output Nodes Count = \", output_count)\n",
    "print(\"Reg Nodes Count = \", reg_count)\n",
    "print(\"Wire Nodes Count = \", wire_count)\n",
    "print()\n",
    "print(\"Subtr Nodes Count = \", subtr_count)\n",
    "print(\"Shift Nodes Count = \", shift_count)\n",
    "print(\"Power Nodes Count = \", power_count)\n",
    "print(\"Mux Nodes Count = \", mux_count)\n",
    "print(\"Mult Nodes Count = \", mult_count)\n",
    "print(\"ConstVal Nodes Count = \", constVal_count)\n",
    "print(\"Conditional Nodes Count = \", conditional_count)\n",
    "print(\"Concat Nodes Count = \", concat_count)\n",
    "print(\"Case Nodes Count = \", case_count)\n",
    "print(\"Not Nodes Count = \", not_count)\n",
    "print(\"Nand Nodes Count = \", nand_count)\n",
    "print(\"Nor Nodes Count = \", nor_count)\n",
    "print(\"Xnor Nodes Count = \", xnor_count)\n",
    "print(\"Xor Nodes Count = \", xor_count)\n",
    "print(\"Or Nodes Count = \", or_count)\n",
    "print(\"And Nodes Count = \", and_count)\n",
    "print(\"Add Nodes Count = \", add_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write global statistics to file\n",
    "with open(\"global_statistics.txt\", \"w\") as file:\n",
    "    # file.write(\"Average connections: \" + str(average_connections) + \"\\n\")\n",
    "    # file.write(\"Max connections: \" + str(max_connections) + \"\\n\")\n",
    "    # file.write(\"Min connections: \" + str(min_connections) + \"\\n\")\n",
    "    # file.write(\"Average node size: \" + str(average_size) + \"\\n\")\n",
    "    # file.write(\"Max node size: \" + str(max_size) + \"\\n\")\n",
    "    # file.write(\"Min node size: \" + str(min_size) + \"\\n\")\n",
    "    file.write(\"Average number of nodes: \" + str(avergae_num_nodes) + \"\\n\")\n",
    "    file.write(\"Max number of nodes: \" + str(max_num_nodes) + \"\\n\")\n",
    "    file.write(\"Min number of nodes: \" + str(min_num_nodes) + \"\\n\")\n",
    "    file.write(\"Average number of edges: \" + str(average_edges) + \"\\n\")\n",
    "    file.write(\"Max number of edges: \" + str(max_edges) + \"\\n\")\n",
    "    file.write(\"Min number of edges: \" + str(min_edges) + \"\\n\")\n",
    "    file.write(\"Sum number of nodes: \" + str(sum_nodes) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"files_global_statistics.txt\", \"w\") as file:\n",
    "    file.write(json.dumps(files_dict, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"files_sizes_connections.txt\", \"w\") as file:\n",
    "#     file.write(json.dumps(nodes_sizes_dict, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"global_dataset_nodes_info.txt\", \"w\") as file:\n",
    "    file.write(\"Input = \" + str(input_count) + \"\\n\")\n",
    "    file.write(\"Output = \" + str(output_count) + \"\\n\")\n",
    "    file.write(\"Reg = \" + str(reg_count) + \"\\n\")\n",
    "    file.write(\"Wire = \" + str(wire_count) + \"\\n\")\n",
    "    file.write(\"\\n\")\n",
    "    file.write(\"Subtr = \" + str(subtr_count) + \"\\n\")\n",
    "    file.write(\"Shift = \" + str(shift_count) + \"\\n\")\n",
    "    file.write(\"Power = \" + str(power_count) + \"\\n\")\n",
    "    file.write(\"Mux  = \" + str(mux_count) + \"\\n\")\n",
    "    file.write(\"Mult = \" + str(mult_count) + \"\\n\")\n",
    "    file.write(\"ConstVal = \" + str(constVal_count) + \"\\n\")\n",
    "    file.write(\"Conditional = \" + str(conditional_count) + \"\\n\")\n",
    "    file.write(\"Concat = \" + str(concat_count) + \"\\n\")\n",
    "    file.write(\"Case = \" + str(case_count) + \"\\n\")\n",
    "    file.write(\"Not = \" + str(not_count) + \"\\n\")\n",
    "    file.write(\"Nand = \" + str(nand_count) + \"\\n\")\n",
    "    file.write(\"Nor = \" + str(nor_count) + \"\\n\")\n",
    "    file.write(\"Xnor = \" + str(xnor_count) + \"\\n\")\n",
    "    file.write(\"Xor = \" + str(xor_count) + \"\\n\")\n",
    "    file.write(\"Or = \" + str(or_count) + \"\\n\")\n",
    "    file.write(\"Add = \" + str(add_count) + \"\\n\")\n",
    "    file.write(\"And = \" + str(and_count) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"classes_nodes_info.txt\", \"w\") as file:\n",
    "    file.write(json.dumps(nodes_files_info, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes\n",
    "# remove power\n",
    "# remove operation and no operation encoder\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
