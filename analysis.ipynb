{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import shutil\n",
    "input_folder = \"encoded\"\n",
    "output_folder = \"done\"\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n",
      "<class 'str'>\n",
      "encoded\\adder11.txt\n"
     ]
    }
   ],
   "source": [
    "# Use list comprehension to create a list of file paths\n",
    "verilog_files = [os.path.join(input_folder, filename) for filename in os.listdir(input_folder) if filename.endswith('.txt')]\n",
    "\n",
    "# Print the list of file paths\n",
    "print(len(verilog_files))\n",
    "print(type(verilog_files[0]))\n",
    "print(verilog_files[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adder 14\n",
      "ALU 9\n",
      "and 25\n",
      "comparator 24\n",
      "decoder 26\n",
      "encoder 23\n",
      "mult 24\n",
      "mux 26\n",
      "nand 20\n",
      "nor 16\n",
      "not 11\n",
      "or 24\n",
      "pe 16\n",
      "sub 9\n",
      "xnor 23\n"
     ]
    }
   ],
   "source": [
    "with open(\"labels_dict.txt\", 'r') as file:\n",
    "    data = file.read()\n",
    "data_dict = json.loads(data)\n",
    "for key, value in data_dict.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded\\ALU10.txt\n",
      "encoded\\ALU13.txt\n",
      "encoded\\decoder30.txt\n",
      "encoded\\encoder16.txt\n",
      "encoded\\encoder18.txt\n",
      "encoded\\encoder6.txt\n",
      "encoded\\pe14.txt\n",
      "encoded\\pe15.txt\n",
      "encoded\\pe16.txt\n",
      "encoded\\pe22.txt\n",
      "encoded\\pe7.txt\n"
     ]
    }
   ],
   "source": [
    "num_connections_list = []\n",
    "size_list = []\n",
    "num_nodes_files_list = []\n",
    "num_edges_files_list = []\n",
    "for file in verilog_files:\n",
    "    with open(file, \"r\") as file:\n",
    "        loaded_data = json.load(file)\n",
    "        num_nodes_files_list.append(len(loaded_data[0]))\n",
    "        num_edges_files_list.append(len(loaded_data[1][0]))\n",
    "        for sublist in loaded_data[0]:\n",
    "            if sublist[2] == 0:\n",
    "                print(file.name)\n",
    "                continue\n",
    "            num_connections_list.append(sublist[2])\n",
    "            size_list.append(sublist[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average connections:  2.506062685884237\n",
      "Max connections:  34\n",
      "Min connections:  1\n"
     ]
    }
   ],
   "source": [
    "average_connections = sum(num_connections_list) / len(num_connections_list)\n",
    "max_connections = max(num_connections_list)\n",
    "min_connections = min(num_connections_list)\n",
    "\n",
    "print(\"Average connections: \", average_connections)\n",
    "print(\"Max connections: \", max_connections)\n",
    "print(\"Min connections: \", min_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average node size:  2.578586135895676\n",
      "Max node size:  32\n",
      "Min node size:  1\n"
     ]
    }
   ],
   "source": [
    "average_size = sum(size_list) / len(size_list)\n",
    "max_size = max(size_list)\n",
    "min_size = min(size_list)\n",
    "\n",
    "print(\"Average node size: \", average_size)\n",
    "print(\"Max node size: \", max_size)\n",
    "print(\"Min node size: \", min_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of nodes:  15.110344827586207\n",
      "Max number of nodes:  165\n",
      "Min number of nodes:  3\n"
     ]
    }
   ],
   "source": [
    "avergae_num_nodes = sum(num_nodes_files_list) / len(num_nodes_files_list)\n",
    "max_num_nodes = max(num_nodes_files_list)\n",
    "min_num_nodes = min(num_nodes_files_list)\n",
    "\n",
    "print(\"Average number of nodes: \", avergae_num_nodes)\n",
    "print(\"Max number of nodes: \", max_num_nodes)\n",
    "print(\"Min number of nodes: \", min_num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of edges:  18.575862068965517\n",
      "Max number of edges:  208\n",
      "Min number of edges:  2\n"
     ]
    }
   ],
   "source": [
    "average_edges = sum(num_edges_files_list) / len(num_edges_files_list)\n",
    "max_edges = max(num_edges_files_list)\n",
    "min_edges = min(num_edges_files_list)\n",
    "\n",
    "print(\"Average number of edges: \", average_edges)\n",
    "print(\"Max number of edges: \", max_edges)\n",
    "print(\"Min number of edges: \", min_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4382"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_nodes = sum(num_nodes_files_list)\n",
    "sum_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dict = dict()\n",
    "for key in data_dict.keys():\n",
    "    num_nodes = 0\n",
    "    num_edges = 0\n",
    "    num_files = 0\n",
    "    # node_sizes = []\n",
    "    for file_path in verilog_files:\n",
    "        st = file_path.split(\"\\\\\")[1].split(\".\")[0]\n",
    "        # print(st)\n",
    "        pattern = f\"^({key})\\d+\"\n",
    "        # print(pattern)\n",
    "        if re.match(pattern, st):\n",
    "            # print(\"hi\")\n",
    "            num_files += 1\n",
    "            with open(file_path, \"r\") as file:\n",
    "                loaded_data = json.load(file)\n",
    "                num_nodes += len(loaded_data[0])\n",
    "                num_edges += len(loaded_data[1][0])\n",
    "                # for sublist in loaded_data[0]:\n",
    "                #     node_sizes.append(sublist[3])\n",
    "                \n",
    "    files_dict[key] = {\n",
    "        \"num_nodes\": num_nodes,\n",
    "        \"num_edges\": num_edges,\n",
    "        \"average_nodes\": round(num_nodes / num_files,2),\n",
    "        \"average_edges\": round(num_edges / num_files,2),\n",
    "        \"num_files\": num_files,\n",
    "        \"percentage_nodes\" : round(num_nodes / sum_nodes * 100,2),\n",
    "        \"percentage_edges\" : round(num_edges / sum(num_edges_files_list) * 1000,2),\n",
    "        \"percentage_files\" : round(num_files / len(verilog_files) * 100,2)\n",
    "    }\n",
    "# files_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_sizes_dict = dict()\n",
    "for key in data_dict.keys():\n",
    "    node_sizes = []\n",
    "    node_connections = []\n",
    "    for file_path in verilog_files:\n",
    "        st = file_path.split(\"\\\\\")[1].split(\".\")[0]\n",
    "        pattern = f\"^({key})\\d+\"\n",
    "        if re.match(pattern, st):\n",
    "            with open(file_path, \"r\") as file:\n",
    "                loaded_data = json.load(file)\n",
    "                for sublist in loaded_data[0]:\n",
    "                    node_sizes.append(sublist[3])\n",
    "                    node_connections.append(sublist[2])\n",
    "                \n",
    "    nodes_sizes_dict[key] = {\n",
    "        \"node connections list\": str(node_connections),\n",
    "        \"node size list\" : str(node_sizes)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = input  output  reg  wire  operation  no_op  add  and  or  xor  xnor  nor  nand  not  case  concat  conditional  constVal  mult  mux  power  shift  subtr  \n",
    "# index         0       1     2    3     4          5    6    7    8   9    10    11    12    13   14    15        16         17       18     19    20    21    22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['done\\\\adder11.txt',\n",
       " 'done\\\\adder12.txt',\n",
       " 'done\\\\adder13.txt',\n",
       " 'done\\\\adder14.txt',\n",
       " 'done\\\\adder15.txt',\n",
       " 'done\\\\adder16.txt',\n",
       " 'done\\\\adder17.txt',\n",
       " 'done\\\\adder18.txt',\n",
       " 'done\\\\adder19.txt',\n",
       " 'done\\\\adder2.txt',\n",
       " 'done\\\\adder20.txt',\n",
       " 'done\\\\adder5.txt',\n",
       " 'done\\\\adder6.txt',\n",
       " 'done\\\\adder8.txt',\n",
       " 'done\\\\ALU10.txt',\n",
       " 'done\\\\ALU13.txt',\n",
       " 'done\\\\ALU14.txt',\n",
       " 'done\\\\ALU15.txt',\n",
       " 'done\\\\ALU2.txt',\n",
       " 'done\\\\ALU6.txt',\n",
       " 'done\\\\ALU7.txt',\n",
       " 'done\\\\ALU8.txt',\n",
       " 'done\\\\ALU9.txt',\n",
       " 'done\\\\and1.txt',\n",
       " 'done\\\\and10.txt',\n",
       " 'done\\\\and12.txt',\n",
       " 'done\\\\and13.txt',\n",
       " 'done\\\\and14.txt',\n",
       " 'done\\\\and15.txt',\n",
       " 'done\\\\and16.txt',\n",
       " 'done\\\\and17.txt',\n",
       " 'done\\\\and18.txt',\n",
       " 'done\\\\and19.txt',\n",
       " 'done\\\\and2.txt',\n",
       " 'done\\\\and20.txt',\n",
       " 'done\\\\and21.txt',\n",
       " 'done\\\\and23.txt',\n",
       " 'done\\\\and25.txt',\n",
       " 'done\\\\and26.txt',\n",
       " 'done\\\\and27.txt',\n",
       " 'done\\\\and28.txt',\n",
       " 'done\\\\and29.txt',\n",
       " 'done\\\\and3.txt',\n",
       " 'done\\\\and30.txt',\n",
       " 'done\\\\and6.txt',\n",
       " 'done\\\\and7.txt',\n",
       " 'done\\\\and8.txt',\n",
       " 'done\\\\and9.txt',\n",
       " 'done\\\\comparator1.txt',\n",
       " 'done\\\\comparator13.txt',\n",
       " 'done\\\\comparator14.txt',\n",
       " 'done\\\\comparator15.txt',\n",
       " 'done\\\\comparator16.txt',\n",
       " 'done\\\\comparator17.txt',\n",
       " 'done\\\\comparator18.txt',\n",
       " 'done\\\\comparator19.txt',\n",
       " 'done\\\\comparator2.txt',\n",
       " 'done\\\\comparator20.txt',\n",
       " 'done\\\\comparator21.txt',\n",
       " 'done\\\\comparator22.txt',\n",
       " 'done\\\\comparator23.txt',\n",
       " 'done\\\\comparator24.txt',\n",
       " 'done\\\\comparator25.txt',\n",
       " 'done\\\\comparator26.txt',\n",
       " 'done\\\\comparator27.txt',\n",
       " 'done\\\\comparator28.txt',\n",
       " 'done\\\\comparator29.txt',\n",
       " 'done\\\\comparator30.txt',\n",
       " 'done\\\\comparator6.txt',\n",
       " 'done\\\\comparator7.txt',\n",
       " 'done\\\\comparator8.txt',\n",
       " 'done\\\\comparator9.txt',\n",
       " 'done\\\\decoder1.txt',\n",
       " 'done\\\\decoder11.txt',\n",
       " 'done\\\\decoder12.txt',\n",
       " 'done\\\\decoder13.txt',\n",
       " 'done\\\\decoder14.txt',\n",
       " 'done\\\\decoder15.txt',\n",
       " 'done\\\\decoder16.txt',\n",
       " 'done\\\\decoder17.txt',\n",
       " 'done\\\\decoder18.txt',\n",
       " 'done\\\\decoder19.txt',\n",
       " 'done\\\\decoder2.txt',\n",
       " 'done\\\\decoder20.txt',\n",
       " 'done\\\\decoder21.txt',\n",
       " 'done\\\\decoder22.txt',\n",
       " 'done\\\\decoder23.txt',\n",
       " 'done\\\\decoder24.txt',\n",
       " 'done\\\\decoder25.txt',\n",
       " 'done\\\\decoder26.txt',\n",
       " 'done\\\\decoder27.txt',\n",
       " 'done\\\\decoder28.txt',\n",
       " 'done\\\\decoder29.txt',\n",
       " 'done\\\\decoder3.txt',\n",
       " 'done\\\\decoder30.txt',\n",
       " 'done\\\\decoder31.txt',\n",
       " 'done\\\\decoder32.txt',\n",
       " 'done\\\\decoder4.txt',\n",
       " 'done\\\\encoder1.txt',\n",
       " 'done\\\\encoder10.txt',\n",
       " 'done\\\\encoder11.txt',\n",
       " 'done\\\\encoder12.txt',\n",
       " 'done\\\\encoder13.txt',\n",
       " 'done\\\\encoder14.txt',\n",
       " 'done\\\\encoder15.txt',\n",
       " 'done\\\\encoder16.txt',\n",
       " 'done\\\\encoder17.txt',\n",
       " 'done\\\\encoder18.txt',\n",
       " 'done\\\\encoder19.txt',\n",
       " 'done\\\\encoder2.txt',\n",
       " 'done\\\\encoder20.txt',\n",
       " 'done\\\\encoder21.txt',\n",
       " 'done\\\\encoder24.txt',\n",
       " 'done\\\\encoder25.txt',\n",
       " 'done\\\\encoder3.txt',\n",
       " 'done\\\\encoder4.txt',\n",
       " 'done\\\\encoder5.txt',\n",
       " 'done\\\\encoder6.txt',\n",
       " 'done\\\\encoder7.txt',\n",
       " 'done\\\\encoder8.txt',\n",
       " 'done\\\\encoder9.txt',\n",
       " 'done\\\\mult1.txt',\n",
       " 'done\\\\mult10.txt',\n",
       " 'done\\\\mult11.txt',\n",
       " 'done\\\\mult12.txt',\n",
       " 'done\\\\mult13.txt',\n",
       " 'done\\\\mult14.txt',\n",
       " 'done\\\\mult15.txt',\n",
       " 'done\\\\mult16.txt',\n",
       " 'done\\\\mult17.txt',\n",
       " 'done\\\\mult18.txt',\n",
       " 'done\\\\mult19.txt',\n",
       " 'done\\\\mult2.txt',\n",
       " 'done\\\\mult3.txt',\n",
       " 'done\\\\mult30.txt',\n",
       " 'done\\\\mult31.txt',\n",
       " 'done\\\\mult32.txt',\n",
       " 'done\\\\mult33.txt',\n",
       " 'done\\\\mult34.txt',\n",
       " 'done\\\\mult35.txt',\n",
       " 'done\\\\mult4.txt',\n",
       " 'done\\\\mult5.txt',\n",
       " 'done\\\\mult6.txt',\n",
       " 'done\\\\mult8.txt',\n",
       " 'done\\\\mult9.txt',\n",
       " 'done\\\\mux1.txt',\n",
       " 'done\\\\mux10.txt',\n",
       " 'done\\\\mux11.txt',\n",
       " 'done\\\\mux12.txt',\n",
       " 'done\\\\mux13.txt',\n",
       " 'done\\\\mux14.txt',\n",
       " 'done\\\\mux15.txt',\n",
       " 'done\\\\mux16.txt',\n",
       " 'done\\\\mux17.txt',\n",
       " 'done\\\\mux18.txt',\n",
       " 'done\\\\mux19.txt',\n",
       " 'done\\\\mux2.txt',\n",
       " 'done\\\\mux20.txt',\n",
       " 'done\\\\mux21.txt',\n",
       " 'done\\\\mux22.txt',\n",
       " 'done\\\\mux23.txt',\n",
       " 'done\\\\mux24.txt',\n",
       " 'done\\\\mux25.txt',\n",
       " 'done\\\\mux26.txt',\n",
       " 'done\\\\mux3.txt',\n",
       " 'done\\\\mux4.txt',\n",
       " 'done\\\\mux5.txt',\n",
       " 'done\\\\mux6.txt',\n",
       " 'done\\\\mux7.txt',\n",
       " 'done\\\\mux8.txt',\n",
       " 'done\\\\mux9.txt',\n",
       " 'done\\\\nand1.txt',\n",
       " 'done\\\\nand10.txt',\n",
       " 'done\\\\nand11.txt',\n",
       " 'done\\\\nand12.txt',\n",
       " 'done\\\\nand14.txt',\n",
       " 'done\\\\nand15.txt',\n",
       " 'done\\\\nand16.txt',\n",
       " 'done\\\\nand17.txt',\n",
       " 'done\\\\nand18.txt',\n",
       " 'done\\\\nand19.txt',\n",
       " 'done\\\\nand2.txt',\n",
       " 'done\\\\nand20.txt',\n",
       " 'done\\\\nand21.txt',\n",
       " 'done\\\\nand22.txt',\n",
       " 'done\\\\nand3.txt',\n",
       " 'done\\\\nand4.txt',\n",
       " 'done\\\\nand6.txt',\n",
       " 'done\\\\nand7.txt',\n",
       " 'done\\\\nand8.txt',\n",
       " 'done\\\\nand9.txt',\n",
       " 'done\\\\nor1.txt',\n",
       " 'done\\\\nor10.txt',\n",
       " 'done\\\\nor11.txt',\n",
       " 'done\\\\nor12.txt',\n",
       " 'done\\\\nor13.txt',\n",
       " 'done\\\\nor14.txt',\n",
       " 'done\\\\nor15.txt',\n",
       " 'done\\\\nor16.txt',\n",
       " 'done\\\\nor17.txt',\n",
       " 'done\\\\nor2.txt',\n",
       " 'done\\\\nor3.txt',\n",
       " 'done\\\\nor4.txt',\n",
       " 'done\\\\nor6.txt',\n",
       " 'done\\\\nor7.txt',\n",
       " 'done\\\\nor8.txt',\n",
       " 'done\\\\nor9.txt',\n",
       " 'done\\\\not1.txt',\n",
       " 'done\\\\not10.txt',\n",
       " 'done\\\\not11.txt',\n",
       " 'done\\\\not12.txt',\n",
       " 'done\\\\not13.txt',\n",
       " 'done\\\\not14.txt',\n",
       " 'done\\\\not2.txt',\n",
       " 'done\\\\not3.txt',\n",
       " 'done\\\\not6.txt',\n",
       " 'done\\\\not7.txt',\n",
       " 'done\\\\not9.txt',\n",
       " 'done\\\\or1.txt',\n",
       " 'done\\\\or10.txt',\n",
       " 'done\\\\or11.txt',\n",
       " 'done\\\\or12.txt',\n",
       " 'done\\\\or13.txt',\n",
       " 'done\\\\or14.txt',\n",
       " 'done\\\\or15.txt',\n",
       " 'done\\\\or16.txt',\n",
       " 'done\\\\or17.txt',\n",
       " 'done\\\\or18.txt',\n",
       " 'done\\\\or19.txt',\n",
       " 'done\\\\or2.txt',\n",
       " 'done\\\\or20.txt',\n",
       " 'done\\\\or21.txt',\n",
       " 'done\\\\or22.txt',\n",
       " 'done\\\\or23.txt',\n",
       " 'done\\\\or24.txt',\n",
       " 'done\\\\or25.txt',\n",
       " 'done\\\\or26.txt',\n",
       " 'done\\\\or28.txt',\n",
       " 'done\\\\or4.txt',\n",
       " 'done\\\\or7.txt',\n",
       " 'done\\\\or8.txt',\n",
       " 'done\\\\or9.txt',\n",
       " 'done\\\\pe1.txt',\n",
       " 'done\\\\pe14.txt',\n",
       " 'done\\\\pe15.txt',\n",
       " 'done\\\\pe16.txt',\n",
       " 'done\\\\pe17.txt',\n",
       " 'done\\\\pe18.txt',\n",
       " 'done\\\\pe19.txt',\n",
       " 'done\\\\pe2.txt',\n",
       " 'done\\\\pe20.txt',\n",
       " 'done\\\\pe21.txt',\n",
       " 'done\\\\pe22.txt',\n",
       " 'done\\\\pe3.txt',\n",
       " 'done\\\\pe4.txt',\n",
       " 'done\\\\pe5.txt',\n",
       " 'done\\\\pe6.txt',\n",
       " 'done\\\\pe7.txt',\n",
       " 'done\\\\sub1.txt',\n",
       " 'done\\\\sub10.txt',\n",
       " 'done\\\\sub11.txt',\n",
       " 'done\\\\sub12.txt',\n",
       " 'done\\\\sub2.txt',\n",
       " 'done\\\\sub5.txt',\n",
       " 'done\\\\sub7.txt',\n",
       " 'done\\\\sub8.txt',\n",
       " 'done\\\\sub9.txt',\n",
       " 'done\\\\xnor1.txt',\n",
       " 'done\\\\xnor10.txt',\n",
       " 'done\\\\xnor11.txt',\n",
       " 'done\\\\xnor12.txt',\n",
       " 'done\\\\xnor13.txt',\n",
       " 'done\\\\xnor14.txt',\n",
       " 'done\\\\xnor15.txt',\n",
       " 'done\\\\xnor16.txt',\n",
       " 'done\\\\xnor17.txt',\n",
       " 'done\\\\xnor18.txt',\n",
       " 'done\\\\xnor19.txt',\n",
       " 'done\\\\xnor2.txt',\n",
       " 'done\\\\xnor20.txt',\n",
       " 'done\\\\xnor21.txt',\n",
       " 'done\\\\xnor22.txt',\n",
       " 'done\\\\xnor23.txt',\n",
       " 'done\\\\xnor24.txt',\n",
       " 'done\\\\xnor25.txt',\n",
       " 'done\\\\xnor4.txt',\n",
       " 'done\\\\xnor6.txt',\n",
       " 'done\\\\xnor7.txt',\n",
       " 'done\\\\xnor8.txt',\n",
       " 'done\\\\xnor9.txt']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_files = [os.path.join(output_folder, filename) for filename in os.listdir(input_folder) if filename.endswith('.txt')]\n",
    "encoded_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_files_info = dict()\n",
    "input_count = 0\n",
    "output_count = 0\n",
    "reg_count = 0\n",
    "wire_count = 0\n",
    "subtr_count = 0\n",
    "shift_count = 0\n",
    "power_count = 0\n",
    "mux_count = 0\n",
    "mult_count = 0\n",
    "constVal_count = 0\n",
    "conditional_count = 0\n",
    "concat_count = 0\n",
    "case_count = 0\n",
    "not_count = 0\n",
    "nand_count = 0\n",
    "nor_count = 0\n",
    "xnor_count = 0\n",
    "xor_count = 0\n",
    "or_count = 0\n",
    "and_count = 0\n",
    "add_count = 0\n",
    "for key in data_dict.keys():\n",
    "    key_dict = dict()\n",
    "    for file_path in encoded_files:\n",
    "        st = file_path.split(\"\\\\\")[1].split(\".\")[0]\n",
    "        pattern = f\"^({key})\\d+\"\n",
    "        if re.match(pattern, st):\n",
    "            with open(file_path, \"r\") as file:\n",
    "                loaded_data = json.load(file)\n",
    "                for sublist in loaded_data[0]:\n",
    "                    # print(sublist)\n",
    "                    # break\n",
    "                    if sublist[0]: # input\n",
    "                        key_dict[\"input\"] = key_dict.get(\"input\", 0) + 1\n",
    "                        input_count +=1\n",
    "                        \n",
    "                    elif sublist[1]: #output\n",
    "                        key_dict[\"output\"] = key_dict.get(\"output\", 0) + 1\n",
    "                        output_count += 1\n",
    "                        \n",
    "                    elif sublist[2]: #reg\n",
    "                        key_dict[\"reg\"] = key_dict.get(\"reg\", 0) + 1\n",
    "                        reg_count +=1\n",
    "                        \n",
    "                    elif sublist[3]: #wire\n",
    "                        key_dict[\"wire\"] = key_dict.get(\"wire\", 0) + 1\n",
    "                        wire_count +=1\n",
    "                        \n",
    "                    elif sublist[4]: #operation\n",
    "                        # key_dict[\"operation\"] = key_dict.get(\"operation\", 0) + 1\n",
    "                        if sublist[5]:\n",
    "                            key_dict[\"subtr\"] = key_dict.get(\"subtr\", 0) + 1\n",
    "                            subtr_count += 1\n",
    "                            \n",
    "                        elif sublist[6]:\n",
    "                            key_dict[\"shift\"] = key_dict.get(\"shift\", 0) + 1\n",
    "                            shift_count +=1\n",
    "                            \n",
    "                        elif sublist[7]:\n",
    "                            key_dict[\"power\"] = key_dict.get(\"power\", 0) + 1\n",
    "                            power_count+=1\n",
    "                            \n",
    "                        elif sublist[8]:\n",
    "                            key_dict[\"mux\"] = key_dict.get(\"mux\", 0) + 1\n",
    "                            mux_count+=1\n",
    "                            \n",
    "                        elif sublist[9]:\n",
    "                            key_dict[\"mult\"] = key_dict.get(\"mult\", 0) + 1\n",
    "                            mult_count+=1\n",
    "                            \n",
    "                        elif sublist[10]:\n",
    "                            key_dict[\"constVal\"] = key_dict.get(\"constVal\", 0) + 1\n",
    "                            constVal_count+=1\n",
    "                            \n",
    "                        elif sublist[11]:\n",
    "                            key_dict[\"conditional\"] = key_dict.get(\"conditional\", 0) + 1\n",
    "                            conditional_count+=1\n",
    "                            \n",
    "                        elif sublist[12]:\n",
    "                            key_dict[\"concat\"] = key_dict.get(\"concat\", 0) + 1\n",
    "                            concat_count +=1\n",
    "                            \n",
    "                        elif sublist[13]:\n",
    "                            key_dict[\"case\"] = key_dict.get(\"case\", 0) + 1\n",
    "                            case_count+=1\n",
    "                            \n",
    "                        elif sublist[14]:\n",
    "                            key_dict[\"not\"] = key_dict.get(\"not\", 0) + 1\n",
    "                            not_count+=1\n",
    "                            \n",
    "                        elif sublist[15]:\n",
    "                            key_dict[\"nand\"] = key_dict.get(\"nand\", 0) + 1\n",
    "                            nand_count+=1\n",
    "                            \n",
    "                        elif sublist[16]:\n",
    "                            key_dict[\"nor\"] = key_dict.get(\"nor\", 0) + 1\n",
    "                            nor_count+=1\n",
    "                            \n",
    "                        elif sublist[17]:\n",
    "                            key_dict[\"xnor\"] = key_dict.get(\"xnor\", 0) + 1\n",
    "                            xnor_count+=1\n",
    "                            \n",
    "                        elif sublist[18]:\n",
    "                            key_dict[\"xor\"] = key_dict.get(\"xor\", 0) + 1\n",
    "                            xor_count+=1\n",
    "                            \n",
    "                        elif sublist[19]:\n",
    "                            key_dict[\"or\"] = key_dict.get(\"or\", 0) + 1\n",
    "                            or_count+=1\n",
    "                            \n",
    "                        elif sublist[20]:\n",
    "                            key_dict[\"and\"] = key_dict.get(\"and\", 0) + 1\n",
    "                            and_count+=1\n",
    "                            \n",
    "                        elif sublist[21]:\n",
    "                            key_dict[\"add\"] = key_dict.get(\"add\", 0) + 1\n",
    "                            add_count+=1\n",
    "                            \n",
    "                        else: \n",
    "                            print(\"eh el habal da\")\n",
    "                            \n",
    "    nodes_files_info[key] = key_dict\n",
    "                \n",
    "    \n",
    "# files_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Nodes Count =  660\n",
      "Output Nodes Count =  387\n",
      "Reg Nodes Count =  59\n",
      "Wire Nodes Count =  72\n",
      "\n",
      "Subtr Nodes Count =  8\n",
      "Shift Nodes Count =  27\n",
      "Power Nodes Count =  0\n",
      "Mux Nodes Count =  301\n",
      "Mult Nodes Count =  7\n",
      "ConstVal Nodes Count =  1025\n",
      "Conditional Nodes Count =  364\n",
      "Concat Nodes Count =  64\n",
      "Case Nodes Count =  72\n",
      "Not Nodes Count =  251\n",
      "Nand Nodes Count =  9\n",
      "Nor Nodes Count =  3\n",
      "Xnor Nodes Count =  6\n",
      "Xor Nodes Count =  131\n",
      "Or Nodes Count =  279\n",
      "And Nodes Count =  623\n",
      "Add Nodes Count =  23\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Nodes Count = \", input_count)\n",
    "print(\"Output Nodes Count = \", output_count)\n",
    "print(\"Reg Nodes Count = \", reg_count)\n",
    "print(\"Wire Nodes Count = \", wire_count)\n",
    "print()\n",
    "print(\"Subtr Nodes Count = \", subtr_count)\n",
    "print(\"Shift Nodes Count = \", shift_count)\n",
    "print(\"Power Nodes Count = \", power_count)\n",
    "print(\"Mux Nodes Count = \", mux_count)\n",
    "print(\"Mult Nodes Count = \", mult_count)\n",
    "print(\"ConstVal Nodes Count = \", constVal_count)\n",
    "print(\"Conditional Nodes Count = \", conditional_count)\n",
    "print(\"Concat Nodes Count = \", concat_count)\n",
    "print(\"Case Nodes Count = \", case_count)\n",
    "print(\"Not Nodes Count = \", not_count)\n",
    "print(\"Nand Nodes Count = \", nand_count)\n",
    "print(\"Nor Nodes Count = \", nor_count)\n",
    "print(\"Xnor Nodes Count = \", xnor_count)\n",
    "print(\"Xor Nodes Count = \", xor_count)\n",
    "print(\"Or Nodes Count = \", or_count)\n",
    "print(\"And Nodes Count = \", and_count)\n",
    "print(\"Add Nodes Count = \", add_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write global statistics to file\n",
    "with open(\"global_statistics.txt\", \"w\") as file:\n",
    "    file.write(\"Average connections: \" + str(average_connections) + \"\\n\")\n",
    "    file.write(\"Max connections: \" + str(max_connections) + \"\\n\")\n",
    "    file.write(\"Min connections: \" + str(min_connections) + \"\\n\")\n",
    "    file.write(\"Average node size: \" + str(average_size) + \"\\n\")\n",
    "    file.write(\"Max node size: \" + str(max_size) + \"\\n\")\n",
    "    file.write(\"Min node size: \" + str(min_size) + \"\\n\")\n",
    "    file.write(\"Average number of nodes: \" + str(avergae_num_nodes) + \"\\n\")\n",
    "    file.write(\"Max number of nodes: \" + str(max_num_nodes) + \"\\n\")\n",
    "    file.write(\"Min number of nodes: \" + str(min_num_nodes) + \"\\n\")\n",
    "    file.write(\"Average number of edges: \" + str(average_edges) + \"\\n\")\n",
    "    file.write(\"Max number of edges: \" + str(max_edges) + \"\\n\")\n",
    "    file.write(\"Min number of edges: \" + str(min_edges) + \"\\n\")\n",
    "    file.write(\"Sum number of nodes: \" + str(sum_nodes) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"files_global_statistics.txt\", \"w\") as file:\n",
    "    file.write(json.dumps(files_dict, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"files_sizes_connections.txt\", \"w\") as file:\n",
    "    file.write(json.dumps(nodes_sizes_dict, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"global_dataset_nodes_info.txt\", \"w\") as file:\n",
    "    file.write(\"Input Nodes Count = \" + str(input_count) + \"\\n\")\n",
    "    file.write(\"Output Nodes Count = \" + str(output_count) + \"\\n\")\n",
    "    file.write(\"Reg Nodes Count = \" + str(reg_count) + \"\\n\")\n",
    "    file.write(\"Wire Nodes Count = \" + str(wire_count) + \"\\n\")\n",
    "    file.write(\"\\n\")\n",
    "    file.write(\"Subtr Nodes Count = \" + str(subtr_count) + \"\\n\")\n",
    "    file.write(\"Shift Nodes Count = \" + str(shift_count) + \"\\n\")\n",
    "    file.write(\"Power Nodes Count = \" + str(power_count) + \"\\n\")\n",
    "    file.write(\"Mux Nodes Count = \" + str(mux_count) + \"\\n\")\n",
    "    file.write(\"Mult Nodes Count = \" + str(mult_count) + \"\\n\")\n",
    "    file.write(\"ConstVal Nodes Count = \" + str(constVal_count) + \"\\n\")\n",
    "    file.write(\"Conditional Nodes Count = \" + str(conditional_count) + \"\\n\")\n",
    "    file.write(\"Concat Nodes Count = \" + str(concat_count) + \"\\n\")\n",
    "    file.write(\"Case Nodes Count = \" + str(case_count) + \"\\n\")\n",
    "    file.write(\"Not Nodes Count = \" + str(not_count) + \"\\n\")\n",
    "    file.write(\"Nand Nodes Count = \" + str(nand_count) + \"\\n\")\n",
    "    file.write(\"Nor Nodes Count = \" + str(nor_count) + \"\\n\")\n",
    "    file.write(\"Xnor Nodes Count = \" + str(xnor_count) + \"\\n\")\n",
    "    file.write(\"Xor Nodes Count = \" + str(xor_count) + \"\\n\")\n",
    "    file.write(\"Or Nodes Count = \" + str(or_count) + \"\\n\")\n",
    "    file.write(\"And Nodes Count = \" + str(and_count) + \"\\n\")\n",
    "    file.write(\"Add Nodes Count = \" + str(add_count) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"classes_nodes_info.txt\", \"w\") as file:\n",
    "    file.write(json.dumps(nodes_files_info, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes\n",
    "# remove power\n",
    "# remove operation and no operation encoder\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
