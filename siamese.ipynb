{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in c:\\users\\mai\\appdata\\roaming\\python\\python39\\site-packages (2.5.2)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\mai\\appdata\\roaming\\python\\python39\\site-packages (from torch_geometric) (3.0.9)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch_geometric) (2022.2.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch_geometric) (1.0.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch_geometric) (4.64.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch_geometric) (1.22.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch_geometric) (2.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch_geometric) (2.27.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\mai\\appdata\\roaming\\python\\python39\\site-packages (from torch_geometric) (5.9.3)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch_geometric) (3.8.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch_geometric) (1.7.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (4.0.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (5.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (1.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from async-timeout<5.0,>=4.0.0a3->aiohttp->torch_geometric) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp->torch_geometric) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from jinja2->torch_geometric) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (1.26.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from scikit-learn->torch_geometric) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from scikit-learn->torch_geometric) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mai\\appdata\\roaming\\python\\python39\\site-packages (from tqdm->torch_geometric) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "%pip install torch_geometric\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import os\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import warnings\n",
    "import math\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n",
      "['done_all\\\\adder10_synth.txt', 'done_all\\\\adder11_synth.txt', 'done_all\\\\adder12_synth.txt', 'done_all\\\\adder13_synth.txt', 'done_all\\\\adder14_synth.txt', 'done_all\\\\adder15_synth.txt', 'done_all\\\\adder16_synth.txt', 'done_all\\\\adder17_synth.txt', 'done_all\\\\adder18_synth.txt', 'done_all\\\\adder19_synth.txt', 'done_all\\\\adder1_synth.txt', 'done_all\\\\adder20_synth.txt', 'done_all\\\\adder21_synth.txt', 'done_all\\\\adder22_synth.txt', 'done_all\\\\adder23_synth.txt', 'done_all\\\\adder24_synth.txt', 'done_all\\\\adder25_synth.txt', 'done_all\\\\adder26_synth.txt', 'done_all\\\\adder27_synth.txt', 'done_all\\\\adder28_synth.txt', 'done_all\\\\adder2_synth.txt', 'done_all\\\\adder3_synth.txt', 'done_all\\\\adder4_synth.txt', 'done_all\\\\adder5_synth.txt', 'done_all\\\\adder6_synth.txt', 'done_all\\\\adder7_synth.txt', 'done_all\\\\adder8_synth.txt', 'done_all\\\\adder9_synth.txt', 'done_all\\\\and10_gate_synth.txt', 'done_all\\\\and11_gate_synth.txt', 'done_all\\\\and12_gate_synth.txt', 'done_all\\\\and13_synth.txt', 'done_all\\\\and14_synth.txt', 'done_all\\\\and15_synth.txt', 'done_all\\\\and16_synth.txt', 'done_all\\\\and17_synth.txt', 'done_all\\\\and18_gate_synth.txt', 'done_all\\\\and19_synth.txt', 'done_all\\\\and1_synth.txt', 'done_all\\\\and20_synth.txt', 'done_all\\\\and21_synth.txt', 'done_all\\\\and22_synth.txt', 'done_all\\\\and23_synth.txt', 'done_all\\\\and24_synth.txt', 'done_all\\\\and25_synth.txt', 'done_all\\\\and26_synth.txt', 'done_all\\\\and27_synth.txt', 'done_all\\\\and28_synth.txt', 'done_all\\\\and29_synth.txt', 'done_all\\\\and2_gate_synth.txt', 'done_all\\\\and30_synth.txt', 'done_all\\\\and3_gate_synth.txt', 'done_all\\\\and4_gate_synth.txt', 'done_all\\\\and5_gate_synth.txt', 'done_all\\\\and6_gate_synth.txt', 'done_all\\\\and7_gate_synth.txt', 'done_all\\\\and8_gate_synth.txt', 'done_all\\\\and9_gate_synth.txt', 'done_all\\\\comparator10_synth.txt', 'done_all\\\\comparator11_synth.txt', 'done_all\\\\comparator12_synth.txt', 'done_all\\\\comparator13_synth.txt', 'done_all\\\\comparator14_synth.txt', 'done_all\\\\comparator15_synth.txt', 'done_all\\\\comparator16_synth.txt', 'done_all\\\\comparator17_synth.txt', 'done_all\\\\comparator18_synth.txt', 'done_all\\\\comparator19_synth.txt', 'done_all\\\\comparator1_synth.txt', 'done_all\\\\comparator20_synth.txt', 'done_all\\\\comparator21_synth.txt', 'done_all\\\\comparator22_synth.txt', 'done_all\\\\comparator2_synth.txt', 'done_all\\\\comparator3_synth.txt', 'done_all\\\\comparator4_synth.txt', 'done_all\\\\comparator5_synth.txt', 'done_all\\\\comparator6_synth.txt', 'done_all\\\\comparator7_synth.txt', 'done_all\\\\comparator8_synth.txt', 'done_all\\\\comparator9_synth.txt', 'done_all\\\\decoder10_synth.txt', 'done_all\\\\decoder11_synth.txt', 'done_all\\\\decoder12_synth.txt', 'done_all\\\\decoder13_synth.txt', 'done_all\\\\decoder14_synth.txt', 'done_all\\\\decoder15_synth.txt', 'done_all\\\\decoder16_synth.txt', 'done_all\\\\decoder17_synth.txt', 'done_all\\\\decoder18_synth.txt', 'done_all\\\\decoder19_synth.txt', 'done_all\\\\decoder1_synth.txt', 'done_all\\\\decoder20_synth.txt', 'done_all\\\\decoder21_synth.txt', 'done_all\\\\decoder22_synth.txt', 'done_all\\\\decoder23_synth.txt', 'done_all\\\\decoder24_synth.txt', 'done_all\\\\decoder25_synth.txt', 'done_all\\\\decoder26_synth.txt', 'done_all\\\\decoder27_synth.txt', 'done_all\\\\decoder28_synth.txt', 'done_all\\\\decoder29_synth.txt', 'done_all\\\\decoder2_synth.txt', 'done_all\\\\decoder30_synth.txt', 'done_all\\\\decoder31_synth.txt', 'done_all\\\\decoder32_synth.txt', 'done_all\\\\decoder3_synth.txt', 'done_all\\\\decoder4_synth.txt', 'done_all\\\\decoder5_synth.txt', 'done_all\\\\decoder6_synth.txt', 'done_all\\\\decoder7_synth.txt', 'done_all\\\\decoder8_synth.txt', 'done_all\\\\decoder9_synth.txt', 'done_all\\\\encoder10_synth.txt', 'done_all\\\\encoder11_synth.txt', 'done_all\\\\encoder12_synth.txt', 'done_all\\\\encoder13_synth.txt', 'done_all\\\\encoder14_synth.txt', 'done_all\\\\encoder15_synth.txt', 'done_all\\\\encoder16_synth.txt', 'done_all\\\\encoder17_synth.txt', 'done_all\\\\encoder18_synth.txt', 'done_all\\\\encoder19_synth.txt', 'done_all\\\\encoder1_synth.txt', 'done_all\\\\encoder20_synth.txt', 'done_all\\\\encoder21_synth.txt', 'done_all\\\\encoder22_synth.txt', 'done_all\\\\encoder23_synth.txt', 'done_all\\\\encoder24_synth.txt', 'done_all\\\\encoder25_synth.txt', 'done_all\\\\encoder2_synth.txt', 'done_all\\\\encoder3_synth.txt', 'done_all\\\\encoder4_synth.txt', 'done_all\\\\encoder5_synth.txt', 'done_all\\\\encoder6_synth.txt', 'done_all\\\\encoder7_synth.txt', 'done_all\\\\encoder8_synth.txt', 'done_all\\\\encoder9_synth.txt', 'done_all\\\\mult10_synth.txt', 'done_all\\\\mult11_synth.txt', 'done_all\\\\mult12_synth.txt', 'done_all\\\\mult13_synth.txt', 'done_all\\\\mult14_synth.txt', 'done_all\\\\mult15_synth.txt', 'done_all\\\\mult16_synth.txt', 'done_all\\\\mult17_synth.txt', 'done_all\\\\mult18_synth.txt', 'done_all\\\\mult19_synth.txt', 'done_all\\\\mult1_synth.txt', 'done_all\\\\mult20_synth.txt', 'done_all\\\\mult21_synth.txt', 'done_all\\\\mult22_synth.txt', 'done_all\\\\mult23_synth.txt', 'done_all\\\\mult25_synth.txt', 'done_all\\\\mult26_synth.txt', 'done_all\\\\mult27_synth.txt', 'done_all\\\\mult28_synth.txt', 'done_all\\\\mult29_synth.txt', 'done_all\\\\mult2_synth.txt', 'done_all\\\\mult30_synth.txt', 'done_all\\\\mult3_synth.txt', 'done_all\\\\mult4_synth.txt', 'done_all\\\\mult5_synth.txt', 'done_all\\\\mult6_synth.txt', 'done_all\\\\mult7_synth.txt', 'done_all\\\\mult8_synth.txt', 'done_all\\\\mult9_synth.txt', 'done_all\\\\mux10_synth.txt', 'done_all\\\\mux11_synth.txt', 'done_all\\\\mux12_synth.txt', 'done_all\\\\mux13_synth.txt', 'done_all\\\\mux15_synth.txt', 'done_all\\\\mux16_synth.txt', 'done_all\\\\mux17_synth.txt', 'done_all\\\\mux18_synth.txt', 'done_all\\\\mux19_synth.txt', 'done_all\\\\mux1_synth.txt', 'done_all\\\\mux20_synth.txt', 'done_all\\\\mux21_synth.txt', 'done_all\\\\mux22_synth.txt', 'done_all\\\\mux23_synth.txt', 'done_all\\\\mux24_synth.txt', 'done_all\\\\mux25_synth.txt', 'done_all\\\\mux26_synth.txt', 'done_all\\\\mux27_synth.txt', 'done_all\\\\mux28_synth.txt', 'done_all\\\\mux2_synth.txt', 'done_all\\\\mux3_synth.txt', 'done_all\\\\mux4_synth.txt', 'done_all\\\\mux5_synth.txt', 'done_all\\\\mux6_synth.txt', 'done_all\\\\mux7_synth.txt', 'done_all\\\\mux8_synth.txt', 'done_all\\\\mux9_synth.txt', 'done_all\\\\nand10_synth.txt', 'done_all\\\\nand11_synth.txt', 'done_all\\\\nand12_gate_synth.txt', 'done_all\\\\nand13_synth.txt', 'done_all\\\\nand14_synth.txt', 'done_all\\\\nand15_synth.txt', 'done_all\\\\nand16_synth.txt', 'done_all\\\\nand17_synth.txt', 'done_all\\\\nand18_synth.txt', 'done_all\\\\nand19_synth.txt', 'done_all\\\\nand1_synth.txt', 'done_all\\\\nand20_gate_synth.txt', 'done_all\\\\nand21_synth.txt', 'done_all\\\\nand22_synth.txt', 'done_all\\\\nand23_synth.txt', 'done_all\\\\nand24_synth.txt', 'done_all\\\\nand25_synth.txt', 'done_all\\\\nand26_synth.txt', 'done_all\\\\nand27_synth.txt', 'done_all\\\\nand28_synth.txt', 'done_all\\\\nand29_synth.txt', 'done_all\\\\nand2_gate_synth.txt', 'done_all\\\\nand30_synth.txt', 'done_all\\\\nand31_synth.txt', 'done_all\\\\nand3_gate_synth.txt', 'done_all\\\\nand4_gate_synth.txt', 'done_all\\\\nand5_gate_synth.txt', 'done_all\\\\nand6_gate_synth.txt', 'done_all\\\\nand7_gate_synth.txt', 'done_all\\\\nand8_gate_synth.txt', 'done_all\\\\nand9_gate_synth.txt', 'done_all\\\\nor10_synth.txt', 'done_all\\\\nor11_synth.txt', 'done_all\\\\nor12_gate_synth.txt', 'done_all\\\\nor13_synth.txt', 'done_all\\\\nor14_synth.txt', 'done_all\\\\nor15_synth.txt', 'done_all\\\\nor16_synth.txt', 'done_all\\\\nor17_synth.txt', 'done_all\\\\nor18_synth.txt', 'done_all\\\\nor19_synth.txt', 'done_all\\\\nor1_synth.txt', 'done_all\\\\nor20_synth.txt', 'done_all\\\\nor21_synth.txt', 'done_all\\\\nor22_synth.txt', 'done_all\\\\nor23_synth.txt', 'done_all\\\\nor24_synth.txt', 'done_all\\\\nor25_synth.txt', 'done_all\\\\nor26_synth.txt', 'done_all\\\\nor27_gate_synth.txt', 'done_all\\\\nor28_synth.txt', 'done_all\\\\nor29_synth.txt', 'done_all\\\\nor2_gate_synth.txt', 'done_all\\\\nor30_synth.txt', 'done_all\\\\nor3_gate_synth.txt', 'done_all\\\\nor4_gate_synth.txt', 'done_all\\\\nor5_gate_synth.txt', 'done_all\\\\nor6_gate_synth.txt', 'done_all\\\\nor7_synth.txt', 'done_all\\\\nor8_gate_synth.txt', 'done_all\\\\nor9_synth.txt', 'done_all\\\\not10_synth.txt', 'done_all\\\\not11_synth.txt', 'done_all\\\\not12_synth.txt', 'done_all\\\\not13_synth.txt', 'done_all\\\\not14_synth.txt', 'done_all\\\\not15_synth.txt', 'done_all\\\\not16_synth.txt', 'done_all\\\\not1_synth.txt', 'done_all\\\\not2_synth.txt', 'done_all\\\\not3_synth.txt', 'done_all\\\\not4_synth.txt', 'done_all\\\\not5_synth.txt', 'done_all\\\\not6_synth.txt', 'done_all\\\\not7_synth.txt', 'done_all\\\\not8_synth.txt', 'done_all\\\\not9_synth.txt', 'done_all\\\\or11_synth.txt', 'done_all\\\\or13_synth.txt', 'done_all\\\\or14_synth.txt', 'done_all\\\\or15_synth.txt', 'done_all\\\\or16_synth.txt', 'done_all\\\\or17_gate_synth.txt', 'done_all\\\\or18_synth.txt', 'done_all\\\\or19_synth.txt', 'done_all\\\\or1_synth.txt', 'done_all\\\\or20_synth.txt', 'done_all\\\\or21_synth.txt', 'done_all\\\\or22_synth.txt', 'done_all\\\\or23_synth.txt', 'done_all\\\\or24_synth.txt', 'done_all\\\\or25_synth.txt', 'done_all\\\\or26_synth.txt', 'done_all\\\\or27_synth.txt', 'done_all\\\\or28_synth.txt', 'done_all\\\\or29_synth.txt', 'done_all\\\\or2_gate_synth.txt', 'done_all\\\\or3_gate_synth.txt', 'done_all\\\\or4_gate_synth.txt', 'done_all\\\\or5_gate_synth.txt', 'done_all\\\\or6_gate_synth.txt', 'done_all\\\\or7_synth.txt', 'done_all\\\\or8_gate_synth.txt', 'done_all\\\\or9_synth.txt', 'done_all\\\\pe10_synth.txt', 'done_all\\\\pe11_synth.txt', 'done_all\\\\pe12_synth.txt', 'done_all\\\\pe13_synth.txt', 'done_all\\\\pe14_synth.txt', 'done_all\\\\pe15_synth.txt', 'done_all\\\\pe16_synth.txt', 'done_all\\\\pe17_synth.txt', 'done_all\\\\pe18_synth.txt', 'done_all\\\\pe19_synth.txt', 'done_all\\\\pe1_synth.txt', 'done_all\\\\pe20_synth.txt', 'done_all\\\\pe21_synth.txt', 'done_all\\\\pe22_synth.txt', 'done_all\\\\pe2_synth.txt', 'done_all\\\\pe3_synth.txt', 'done_all\\\\pe4_synth.txt', 'done_all\\\\pe5_synth.txt', 'done_all\\\\pe6_synth.txt', 'done_all\\\\pe8_synth.txt', 'done_all\\\\pe9_synth.txt', 'done_all\\\\seg1_synth.txt', 'done_all\\\\seg2_synth.txt', 'done_all\\\\seg3_synth.txt', 'done_all\\\\seg4_synth.txt', 'done_all\\\\seg5_synth.txt', 'done_all\\\\seg6_synth.txt', 'done_all\\\\seg7_synth.txt', 'done_all\\\\seg8_synth.txt', 'done_all\\\\seg9_synth.txt', 'done_all\\\\sub10_synth.txt', 'done_all\\\\sub11_synth.txt', 'done_all\\\\sub12_synth.txt', 'done_all\\\\sub1_synth.txt', 'done_all\\\\sub2_synth.txt', 'done_all\\\\sub4_synth.txt', 'done_all\\\\sub5_synth.txt', 'done_all\\\\sub6_synth.txt', 'done_all\\\\sub7_synth.txt', 'done_all\\\\sub8_synth.txt', 'done_all\\\\sub9_synth.txt', 'done_all\\\\xnor10_synth.txt', 'done_all\\\\xnor11_synth.txt', 'done_all\\\\xnor12_synth.txt', 'done_all\\\\xnor13_synth.txt', 'done_all\\\\xnor14_synth.txt', 'done_all\\\\xnor15_synth.txt', 'done_all\\\\xnor16_synth.txt', 'done_all\\\\xnor17_synth.txt', 'done_all\\\\xnor18_synth.txt', 'done_all\\\\xnor19_synth.txt', 'done_all\\\\xnor1_synth.txt', 'done_all\\\\xnor20_synth.txt', 'done_all\\\\xnor21_synth.txt', 'done_all\\\\xnor22_synth.txt', 'done_all\\\\xnor23_synth.txt', 'done_all\\\\xnor24_synth.txt', 'done_all\\\\xnor25_synth.txt', 'done_all\\\\xnor26_synth.txt', 'done_all\\\\xnor27_synth.txt', 'done_all\\\\xnor28_synth.txt', 'done_all\\\\xnor29_synth.txt', 'done_all\\\\xnor2_synth.txt', 'done_all\\\\xnor30_synth.txt', 'done_all\\\\xnor3_synth.txt', 'done_all\\\\xnor4_synth.txt', 'done_all\\\\xnor5_synth.txt', 'done_all\\\\xnor6_synth.txt', 'done_all\\\\xnor7_synth.txt', 'done_all\\\\xnor8_synth.txt', 'done_all\\\\xnor9_synth.txt', 'done_all\\\\xor10_synth.txt', 'done_all\\\\xor11_synth.txt', 'done_all\\\\xor12_synth.txt', 'done_all\\\\xor13_synth.txt', 'done_all\\\\xor14_synth.txt', 'done_all\\\\xor15_synth.txt', 'done_all\\\\xor16_synth.txt', 'done_all\\\\xor17_synth.txt', 'done_all\\\\xor18_synth.txt', 'done_all\\\\xor19_synth.txt', 'done_all\\\\xor1_synth.txt', 'done_all\\\\xor20_synth.txt', 'done_all\\\\xor21_synth.txt', 'done_all\\\\xor22_synth.txt', 'done_all\\\\xor23_synth.txt', 'done_all\\\\xor24_synth.txt', 'done_all\\\\xor25_synth.txt', 'done_all\\\\xor26_synth.txt', 'done_all\\\\xor27_synth.txt', 'done_all\\\\xor28_synth.txt', 'done_all\\\\xor29_synth.txt', 'done_all\\\\xor2_synth.txt', 'done_all\\\\xor3_synth.txt', 'done_all\\\\xor4_synth.txt', 'done_all\\\\xor5_synth.txt', 'done_all\\\\xor6_synth.txt', 'done_all\\\\xor7_synth.txt', 'done_all\\\\xor8_synth.txt']\n"
     ]
    }
   ],
   "source": [
    "def get_files_in_folder(input_folder):\n",
    "    file_list = []\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            file_list.append(file_path)\n",
    "    return file_list\n",
    "\n",
    "# Example usage:\n",
    "folder_path = 'done_all'\n",
    "verilog_files = get_files_in_folder(folder_path)\n",
    "print(len(verilog_files))\n",
    "print(verilog_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracting_attributes(verilog_file):\n",
    "    try:\n",
    "        if os.path.isfile(verilog_file):\n",
    "            with open(verilog_file, \"r\") as file:\n",
    "                loaded_data = json.load(file)\n",
    "                nodes = loaded_data[0]\n",
    "                edges = loaded_data[1]\n",
    "                label = loaded_data[2]\n",
    "                \n",
    "                x = torch.tensor(nodes, dtype=torch.float)\n",
    "                edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "                y = torch.tensor(label, dtype=torch.float)\n",
    "                num_nodes = x.size(0)\n",
    "                \n",
    "                # Create batch assignment vector (assuming one graph per file)\n",
    "                batch = torch.zeros(num_nodes, dtype=torch.long)\n",
    "                data = Data(x=x, edge_index=edge_index, y = y, batch = batch)\n",
    "                return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 396 Verilog files.\n",
      "396\n"
     ]
    }
   ],
   "source": [
    "class VerilogDataset(Dataset):  # Using Dataset from torch_geometric\n",
    "    def __init__(self, verilog_files):\n",
    "        print(f\"Loaded {len(verilog_files)} Verilog files.\")\n",
    "        self.verilog_files = verilog_files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.verilog_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        verilog_file = self.verilog_files[idx]\n",
    "        data = extracting_attributes(verilog_file)\n",
    "        return data\n",
    "\n",
    "dataset = VerilogDataset(verilog_files)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[54, 7], edge_index=[2, 72], y=[1, 16], batch=[54])\n",
      "done_all\\adder10_synth.txt\n",
      "done_all\\adder10_synth.txt\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])\n",
    "print(verilog_files[0])\n",
    "print(dataset.verilog_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data objects are unique.\n"
     ]
    }
   ],
   "source": [
    "def are_all_data_objects_unique(dataset):\n",
    "    data_objects = []\n",
    "    for data in dataset:\n",
    "        if data in data_objects:\n",
    "            return False\n",
    "        data_objects.append(data)\n",
    "    return True\n",
    "\n",
    "# Example usage:\n",
    "is_unique = are_all_data_objects_unique(dataset)\n",
    "if is_unique:\n",
    "    print(\"All data objects are unique.\")\n",
    "else:\n",
    "    print(\"Duplicate data objects found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = []\n",
    "for data in dataset:\n",
    "    # print(data)\n",
    "    # print(data.y.tolist())\n",
    "    y_labels.append(np.argmax(data.y.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    if isinstance(batch[0], Data):\n",
    "        return batch\n",
    "    else:\n",
    "        return default_collate(batch)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, y_labels, test_size=0.2, stratify = y_labels, random_state=41)\n",
    "train_loader = DataLoader(X_train, batch_size=16, shuffle=True, collate_fn=custom_collate)\n",
    "test_loader = DataLoader(X_test, batch_size=16, shuffle = False, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[82, 7], edge_index=[2, 109], y=[1, 16], batch=[82])\n"
     ]
    }
   ],
   "source": [
    "# len(train_loader.dataset)\n",
    "print(train_loader.dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.all(dataset[0].y == dataset[1].y).tolist() == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairs(dataset):\n",
    "    pairs = []\n",
    "    pair_labels = []\n",
    "    for i in range(len(dataset)):\n",
    "        for j in range(i + 1, len(dataset)):\n",
    "            pairs.append((dataset[i], dataset[j]))\n",
    "            pair_labels.append(1 if torch.all(dataset[i].y == dataset[j].y).tolist() else 0)\n",
    "    return pairs, pair_labels\n",
    "\n",
    "# Example usage\n",
    "pairs, pair_labels = generate_pairs(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class SiameseGNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(SiameseGNN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(7, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        # print(x)\n",
    "        x = global_mean_pool(x, data.batch)  # [batch_size, hidden_channels]\n",
    "        return x\n",
    "\n",
    "    def compute_similarity(self, data1, data2):\n",
    "        emb1 = self.forward(data1)\n",
    "        emb2 = self.forward(data2)\n",
    "        return F.cosine_similarity(emb1, emb2), emb1, emb2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Data(x=[17, 7], edge_index=[2, 23], y=[1, 16], batch=[17]), Data(x=[26, 7], edge_index=[2, 36], y=[1, 16], batch=[26]))\n"
     ]
    }
   ],
   "source": [
    "data_pairs = [(data1, data2) for data1, data2 in pairs]\n",
    "print(data_pairs[1234])\n",
    "labels = torch.tensor(pair_labels, dtype=torch.float32)\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(similarity, label, margin=0.5):\n",
    "    loss = (label * (1 - similarity)**2 + (1 - label) * F.relu(similarity - margin)**2).mean()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "Epoch 0, Loss: 0.0264\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "Epoch 1, Loss: 0.0182\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "siamese_model = SiameseGNN(hidden_channels=32).to(device)\n",
    "optimizer = torch.optim.Adam(siamese_model.parameters(), lr=0.01)\n",
    "\n",
    "def train(model, data_pairs, labels):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, (data1, data2) in enumerate(data_pairs):\n",
    "        data1, data2 = data1.to(device), data2.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        if i % 10000 == 0:\n",
    "            print(i)\n",
    "        # print(data1.y)\n",
    "        # print(data2.y)\n",
    "        similarity, emb1, emb2 = model.compute_similarity(data1, data2)\n",
    "        # print(similarity)\n",
    "        loss = contrastive_loss(similarity, labels[i].to(device))\n",
    "        # print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_pairs)\n",
    "\n",
    "# Create DataLoader for pairs\n",
    "data_pairs = [(data1, data2) for data1, data2 in pairs]\n",
    "# print(data_pairs)\n",
    "labels = torch.tensor(pair_labels, dtype=torch.float32)\n",
    "# loader = DataLoader(data_pairs, batch_size=32, shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "flag = 0\n",
    "for epoch in range(100):\n",
    "    loss = train(siamese_model, data_pairs, labels)\n",
    "    if flag == 2:\n",
    "        break\n",
    "    if loss < 0.3:\n",
    "        flag += 1\n",
    "    \n",
    "    print(f'Epoch {epoch}, Loss: {loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_embeddings = []\n",
    "for data in X_train:\n",
    "    data = data.to(device)\n",
    "    graph_embeddings.append(siamese_model.forward(data).detach().cpu().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_MSE(v1, v2):\n",
    "    squared_diff = (v1 - v2) ** 2\n",
    "\n",
    "# Step 2: Calculate mean squared error\n",
    "    mse = np.mean(squared_diff)\n",
    "\n",
    "# Step 3 (optional): Compute root mean squared error (RMSE)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "siamese_model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in X_test:\n",
    "        data = data.to(device)\n",
    "        res = siamese_model.forward(data).detach().cpu().numpy()\n",
    "        min_loss = math.inf\n",
    "        match = []\n",
    "        for i, em in enumerate(graph_embeddings):\n",
    "            diff = compute_MSE(em, res)\n",
    "            if diff <min_loss:\n",
    "                min_loss = diff\n",
    "                match = X_train[i]\n",
    "        \n",
    "        if torch.all(data.y == match.y):\n",
    "            correct += 1\n",
    "\n",
    "accuracy = correct/len(X_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(siamese_model.state_dict(), 'siamese_80.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionHead(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_dim, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveGNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, output_dim, siamese_model):\n",
    "        super(ContrastiveGNN, self).__init__()\n",
    "        self.siamese_gnn = siamese_model\n",
    "        self.projection_head = ProjectionHead(hidden_channels, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.siamese_gnn(data)\n",
    "        x = self.projection_head(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
