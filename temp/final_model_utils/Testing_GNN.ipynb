{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\mai\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (2022.2.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "%pip install torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "%pip install torch_geometric -q\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data import random_split\n",
    "import math\n",
    "from torch_geometric.utils import to_dense_adj, add_self_loops\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from preprocessing_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (gcn1): GCNConv(20, 64)\n",
       "  (r1): ReLU()\n",
       "  (gcn2): GCNConv(64, 64)\n",
       "  (r2): ReLU()\n",
       "  (gcn3): GCNConv(64, 128)\n",
       "  (linear): Linear(in_features=128, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from torch_geometric.nn import GCNConv\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        \n",
    "        num_node_features = 20\n",
    "        num_output_classes = 14\n",
    "        \n",
    "        # num_channels = 32\n",
    "        \n",
    "        self.gcn1 = GCNConv(num_node_features, 64)\n",
    "        self.r1 = nn.ReLU()\n",
    "        self.gcn2 = GCNConv(64, 64)\n",
    "        self.r2 = nn.ReLU()\n",
    "        self.gcn3 = GCNConv(64, 128)\n",
    "        # self.r3 = nn.ReLU()\n",
    "        # self.gcn4 = GCNConv(128, 128)\n",
    "        self.linear = nn.Linear(in_features=128, out_features=num_output_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "    \n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = self.r1(x)\n",
    "        x = self.gcn2(x, edge_index)\n",
    "        x = self.r2(x)\n",
    "        x = self.gcn3(x, edge_index)\n",
    "        # x = self.r3(x)\n",
    "        # x = self.gcn4(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = F.dropout(x, p = 0.4, training=self.training)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        probs = F.log_softmax(x, dim=-1)\n",
    "        \n",
    "        return probs\n",
    "        \n",
    "        \n",
    "        \n",
    "        # KNN\n",
    "        # embeddings\n",
    "        # PCA\n",
    "GCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_test(test_file):\n",
    "    if test_file.endswith('.txt'):\n",
    "        with open(test_file, \"r\") as file:\n",
    "            loaded_data = json.load(file)\n",
    "            label = label_verilog_file(os.path.basename(test_file))\n",
    "            if label is not None and [label] not in loaded_data:  # Check if label already exists\n",
    "                loaded_data.append([label])  # Add label as the third list\n",
    "            return loaded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracting_attributes(verilog_file):\n",
    "    try:\n",
    "                nodes = verilog_file[0]\n",
    "                edges = verilog_file[1]\n",
    "                label = verilog_file[2]\n",
    "                \n",
    "                x = torch.tensor(nodes, dtype=torch.float)\n",
    "                edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "                y = torch.tensor(label, dtype=torch.float)\n",
    "                num_nodes = x.size(0)\n",
    "                \n",
    "                # Create batch assignment vector (assuming one graph per file)\n",
    "                batch = torch.zeros(num_nodes, dtype=torch.long)\n",
    "                data = Data(x=x, edge_index=edge_index, y = y, batch = batch)\n",
    "                return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_GNN(test_file):\n",
    "    label_mapping = {\n",
    "        'adder': 0, 'comparator': 1, 'decoder': 2,\n",
    "        'encoder': 3, 'mult': 4, 'mux': 5, 'pe': 6, 'sub': 7, 'and': 8, 'or': 9, 'not': 10, 'nand': 11, 'nor': 12, 'xnor': 13\n",
    "    }\n",
    "    \n",
    "    verilog_file = preprocessing_test(test_file)\n",
    "    data = extracting_attributes(verilog_file)\n",
    "    gcn = GCN()\n",
    "    gcn.load_state_dict(torch.load('gcn_model89-72-0001-200.pth'))\n",
    "    out = gcn(data.x, data.edge_index, data.batch) \n",
    "    pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    pred_label = (pred.tolist())[0]\n",
    "    label = [k for k, v in label_mapping.items() if v == pred_label]\n",
    "    return label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook testing_GNN.ipynb to script\n",
      "[NbConvertApp] Writing 4295 bytes to testing_GNN.py\n"
     ]
    }
   ],
   "source": [
    "def create_py():\n",
    "    !jupyter nbconvert --to script testing_GNN.ipynb\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    create_py()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adder'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file = 'adder12.txt'\n",
    "label = infer_GNN(test_file)\n",
    "label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
