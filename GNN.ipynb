{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\mai\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (2022.2.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "%pip install torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "%pip install torch_geometric -q\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data import random_split\n",
    "import math\n",
    "from torch_geometric.utils import to_dense_adj, add_self_loops\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "DATA_PATH = \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289\n",
      "['done\\\\adder11.txt', 'done\\\\adder12.txt', 'done\\\\adder13.txt', 'done\\\\adder14.txt', 'done\\\\adder15.txt', 'done\\\\adder16.txt', 'done\\\\adder17.txt', 'done\\\\adder18.txt', 'done\\\\adder19.txt', 'done\\\\adder2.txt', 'done\\\\adder20.txt', 'done\\\\adder4.txt', 'done\\\\adder5.txt', 'done\\\\adder6.txt', 'done\\\\adder8.txt', 'done\\\\and1.txt', 'done\\\\and10.txt', 'done\\\\and12.txt', 'done\\\\and13.txt', 'done\\\\and14.txt', 'done\\\\and15.txt', 'done\\\\and16.txt', 'done\\\\and17.txt', 'done\\\\and18.txt', 'done\\\\and19.txt', 'done\\\\and2.txt', 'done\\\\and20.txt', 'done\\\\and21.txt', 'done\\\\and23.txt', 'done\\\\and25.txt', 'done\\\\and26.txt', 'done\\\\and27.txt', 'done\\\\and28.txt', 'done\\\\and29.txt', 'done\\\\and3.txt', 'done\\\\and30.txt', 'done\\\\and6.txt', 'done\\\\and7.txt', 'done\\\\and8.txt', 'done\\\\and9.txt', 'done\\\\comparator1.txt', 'done\\\\comparator13.txt', 'done\\\\comparator14.txt', 'done\\\\comparator15.txt', 'done\\\\comparator16.txt', 'done\\\\comparator17.txt', 'done\\\\comparator18.txt', 'done\\\\comparator19.txt', 'done\\\\comparator2.txt', 'done\\\\comparator20.txt', 'done\\\\comparator21.txt', 'done\\\\comparator22.txt', 'done\\\\comparator23.txt', 'done\\\\comparator24.txt', 'done\\\\comparator25.txt', 'done\\\\comparator26.txt', 'done\\\\comparator27.txt', 'done\\\\comparator28.txt', 'done\\\\comparator29.txt', 'done\\\\comparator3.txt', 'done\\\\comparator30.txt', 'done\\\\comparator31.txt', 'done\\\\comparator4.txt', 'done\\\\comparator5.txt', 'done\\\\comparator6.txt', 'done\\\\comparator7.txt', 'done\\\\comparator8.txt', 'done\\\\comparator9.txt', 'done\\\\decoder1.txt', 'done\\\\decoder11.txt', 'done\\\\decoder12.txt', 'done\\\\decoder13.txt', 'done\\\\decoder14.txt', 'done\\\\decoder15.txt', 'done\\\\decoder16.txt', 'done\\\\decoder17.txt', 'done\\\\decoder18.txt', 'done\\\\decoder19.txt', 'done\\\\decoder2.txt', 'done\\\\decoder20.txt', 'done\\\\decoder21.txt', 'done\\\\decoder22.txt', 'done\\\\decoder23.txt', 'done\\\\decoder24.txt', 'done\\\\decoder25.txt', 'done\\\\decoder26.txt', 'done\\\\decoder27.txt', 'done\\\\decoder28.txt', 'done\\\\decoder29.txt', 'done\\\\decoder3.txt', 'done\\\\decoder30.txt', 'done\\\\decoder31.txt', 'done\\\\decoder32.txt', 'done\\\\decoder4.txt', 'done\\\\encoder1.txt', 'done\\\\encoder10.txt', 'done\\\\encoder11.txt', 'done\\\\encoder12.txt', 'done\\\\encoder13.txt', 'done\\\\encoder14.txt', 'done\\\\encoder15.txt', 'done\\\\encoder16.txt', 'done\\\\encoder17.txt', 'done\\\\encoder18.txt', 'done\\\\encoder19.txt', 'done\\\\encoder2.txt', 'done\\\\encoder20.txt', 'done\\\\encoder21.txt', 'done\\\\encoder24.txt', 'done\\\\encoder25.txt', 'done\\\\encoder3.txt', 'done\\\\encoder4.txt', 'done\\\\encoder5.txt', 'done\\\\encoder6.txt', 'done\\\\encoder7.txt', 'done\\\\encoder8.txt', 'done\\\\encoder9.txt', 'done\\\\mult1.txt', 'done\\\\mult10.txt', 'done\\\\mult11.txt', 'done\\\\mult12.txt', 'done\\\\mult13.txt', 'done\\\\mult14.txt', 'done\\\\mult15.txt', 'done\\\\mult16.txt', 'done\\\\mult17.txt', 'done\\\\mult18.txt', 'done\\\\mult19.txt', 'done\\\\mult2.txt', 'done\\\\mult3.txt', 'done\\\\mult30.txt', 'done\\\\mult31.txt', 'done\\\\mult32.txt', 'done\\\\mult33.txt', 'done\\\\mult34.txt', 'done\\\\mult35.txt', 'done\\\\mult36.txt', 'done\\\\mult4.txt', 'done\\\\mult5.txt', 'done\\\\mult6.txt', 'done\\\\mult8.txt', 'done\\\\mult9.txt', 'done\\\\mux1.txt', 'done\\\\mux10.txt', 'done\\\\mux11.txt', 'done\\\\mux12.txt', 'done\\\\mux13.txt', 'done\\\\mux14.txt', 'done\\\\mux15.txt', 'done\\\\mux16.txt', 'done\\\\mux17.txt', 'done\\\\mux18.txt', 'done\\\\mux19.txt', 'done\\\\mux2.txt', 'done\\\\mux20.txt', 'done\\\\mux21.txt', 'done\\\\mux22.txt', 'done\\\\mux23.txt', 'done\\\\mux24.txt', 'done\\\\mux25.txt', 'done\\\\mux26.txt', 'done\\\\mux3.txt', 'done\\\\mux4.txt', 'done\\\\mux5.txt', 'done\\\\mux6.txt', 'done\\\\mux7.txt', 'done\\\\mux8.txt', 'done\\\\mux9.txt', 'done\\\\nand1.txt', 'done\\\\nand10.txt', 'done\\\\nand11.txt', 'done\\\\nand12.txt', 'done\\\\nand14.txt', 'done\\\\nand15.txt', 'done\\\\nand16.txt', 'done\\\\nand17.txt', 'done\\\\nand18.txt', 'done\\\\nand19.txt', 'done\\\\nand2.txt', 'done\\\\nand20.txt', 'done\\\\nand21.txt', 'done\\\\nand22.txt', 'done\\\\nand3.txt', 'done\\\\nand4.txt', 'done\\\\nand6.txt', 'done\\\\nand7.txt', 'done\\\\nand8.txt', 'done\\\\nand9.txt', 'done\\\\nor1.txt', 'done\\\\nor10.txt', 'done\\\\nor11.txt', 'done\\\\nor12.txt', 'done\\\\nor13.txt', 'done\\\\nor14.txt', 'done\\\\nor15.txt', 'done\\\\nor16.txt', 'done\\\\nor17.txt', 'done\\\\nor2.txt', 'done\\\\nor3.txt', 'done\\\\nor4.txt', 'done\\\\nor6.txt', 'done\\\\nor7.txt', 'done\\\\nor8.txt', 'done\\\\nor9.txt', 'done\\\\not1.txt', 'done\\\\not10.txt', 'done\\\\not11.txt', 'done\\\\not12.txt', 'done\\\\not13.txt', 'done\\\\not14.txt', 'done\\\\not2.txt', 'done\\\\not3.txt', 'done\\\\not6.txt', 'done\\\\not7.txt', 'done\\\\not9.txt', 'done\\\\or1.txt', 'done\\\\or10.txt', 'done\\\\or11.txt', 'done\\\\or12.txt', 'done\\\\or13.txt', 'done\\\\or14.txt', 'done\\\\or15.txt', 'done\\\\or16.txt', 'done\\\\or17.txt', 'done\\\\or18.txt', 'done\\\\or19.txt', 'done\\\\or2.txt', 'done\\\\or20.txt', 'done\\\\or21.txt', 'done\\\\or22.txt', 'done\\\\or23.txt', 'done\\\\or24.txt', 'done\\\\or25.txt', 'done\\\\or26.txt', 'done\\\\or28.txt', 'done\\\\or4.txt', 'done\\\\or7.txt', 'done\\\\or8.txt', 'done\\\\or9.txt', 'done\\\\pe1.txt', 'done\\\\pe14.txt', 'done\\\\pe15.txt', 'done\\\\pe16.txt', 'done\\\\pe17.txt', 'done\\\\pe18.txt', 'done\\\\pe19.txt', 'done\\\\pe2.txt', 'done\\\\pe20.txt', 'done\\\\pe21.txt', 'done\\\\pe22.txt', 'done\\\\pe3.txt', 'done\\\\pe32.txt', 'done\\\\pe4.txt', 'done\\\\pe5.txt', 'done\\\\pe6.txt', 'done\\\\pe7.txt', 'done\\\\sub1.txt', 'done\\\\sub10.txt', 'done\\\\sub11.txt', 'done\\\\sub12.txt', 'done\\\\sub2.txt', 'done\\\\sub5.txt', 'done\\\\sub6.txt', 'done\\\\sub7.txt', 'done\\\\sub8.txt', 'done\\\\sub9.txt', 'done\\\\xnor1.txt', 'done\\\\xnor10.txt', 'done\\\\xnor11.txt', 'done\\\\xnor12.txt', 'done\\\\xnor13.txt', 'done\\\\xnor14.txt', 'done\\\\xnor15.txt', 'done\\\\xnor16.txt', 'done\\\\xnor17.txt', 'done\\\\xnor18.txt', 'done\\\\xnor19.txt', 'done\\\\xnor2.txt', 'done\\\\xnor20.txt', 'done\\\\xnor21.txt', 'done\\\\xnor22.txt', 'done\\\\xnor23.txt', 'done\\\\xnor24.txt', 'done\\\\xnor25.txt', 'done\\\\xnor4.txt', 'done\\\\xnor6.txt', 'done\\\\xnor7.txt', 'done\\\\xnor8.txt', 'done\\\\xnor9.txt']\n"
     ]
    }
   ],
   "source": [
    "def get_files_in_folder(input_folder):\n",
    "    file_list = []\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            file_list.append(file_path)\n",
    "    return file_list\n",
    "\n",
    "# Example usage:\n",
    "folder_path = 'done'\n",
    "verilog_files = get_files_in_folder(folder_path)\n",
    "print(len(verilog_files))\n",
    "print(verilog_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracting_attributes(verilog_file):\n",
    "    try:\n",
    "        if os.path.isfile(verilog_file):\n",
    "            with open(verilog_file, \"r\") as file:\n",
    "                loaded_data = json.load(file)\n",
    "                nodes = loaded_data[0]\n",
    "                edges = loaded_data[1]\n",
    "                label = loaded_data[2]\n",
    "                \n",
    "                x = torch.tensor(nodes, dtype=torch.float)\n",
    "                edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "                y = torch.tensor(label, dtype=torch.float)\n",
    "                num_nodes = x.size(0)\n",
    "                \n",
    "                # Create batch assignment vector (assuming one graph per file)\n",
    "                batch = torch.zeros(num_nodes, dtype=torch.long)\n",
    "                data = Data(x=x, edge_index=edge_index, y = y, batch = batch)\n",
    "                return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return e\n",
    "\n",
    "# temp=extracting_attributes(\"./done/adder6.txt\")\n",
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 289 Verilog files.\n",
      "289\n"
     ]
    }
   ],
   "source": [
    "class VerilogDataset(Dataset):  # Using Dataset from torch_geometric\n",
    "    def __init__(self, verilog_files):\n",
    "        print(f\"Loaded {len(verilog_files)} Verilog files.\")\n",
    "        self.verilog_files = verilog_files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.verilog_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        verilog_file = self.verilog_files[idx]\n",
    "        data = extracting_attributes(verilog_file)\n",
    "        return data\n",
    "\n",
    "dataset = VerilogDataset(verilog_files)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[165, 20], edge_index=[2, 208], y=[1, 14], batch=[165])\n",
      "done\\adder11.txt\n",
      "done\\adder11.txt\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])\n",
    "print(verilog_files[0])\n",
    "print(dataset.verilog_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data objects are unique.\n"
     ]
    }
   ],
   "source": [
    "def are_all_data_objects_unique(dataset):\n",
    "    data_objects = []\n",
    "    for data in dataset:\n",
    "        if data in data_objects:\n",
    "            return False\n",
    "        data_objects.append(data)\n",
    "    return True\n",
    "\n",
    "# Example usage:\n",
    "is_unique = are_all_data_objects_unique(dataset)\n",
    "if is_unique:\n",
    "    print(\"All data objects are unique.\")\n",
    "else:\n",
    "    print(\"Duplicate data objects found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done\\\\comparator28.txt'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = random.randint(0, len(verilog_files))\n",
    "verilog_files[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = dataset[num]\n",
    "data\n",
    "\n",
    "g = nx.Graph()\n",
    "g.add_nodes_from(range(data.num_nodes))\n",
    "edges = data.edge_index.t().tolist()\n",
    "# edge_attrs = {tuple(edge): attr.item() for edge, attr in zip(edges, data.edge_attr)}\n",
    "g.add_edges_from(edges)\n",
    "print(len(edges))\n",
    "\n",
    "# Draw the graph with edge attributes\n",
    "pos = nx.spring_layout(g)  # positions for all nodes\n",
    "nx.draw(g, pos, with_labels=True, node_color='skyblue', node_size=1500, edge_color='k', linewidths=1, font_size=15)\n",
    "nx.draw_networkx_edge_labels(g, pos, font_color='red', font_size=12)  # Add edge labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    if isinstance(batch[0], Data):\n",
    "        return batch\n",
    "    else:\n",
    "        return default_collate(batch)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK THIS TANYY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = []\n",
    "for data in dataset:\n",
    "    # print(data)\n",
    "    # print(data.y.tolist())\n",
    "    y_labels.append(np.argmax(data.y.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, y_labels, test_size=0.3, stratify = y_labels, random_state=42)\n",
    "train_loader = DataLoader(X_train, batch_size=16, shuffle=True, collate_fn=custom_collate)\n",
    "test_loader = DataLoader(X_test, batch_size=16, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from torch.utils.data import random_split\n",
    "\n",
    "# # # Define the sizes of training, validation, and test sets\n",
    "# # train_size = int(0.7 * len(dataset))  # 70% of the data for training\n",
    "# # val_size = int(0.15 * len(dataset))   # 15% of the data for validation\n",
    "# # test_size = len(dataset) - train_size - val_size  # Remaining data for testing\n",
    "\n",
    "# # # Split the dataset into training, validation, and test sets\n",
    "# # train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# # # Create DataLoader for each set\n",
    "# # train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# # val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
    "# # test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "\n",
    "# # Define the size of the training set (e.g., 70% of the data)\n",
    "# train_size = int(0.7 * len(dataset))\n",
    "\n",
    "# # Calculate the size of the testing set\n",
    "# test_size = len(dataset) - train_size\n",
    "\n",
    "# # Split the dataset into training and testing sets\n",
    "# train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# # Create DataLoader for each set\n",
    "# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=custom_collate)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=custom_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[47, 20], edge_index=[2, 80], y=[1, 14], batch=[47])\n"
     ]
    }
   ],
   "source": [
    "# len(train_loader.dataset)\n",
    "print(train_loader.dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_iter = iter(train_loader)\n",
    "batch = next(loader_iter)\n",
    "# print(batch)\n",
    "# print(batch.num_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (gcn1): GCNConv(20, 64)\n",
       "  (r1): ReLU()\n",
       "  (gcn2): GCNConv(64, 64)\n",
       "  (r2): ReLU()\n",
       "  (gcn3): GCNConv(64, 128)\n",
       "  (linear): Linear(in_features=128, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from torch_geometric.nn import GCNConv\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        \n",
    "        num_node_features = 20\n",
    "        num_output_classes = 14\n",
    "        \n",
    "        # num_channels = 32\n",
    "        \n",
    "        self.gcn1 = GCNConv(num_node_features, 64)\n",
    "        self.r1 = nn.ReLU()\n",
    "        self.gcn2 = GCNConv(64, 64)\n",
    "        self.r2 = nn.ReLU()\n",
    "        self.gcn3 = GCNConv(64, 128)\n",
    "        # self.r3 = nn.ReLU()\n",
    "        # self.gcn4 = GCNConv(128, 128)\n",
    "        self.linear = nn.Linear(in_features=128, out_features=num_output_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "    \n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = self.r1(x)\n",
    "        x = self.gcn2(x, edge_index)\n",
    "        x = self.r2(x)\n",
    "        x = self.gcn3(x, edge_index)\n",
    "        # x = self.r3(x)\n",
    "        # x = self.gcn4(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = F.dropout(x, p = 0.4, training=self.training)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        probs = F.log_softmax(x, dim=-1)\n",
    "        \n",
    "        return probs\n",
    "        \n",
    "        \n",
    "        \n",
    "        # KNN\n",
    "        # embeddings\n",
    "        # PCA\n",
    "GCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.0990, Test Acc: 0.0920\n",
      "Epoch: 002, Train Acc: 0.1337, Test Acc: 0.1264\n",
      "Epoch: 003, Train Acc: 0.1485, Test Acc: 0.1264\n",
      "Epoch: 004, Train Acc: 0.1139, Test Acc: 0.1149\n",
      "Epoch: 005, Train Acc: 0.1931, Test Acc: 0.1724\n",
      "Epoch: 006, Train Acc: 0.2228, Test Acc: 0.2644\n",
      "Epoch: 007, Train Acc: 0.2030, Test Acc: 0.2529\n",
      "Epoch: 008, Train Acc: 0.2178, Test Acc: 0.2414\n",
      "Epoch: 009, Train Acc: 0.2624, Test Acc: 0.2874\n",
      "Epoch: 010, Train Acc: 0.2624, Test Acc: 0.2759\n",
      "Epoch: 011, Train Acc: 0.3020, Test Acc: 0.2989\n",
      "Epoch: 012, Train Acc: 0.3168, Test Acc: 0.2874\n",
      "Epoch: 013, Train Acc: 0.3020, Test Acc: 0.2989\n",
      "Epoch: 014, Train Acc: 0.3515, Test Acc: 0.2874\n",
      "Epoch: 015, Train Acc: 0.3218, Test Acc: 0.3218\n",
      "Epoch: 016, Train Acc: 0.3465, Test Acc: 0.3103\n",
      "Epoch: 017, Train Acc: 0.3861, Test Acc: 0.3333\n",
      "Epoch: 018, Train Acc: 0.4109, Test Acc: 0.3218\n",
      "Epoch: 019, Train Acc: 0.4208, Test Acc: 0.3448\n",
      "Epoch: 020, Train Acc: 0.4208, Test Acc: 0.3218\n",
      "Epoch: 021, Train Acc: 0.3960, Test Acc: 0.3448\n",
      "Epoch: 022, Train Acc: 0.4406, Test Acc: 0.3563\n",
      "Epoch: 023, Train Acc: 0.4208, Test Acc: 0.3103\n",
      "Epoch: 024, Train Acc: 0.4406, Test Acc: 0.3678\n",
      "Epoch: 025, Train Acc: 0.5000, Test Acc: 0.4138\n",
      "Epoch: 026, Train Acc: 0.4752, Test Acc: 0.4023\n",
      "Epoch: 027, Train Acc: 0.4901, Test Acc: 0.4138\n",
      "Epoch: 028, Train Acc: 0.4802, Test Acc: 0.3563\n",
      "Epoch: 029, Train Acc: 0.5000, Test Acc: 0.3563\n",
      "Epoch: 030, Train Acc: 0.4901, Test Acc: 0.4253\n",
      "Epoch: 031, Train Acc: 0.4950, Test Acc: 0.4483\n",
      "Epoch: 032, Train Acc: 0.5198, Test Acc: 0.4598\n",
      "Epoch: 033, Train Acc: 0.5198, Test Acc: 0.4368\n",
      "Epoch: 034, Train Acc: 0.5396, Test Acc: 0.4253\n",
      "Epoch: 035, Train Acc: 0.5198, Test Acc: 0.4253\n",
      "Epoch: 036, Train Acc: 0.5297, Test Acc: 0.4253\n",
      "Epoch: 037, Train Acc: 0.4901, Test Acc: 0.3908\n",
      "Epoch: 038, Train Acc: 0.5396, Test Acc: 0.4023\n",
      "Epoch: 039, Train Acc: 0.5050, Test Acc: 0.3908\n",
      "Epoch: 040, Train Acc: 0.5099, Test Acc: 0.3908\n",
      "Epoch: 041, Train Acc: 0.5495, Test Acc: 0.4598\n",
      "Epoch: 042, Train Acc: 0.5446, Test Acc: 0.4138\n",
      "Epoch: 043, Train Acc: 0.5743, Test Acc: 0.4368\n",
      "Epoch: 044, Train Acc: 0.5495, Test Acc: 0.4828\n",
      "Epoch: 045, Train Acc: 0.5347, Test Acc: 0.4253\n",
      "Epoch: 046, Train Acc: 0.5347, Test Acc: 0.4138\n",
      "Epoch: 047, Train Acc: 0.5198, Test Acc: 0.4598\n",
      "Epoch: 048, Train Acc: 0.5347, Test Acc: 0.4368\n",
      "Epoch: 049, Train Acc: 0.5248, Test Acc: 0.4598\n",
      "Epoch: 050, Train Acc: 0.5495, Test Acc: 0.4253\n",
      "Epoch: 051, Train Acc: 0.5495, Test Acc: 0.4483\n",
      "Epoch: 052, Train Acc: 0.5644, Test Acc: 0.4713\n",
      "Epoch: 053, Train Acc: 0.5941, Test Acc: 0.4598\n",
      "Epoch: 054, Train Acc: 0.5891, Test Acc: 0.4713\n",
      "Epoch: 055, Train Acc: 0.5297, Test Acc: 0.4253\n",
      "Epoch: 056, Train Acc: 0.5594, Test Acc: 0.4713\n",
      "Epoch: 057, Train Acc: 0.5743, Test Acc: 0.4828\n",
      "Epoch: 058, Train Acc: 0.5743, Test Acc: 0.5172\n",
      "Epoch: 059, Train Acc: 0.5792, Test Acc: 0.5057\n",
      "Epoch: 060, Train Acc: 0.6188, Test Acc: 0.5057\n",
      "Epoch: 061, Train Acc: 0.5990, Test Acc: 0.5287\n",
      "Epoch: 062, Train Acc: 0.5990, Test Acc: 0.4598\n",
      "Epoch: 063, Train Acc: 0.6386, Test Acc: 0.4828\n",
      "Epoch: 064, Train Acc: 0.5891, Test Acc: 0.4598\n",
      "Epoch: 065, Train Acc: 0.6089, Test Acc: 0.5172\n",
      "Epoch: 066, Train Acc: 0.6287, Test Acc: 0.5747\n",
      "Epoch: 067, Train Acc: 0.6535, Test Acc: 0.4713\n",
      "Epoch: 068, Train Acc: 0.6733, Test Acc: 0.4828\n",
      "Epoch: 069, Train Acc: 0.5941, Test Acc: 0.5287\n",
      "Epoch: 070, Train Acc: 0.6287, Test Acc: 0.5402\n",
      "Epoch: 071, Train Acc: 0.6188, Test Acc: 0.5517\n",
      "Epoch: 072, Train Acc: 0.6337, Test Acc: 0.5172\n",
      "Epoch: 073, Train Acc: 0.6485, Test Acc: 0.5402\n",
      "Epoch: 074, Train Acc: 0.6485, Test Acc: 0.5172\n",
      "Epoch: 075, Train Acc: 0.6535, Test Acc: 0.5632\n",
      "Epoch: 076, Train Acc: 0.6782, Test Acc: 0.5402\n",
      "Epoch: 077, Train Acc: 0.6287, Test Acc: 0.5172\n",
      "Epoch: 078, Train Acc: 0.6634, Test Acc: 0.5287\n",
      "Epoch: 079, Train Acc: 0.6485, Test Acc: 0.5172\n",
      "Epoch: 080, Train Acc: 0.7129, Test Acc: 0.5747\n",
      "Epoch: 081, Train Acc: 0.6980, Test Acc: 0.5632\n",
      "Epoch: 082, Train Acc: 0.6485, Test Acc: 0.6207\n",
      "Epoch: 083, Train Acc: 0.6634, Test Acc: 0.5517\n",
      "Epoch: 084, Train Acc: 0.6832, Test Acc: 0.5402\n",
      "Epoch: 085, Train Acc: 0.6881, Test Acc: 0.5632\n",
      "Epoch: 086, Train Acc: 0.6683, Test Acc: 0.5747\n",
      "Epoch: 087, Train Acc: 0.6980, Test Acc: 0.5747\n",
      "Epoch: 088, Train Acc: 0.6881, Test Acc: 0.5977\n",
      "Epoch: 089, Train Acc: 0.6683, Test Acc: 0.5747\n",
      "Epoch: 090, Train Acc: 0.7030, Test Acc: 0.5632\n",
      "Epoch: 091, Train Acc: 0.6782, Test Acc: 0.6207\n",
      "Epoch: 092, Train Acc: 0.6881, Test Acc: 0.5862\n",
      "Epoch: 093, Train Acc: 0.6584, Test Acc: 0.5747\n",
      "Epoch: 094, Train Acc: 0.6980, Test Acc: 0.5862\n",
      "Epoch: 095, Train Acc: 0.7079, Test Acc: 0.6207\n",
      "Epoch: 096, Train Acc: 0.7426, Test Acc: 0.6322\n",
      "Epoch: 097, Train Acc: 0.6980, Test Acc: 0.5862\n",
      "Epoch: 098, Train Acc: 0.6931, Test Acc: 0.5517\n",
      "Epoch: 099, Train Acc: 0.7228, Test Acc: 0.6207\n",
      "Epoch: 100, Train Acc: 0.7030, Test Acc: 0.5977\n",
      "Epoch: 101, Train Acc: 0.7228, Test Acc: 0.6322\n",
      "Epoch: 102, Train Acc: 0.7079, Test Acc: 0.6092\n",
      "Epoch: 103, Train Acc: 0.7376, Test Acc: 0.6322\n",
      "Epoch: 104, Train Acc: 0.7228, Test Acc: 0.6437\n",
      "Epoch: 105, Train Acc: 0.7574, Test Acc: 0.6322\n",
      "Epoch: 106, Train Acc: 0.6980, Test Acc: 0.6322\n",
      "Epoch: 107, Train Acc: 0.7178, Test Acc: 0.6092\n",
      "Epoch: 108, Train Acc: 0.7178, Test Acc: 0.5977\n",
      "Epoch: 109, Train Acc: 0.7475, Test Acc: 0.6207\n",
      "Epoch: 110, Train Acc: 0.7475, Test Acc: 0.6667\n",
      "Epoch: 111, Train Acc: 0.7228, Test Acc: 0.6092\n",
      "Epoch: 112, Train Acc: 0.7426, Test Acc: 0.6322\n",
      "Epoch: 113, Train Acc: 0.7327, Test Acc: 0.6782\n",
      "Epoch: 114, Train Acc: 0.7228, Test Acc: 0.6437\n",
      "Epoch: 115, Train Acc: 0.7624, Test Acc: 0.6437\n",
      "Epoch: 116, Train Acc: 0.7723, Test Acc: 0.6437\n",
      "Epoch: 117, Train Acc: 0.7525, Test Acc: 0.6322\n",
      "Epoch: 118, Train Acc: 0.7673, Test Acc: 0.6092\n",
      "Epoch: 119, Train Acc: 0.7574, Test Acc: 0.6437\n",
      "Epoch: 120, Train Acc: 0.7673, Test Acc: 0.6207\n",
      "Epoch: 121, Train Acc: 0.7574, Test Acc: 0.6092\n",
      "Epoch: 122, Train Acc: 0.7822, Test Acc: 0.6552\n",
      "Epoch: 123, Train Acc: 0.7129, Test Acc: 0.6322\n",
      "Epoch: 124, Train Acc: 0.7624, Test Acc: 0.6437\n",
      "Epoch: 125, Train Acc: 0.7921, Test Acc: 0.6322\n",
      "Epoch: 126, Train Acc: 0.7723, Test Acc: 0.6207\n",
      "Epoch: 127, Train Acc: 0.7525, Test Acc: 0.6322\n",
      "Epoch: 128, Train Acc: 0.7921, Test Acc: 0.6437\n",
      "Epoch: 129, Train Acc: 0.8069, Test Acc: 0.6552\n",
      "Epoch: 130, Train Acc: 0.8069, Test Acc: 0.6897\n",
      "Epoch: 131, Train Acc: 0.7624, Test Acc: 0.6667\n",
      "Epoch: 132, Train Acc: 0.7970, Test Acc: 0.7011\n",
      "Epoch: 133, Train Acc: 0.7921, Test Acc: 0.6667\n",
      "Epoch: 134, Train Acc: 0.7921, Test Acc: 0.6667\n",
      "Epoch: 135, Train Acc: 0.7871, Test Acc: 0.6667\n",
      "Epoch: 136, Train Acc: 0.7871, Test Acc: 0.6667\n",
      "Epoch: 137, Train Acc: 0.7871, Test Acc: 0.6667\n",
      "Epoch: 138, Train Acc: 0.7475, Test Acc: 0.6437\n",
      "Epoch: 139, Train Acc: 0.7772, Test Acc: 0.6322\n",
      "Epoch: 140, Train Acc: 0.7822, Test Acc: 0.6552\n",
      "Epoch: 141, Train Acc: 0.7426, Test Acc: 0.6552\n",
      "Epoch: 142, Train Acc: 0.7822, Test Acc: 0.6322\n",
      "Epoch: 143, Train Acc: 0.7574, Test Acc: 0.6552\n",
      "Epoch: 144, Train Acc: 0.8119, Test Acc: 0.6782\n",
      "Epoch: 145, Train Acc: 0.7673, Test Acc: 0.6782\n",
      "Epoch: 146, Train Acc: 0.7871, Test Acc: 0.6897\n",
      "Epoch: 147, Train Acc: 0.8119, Test Acc: 0.6667\n",
      "Epoch: 148, Train Acc: 0.7871, Test Acc: 0.6667\n",
      "Epoch: 149, Train Acc: 0.7921, Test Acc: 0.6782\n",
      "Epoch: 150, Train Acc: 0.7822, Test Acc: 0.6667\n",
      "Epoch: 151, Train Acc: 0.8218, Test Acc: 0.6897\n",
      "Epoch: 152, Train Acc: 0.8119, Test Acc: 0.7126\n",
      "Epoch: 153, Train Acc: 0.8020, Test Acc: 0.6667\n",
      "Epoch: 154, Train Acc: 0.7871, Test Acc: 0.6667\n",
      "Epoch: 155, Train Acc: 0.7772, Test Acc: 0.6207\n",
      "Epoch: 156, Train Acc: 0.7723, Test Acc: 0.6667\n",
      "Epoch: 157, Train Acc: 0.7921, Test Acc: 0.6437\n",
      "Epoch: 158, Train Acc: 0.8218, Test Acc: 0.7126\n",
      "Epoch: 159, Train Acc: 0.7921, Test Acc: 0.6322\n",
      "Epoch: 160, Train Acc: 0.8119, Test Acc: 0.6667\n",
      "Epoch: 161, Train Acc: 0.7970, Test Acc: 0.6667\n",
      "Epoch: 162, Train Acc: 0.8168, Test Acc: 0.6897\n",
      "Epoch: 163, Train Acc: 0.8168, Test Acc: 0.7011\n",
      "Epoch: 164, Train Acc: 0.8317, Test Acc: 0.6782\n",
      "Epoch: 165, Train Acc: 0.8069, Test Acc: 0.6437\n",
      "Epoch: 166, Train Acc: 0.8317, Test Acc: 0.6667\n",
      "Epoch: 167, Train Acc: 0.7921, Test Acc: 0.6667\n",
      "Epoch: 168, Train Acc: 0.8020, Test Acc: 0.6667\n",
      "Epoch: 169, Train Acc: 0.8168, Test Acc: 0.6897\n",
      "Epoch: 170, Train Acc: 0.7970, Test Acc: 0.7126\n",
      "Epoch: 171, Train Acc: 0.8366, Test Acc: 0.7241\n",
      "Epoch: 172, Train Acc: 0.7624, Test Acc: 0.6897\n",
      "Epoch: 173, Train Acc: 0.8267, Test Acc: 0.6782\n",
      "Epoch: 174, Train Acc: 0.7673, Test Acc: 0.6897\n",
      "Epoch: 175, Train Acc: 0.8218, Test Acc: 0.7241\n",
      "Epoch: 176, Train Acc: 0.8317, Test Acc: 0.7126\n",
      "Epoch: 177, Train Acc: 0.8218, Test Acc: 0.6897\n",
      "Epoch: 178, Train Acc: 0.7871, Test Acc: 0.7126\n",
      "Epoch: 179, Train Acc: 0.8515, Test Acc: 0.6897\n",
      "Epoch: 180, Train Acc: 0.8218, Test Acc: 0.6782\n",
      "Epoch: 181, Train Acc: 0.8069, Test Acc: 0.6667\n",
      "Epoch: 182, Train Acc: 0.7624, Test Acc: 0.6552\n",
      "Epoch: 183, Train Acc: 0.8218, Test Acc: 0.7126\n",
      "Epoch: 184, Train Acc: 0.8168, Test Acc: 0.7126\n",
      "Epoch: 185, Train Acc: 0.8069, Test Acc: 0.6897\n",
      "Epoch: 186, Train Acc: 0.8416, Test Acc: 0.6782\n",
      "Epoch: 187, Train Acc: 0.8218, Test Acc: 0.6437\n",
      "Epoch: 188, Train Acc: 0.7723, Test Acc: 0.6897\n",
      "Epoch: 189, Train Acc: 0.8267, Test Acc: 0.6897\n",
      "Epoch: 190, Train Acc: 0.8218, Test Acc: 0.6552\n",
      "Epoch: 191, Train Acc: 0.8663, Test Acc: 0.6897\n",
      "Epoch: 192, Train Acc: 0.8119, Test Acc: 0.6667\n",
      "Epoch: 193, Train Acc: 0.8069, Test Acc: 0.6667\n",
      "Epoch: 194, Train Acc: 0.8267, Test Acc: 0.7011\n",
      "Epoch: 195, Train Acc: 0.8267, Test Acc: 0.6437\n",
      "Epoch: 196, Train Acc: 0.8317, Test Acc: 0.7126\n",
      "Epoch: 197, Train Acc: 0.8465, Test Acc: 0.7011\n",
      "Epoch: 198, Train Acc: 0.8168, Test Acc: 0.6667\n",
      "Epoch: 199, Train Acc: 0.8119, Test Acc: 0.6667\n",
      "Epoch: 200, Train Acc: 0.8267, Test Acc: 0.6897\n",
      "Training duration: 496.8173017501831 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gcn = GCN()\n",
    "gcn = gcn.to(device)\n",
    "# print(gcn.parameters())\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(gcn.parameters(), lr=0.0005, weight_decay=0.0005)\n",
    "# loss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "out_labels = []\n",
    "\n",
    "# training_running_loss = 0.0\n",
    "\n",
    "def train(train_loader):\n",
    "    \n",
    "    gcn.train()\n",
    "    # print(gcn.parameters())\n",
    "    for batch_data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        for data in batch_data:\n",
    "            optimizer.zero_grad()\n",
    "            data = data.to(device)\n",
    "            #forward pass\n",
    "            out = gcn(data.x, data.edge_index, data.batch)\n",
    "            # calculate the loss\n",
    "            loss = criterion(out, data.y)\n",
    "            # zero the gradients of the weights so that the gradients are not accumulated\n",
    "            # calculate the gradients using backpropagation\n",
    "            loss.backward()\n",
    "            # update the weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # calculate the loss\n",
    "            # training_running_loss += loss.detach().item()\n",
    "            \n",
    "            out_labels.append((out, data.y))\n",
    "        \n",
    "        \n",
    "\n",
    "testing_labels = []\n",
    "def test(loader):\n",
    "    gcn.eval()\n",
    "    correct = 0\n",
    "    for batch_data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        for data in batch_data:\n",
    "            out = gcn(data.x, data.edge_index, data.batch)  \n",
    "            pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "            testing_labels.append(pred)\n",
    "            y_label = (data.y.tolist())\n",
    "            y_label = y_label[0].index(1.0)\n",
    "            pred_label = (pred.tolist())[0]\n",
    "            # print(pred_label)\n",
    "            # print(y_label)\n",
    "            if y_label == pred_label:\n",
    "                correct += 1            \n",
    "            # correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "num_epochs = 200\n",
    "# Your training code here\n",
    "for epoch in range(num_epochs):\n",
    "    train(train_loader)\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch + 1:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    \n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the duration\n",
    "duration = end_time - start_time\n",
    "print(\"Training duration:\", duration, \"seconds\")\n",
    "# with open(\"out_labels.txt\", \"w\") as output:\n",
    "#         output.write(str(out_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6896551724137931"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    gcn.eval()\n",
    "    train_embeddings = []\n",
    "    test_embeddings = []\n",
    "    for data in X_train:\n",
    "        train_embeddings.append(gcn(data.x, data.edge_index, data.batch).detach().numpy())\n",
    "    for data in X_test:\n",
    "        test_embeddings.append(gcn(data.x, data.edge_index, data.batch).detach().numpy())\n",
    "\n",
    "# Use node embeddings as features for classical ML model (e.g., logistic regression)\n",
    "X_train, y_train = train_embeddings, y_train\n",
    "X_test, y_test = test_embeddings, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.4262156 , -12.328635  ,  -0.70579815,  -1.5290565 ,\n",
       "         -1.4895434 , -13.209088  ,  -4.6643686 ,  -4.124858  ,\n",
       "         -6.7015753 ,  -8.41748   ,  -7.3645954 ,  -5.603663  ,\n",
       "         -8.5741205 , -11.947055  ]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]\n",
    "# y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.5057471264367817\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train_np = np.array(train_embeddings)\n",
    "X_test_np = np.array(test_embeddings)\n",
    "\n",
    "# Reshape the arrays\n",
    "X_train_flat = X_train_np.reshape(X_train_np.shape[0], -1)\n",
    "X_test_flat = X_test_np.reshape(X_test_np.shape[0], -1)\n",
    "\n",
    "# Convert back to lists if needed\n",
    "X_train_flat = X_train_flat.tolist()\n",
    "X_test_flat = X_test_flat.tolist()\n",
    "\n",
    "# Train classical ML model (KNN)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # Specify the number of neighbors\n",
    "knn_classifier.fit(X_train_flat, y_train)\n",
    "\n",
    "# Evaluate classical ML model (KNN)\n",
    "knn_y_pred = knn_classifier.predict(X_test_flat)\n",
    "knn_accuracy = accuracy_score(y_test, knn_y_pred)\n",
    "print(\"KNN Accuracy:\", knn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(knn_classifier, 'knn_model2.pkl')\n",
    "KNN_loaded_model = joblib.load('knn_model2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gcn.state_dict(), 'gcn_model82-68-00005-200.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components=7)\n",
    "# X_train_pca = pca.fit_transform(X_train_flat)\n",
    "# X_test_pca = pca.transform(X_test_flat)\n",
    "\n",
    "# # Train KNN classifier on PCA-transformed data\n",
    "# knn_classifier = KNeighborsClassifier(n_neighbors=14)\n",
    "# knn_classifier.fit(X_train_pca, y_train)\n",
    "\n",
    "# # Evaluate KNN classifier on test set\n",
    "# y_pred = knn_classifier.predict(X_test_pca)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(12, 2): 1,\n",
       " (12, 9): 2,\n",
       " (3, 9): 2,\n",
       " (2, 3): 2,\n",
       " (4, 3): 1,\n",
       " (3, 6): 1,\n",
       " (5, 1): 1,\n",
       " (8, 4): 1,\n",
       " (13, 1): 2,\n",
       " (10, 11): 1,\n",
       " (5, 11): 1,\n",
       " (12, 11): 1,\n",
       " (0, 7): 1,\n",
       " (4, 7): 1,\n",
       " (3, 2): 1,\n",
       " (4, 0): 1,\n",
       " (11, 8): 1,\n",
       " (6, 3): 1,\n",
       " (10, 12): 1,\n",
       " (4, 8): 1,\n",
       " (2, 4): 1,\n",
       " (11, 12): 1,\n",
       " (6, 9): 1}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num = random.randint(0, len(verilog_files))\n",
    "# print(verilog_files[num])\n",
    "output_dict = dict()\n",
    "for data_trial in test_loader.dataset:\n",
    "    \n",
    "    out = gcn(data_trial.x, data_trial.edge_index, data_trial.batch)\n",
    "    pred = out.argmax(dim=1)\n",
    "    \n",
    "    if pred.tolist()[0] != (data_trial.y.tolist())[0].index(1.0):\n",
    "        output_dict[(pred.tolist()[0], (data_trial.y.tolist())[0].index(1.0))] = output_dict.get((pred.tolist()[0], (data_trial.y.tolist())[0].index(1.0)), 0) +1\n",
    "        # print(pred.tolist())\n",
    "        # print((data_trial.y.tolist())[0].index(1.0))\n",
    "\n",
    "\n",
    "output_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gcn = GCN()\n",
    "# gcn.load_state_dict(torch.load('gcn_model85-59-0001-200.pth'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode of Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 321 verilog files \n",
    "* only 3 features             [type, operation_type, num_of_connections]\n",
    "* no edge attribute\n",
    "* 18 classes \n",
    "* 200 epochs \n",
    "* learning rate = 0.01\n",
    "* Dropoout = 0.4\n",
    "* Adam Optimizer\n",
    "* train 70, test 30 (on whole dataset, not each class)\n",
    "* time of training = seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train acc:  0.2902\n",
    "* Test Acc: 0.1959\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested Modifications for upcoming experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Clean dataset (by removing unnecessay, uninformative or wrong code files)\n",
    "2) remove reduntant parsing (different files but same parsing)\n",
    "3) include more informative features\n",
    "4) improve encoding format\n",
    "5) try using less classes (most important ones, so that less classes but more balanced dataset)\n",
    "6) adding more files\n",
    "7) adjusting hyperparameters such as learning rate, dropout, ...etc\n",
    "8) splitting train, val, test\n",
    "9) using equal percentages of each class (adjusting splitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode of Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested Modifications for upcoming experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr = 0.001\n",
    "\n",
    "droput 0.4\n",
    "\n",
    "314 files\n",
    "\n",
    "17 features (node_type)\n",
    "\n",
    "16 classes\n",
    "\n",
    "conv relu conv relu conv relu conv linear\n",
    "\n",
    "train = 40, test = 27\n",
    "\n",
    "200 epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experiment 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same as 5 but 100 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train = 43, test = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr = 0.001\n",
    "\n",
    "conv relu conv relu conv dropout linear\n",
    "\n",
    "9 classes\n",
    "\n",
    "164 file\n",
    "\n",
    "train = 34, test = 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr = 0.001\n",
    "\n",
    "9 classes\n",
    "\n",
    "conv relu conv relu conv dropout linear \n",
    "\n",
    "train = 64, test = 52\n",
    "\n",
    "164 \n",
    "\n",
    "17 features (node type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
