{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\mai\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (2022.2.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "!pip install torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "!pip install torch_geometric -q\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data import random_split\n",
    "import math\n",
    "from torch_geometric.utils import to_dense_adj, add_self_loops\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "DATA_PATH = \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['done\\\\adder11.txt', 'done\\\\adder12.txt', 'done\\\\adder13.txt', 'done\\\\adder14.txt', 'done\\\\adder15.txt', 'done\\\\adder16.txt', 'done\\\\adder17.txt', 'done\\\\adder18.txt', 'done\\\\adder19.txt', 'done\\\\adder2.txt', 'done\\\\adder20.txt', 'done\\\\adder5.txt', 'done\\\\adder6.txt', 'done\\\\adder8.txt', 'done\\\\ALU10.txt', 'done\\\\ALU13.txt', 'done\\\\ALU14.txt', 'done\\\\ALU15.txt', 'done\\\\ALU2.txt', 'done\\\\ALU6.txt', 'done\\\\ALU7.txt', 'done\\\\ALU8.txt', 'done\\\\ALU9.txt', 'done\\\\comparator1.txt', 'done\\\\comparator13.txt', 'done\\\\comparator14.txt', 'done\\\\comparator15.txt', 'done\\\\comparator16.txt', 'done\\\\comparator17.txt', 'done\\\\comparator18.txt', 'done\\\\comparator19.txt', 'done\\\\comparator2.txt', 'done\\\\comparator20.txt', 'done\\\\comparator21.txt', 'done\\\\comparator22.txt', 'done\\\\comparator23.txt', 'done\\\\comparator6.txt', 'done\\\\comparator7.txt', 'done\\\\comparator8.txt', 'done\\\\comparator9.txt', 'done\\\\decoder1.txt', 'done\\\\decoder11.txt', 'done\\\\decoder12.txt', 'done\\\\decoder13.txt', 'done\\\\decoder14.txt', 'done\\\\decoder15.txt', 'done\\\\decoder16.txt', 'done\\\\decoder17.txt', 'done\\\\decoder18.txt', 'done\\\\decoder19.txt', 'done\\\\decoder2.txt', 'done\\\\decoder20.txt', 'done\\\\decoder21.txt', 'done\\\\decoder22.txt', 'done\\\\decoder23.txt', 'done\\\\decoder24.txt', 'done\\\\decoder25.txt', 'done\\\\decoder26.txt', 'done\\\\decoder27.txt', 'done\\\\decoder28.txt', 'done\\\\decoder29.txt', 'done\\\\decoder3.txt', 'done\\\\decoder30.txt', 'done\\\\decoder31.txt', 'done\\\\decoder32.txt', 'done\\\\decoder4.txt', 'done\\\\encoder1.txt', 'done\\\\encoder10.txt', 'done\\\\encoder11.txt', 'done\\\\encoder12.txt', 'done\\\\encoder13.txt', 'done\\\\encoder14.txt', 'done\\\\encoder15.txt', 'done\\\\encoder16.txt', 'done\\\\encoder17.txt', 'done\\\\encoder18.txt', 'done\\\\encoder19.txt', 'done\\\\encoder2.txt', 'done\\\\encoder20.txt', 'done\\\\encoder21.txt', 'done\\\\encoder24.txt', 'done\\\\encoder25.txt', 'done\\\\encoder3.txt', 'done\\\\encoder4.txt', 'done\\\\encoder5.txt', 'done\\\\encoder6.txt', 'done\\\\encoder7.txt', 'done\\\\encoder8.txt', 'done\\\\encoder9.txt', 'done\\\\mult1.txt', 'done\\\\mult10.txt', 'done\\\\mult11.txt', 'done\\\\mult12.txt', 'done\\\\mult13.txt', 'done\\\\mult14.txt', 'done\\\\mult15.txt', 'done\\\\mult16.txt', 'done\\\\mult17.txt', 'done\\\\mult18.txt', 'done\\\\mult19.txt', 'done\\\\mult2.txt', 'done\\\\mult3.txt', 'done\\\\mult30.txt', 'done\\\\mult31.txt', 'done\\\\mult32.txt', 'done\\\\mult33.txt', 'done\\\\mult34.txt', 'done\\\\mult35.txt', 'done\\\\mult4.txt', 'done\\\\mult5.txt', 'done\\\\mult6.txt', 'done\\\\mult8.txt', 'done\\\\mult9.txt', 'done\\\\mux1.txt', 'done\\\\mux10.txt', 'done\\\\mux11.txt', 'done\\\\mux12.txt', 'done\\\\mux13.txt', 'done\\\\mux14.txt', 'done\\\\mux15.txt', 'done\\\\mux16.txt', 'done\\\\mux17.txt', 'done\\\\mux18.txt', 'done\\\\mux19.txt', 'done\\\\mux2.txt', 'done\\\\mux20.txt', 'done\\\\mux21.txt', 'done\\\\mux22.txt', 'done\\\\mux23.txt', 'done\\\\mux24.txt', 'done\\\\mux25.txt', 'done\\\\mux26.txt', 'done\\\\mux3.txt', 'done\\\\mux4.txt', 'done\\\\mux5.txt', 'done\\\\mux6.txt', 'done\\\\mux7.txt', 'done\\\\mux8.txt', 'done\\\\mux9.txt', 'done\\\\pe1.txt', 'done\\\\pe14.txt', 'done\\\\pe15.txt', 'done\\\\pe16.txt', 'done\\\\pe17.txt', 'done\\\\pe18.txt', 'done\\\\pe19.txt', 'done\\\\pe2.txt', 'done\\\\pe20.txt', 'done\\\\pe21.txt', 'done\\\\pe22.txt', 'done\\\\pe3.txt', 'done\\\\pe4.txt', 'done\\\\pe5.txt', 'done\\\\pe6.txt', 'done\\\\pe7.txt', 'done\\\\sub1.txt', 'done\\\\sub10.txt', 'done\\\\sub11.txt', 'done\\\\sub12.txt', 'done\\\\sub2.txt', 'done\\\\sub5.txt', 'done\\\\sub7.txt', 'done\\\\sub8.txt', 'done\\\\sub9.txt']\n",
      "164\n"
     ]
    }
   ],
   "source": [
    "def get_files_in_folder(folder_path):\n",
    "    file_list = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            file_list.append(file_path)\n",
    "    return file_list\n",
    "\n",
    "# Replace 'folder_path' with the path to the folder you want to read files from\n",
    "verilog_files = get_files_in_folder(DATA_PATH)\n",
    "with open('verilog_files.txt', 'w') as f:\n",
    "    json.dump(verilog_files, f)\n",
    "\n",
    "print(verilog_files)\n",
    "print(len(verilog_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Shuffle the dataset in-place\n",
    "random.shuffle(verilog_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracting_attributes(verilog_file):\n",
    "    try:\n",
    "        if os.path.isfile(verilog_file):\n",
    "            with open(verilog_file, \"r\") as file:\n",
    "                loaded_data = json.load(file)\n",
    "                nodes = loaded_data[0]\n",
    "                edges = loaded_data[1]\n",
    "                # edge_atr = loaded_data[2]\n",
    "                label = loaded_data[3]\n",
    "                \n",
    "                x = torch.tensor(nodes, dtype=torch.float)\n",
    "                edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "                # edge_atr = torch.tensor(edge_atr, dtype=torch.long)\n",
    "                y = torch.tensor(label, dtype=torch.float)\n",
    "                num_nodes = x.size(0)\n",
    "                # print(num_nodes)\n",
    "                \n",
    "                # Create batch assignment vector (assuming one graph per file)\n",
    "                batch = torch.zeros(num_nodes, dtype=torch.long)\n",
    "                # data = Data(x=x, edge_index=edge_index, edge_attr=edge_atr ,y = y, batch = batch)\n",
    "                data = Data(x=x, edge_index=edge_index, y = y, batch = batch)\n",
    "                return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return e\n",
    "\n",
    "# temp=extracting_attributes(\"./done/adder6.txt\")\n",
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 164 Verilog files.\n",
      "164\n"
     ]
    }
   ],
   "source": [
    "class VerilogDataset(Dataset):  # Using Dataset from torch_geometric\n",
    "    def __init__(self, verilog_files):\n",
    "        print(f\"Loaded {len(verilog_files)} Verilog files.\")\n",
    "        self.verilog_files = verilog_files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.verilog_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        verilog_file = self.verilog_files[idx]\n",
    "        data = extracting_attributes(verilog_file)\n",
    "        return data\n",
    "\n",
    "dataset = VerilogDataset(verilog_files)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\\decoder3.txt\n",
      "done\\decoder3.txt\n"
     ]
    }
   ],
   "source": [
    "print(verilog_files[0])\n",
    "print(dataset.verilog_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data objects are unique.\n"
     ]
    }
   ],
   "source": [
    "def are_all_data_objects_unique(dataset):\n",
    "    data_objects = []\n",
    "    for data in dataset:\n",
    "        if data in data_objects:\n",
    "            return False\n",
    "        data_objects.append(data)\n",
    "    return True\n",
    "\n",
    "# Example usage:\n",
    "is_unique = are_all_data_objects_unique(dataset)\n",
    "if is_unique:\n",
    "    print(\"All data objects are unique.\")\n",
    "else:\n",
    "    print(\"Duplicate data objects found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done\\\\pe22.txt'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = random.randint(0, len(verilog_files))\n",
    "verilog_files[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = dataset[num]\n",
    "data\n",
    "\n",
    "g = nx.Graph()\n",
    "g.add_nodes_from(range(data.num_nodes))\n",
    "edges = data.edge_index.t().tolist()\n",
    "# edge_attrs = {tuple(edge): attr.item() for edge, attr in zip(edges, data.edge_attr)}\n",
    "g.add_edges_from(edges)\n",
    "print(len(edges))\n",
    "\n",
    "# Draw the graph with edge attributes\n",
    "pos = nx.spring_layout(g)  # positions for all nodes\n",
    "nx.draw(g, pos, with_labels=True, node_color='skyblue', node_size=1500, edge_color='k', linewidths=1, font_size=15)\n",
    "nx.draw_networkx_edge_labels(g, pos, font_color='red', font_size=12)  # Add edge labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_num_nodes: 4\n",
      "max_num_nodes: 165\n",
      "mean_num_nodes: 21.76829268292683\n",
      "min_num_edges: 3\n",
      "max_num_edges: 208\n",
      "mean_num_edges: 28.341463414634145\n",
      "mean nodes degree: 1.3019607843137253\n"
     ]
    }
   ],
   "source": [
    "def graph_stat(dataset):\n",
    "    \"\"\"\n",
    "    TODO: calculate the statistics of the ENZYMES dataset.\n",
    "    \n",
    "    Outputs:\n",
    "        min_num_nodes: min number of nodes\n",
    "        max_num_nodes: max number of nodes\n",
    "        mean_num_nodes: average number of nodes\n",
    "        min_num_edges: min number of edges\n",
    "        max_num_edges: max number of edges\n",
    "        mean_num_edges: average number of edges\n",
    "    \"\"\"\n",
    "    # for ind,data in enumerate(dataset):\n",
    "        # print(verilog_files[ind])\n",
    "        # print(data)\n",
    "        # print(len(data.x[1]))\n",
    "        \n",
    "    nodes_edges = [(data.num_nodes, data.num_edges) for data in dataset]\n",
    "    num_nodes, num_edges = list(list(zip(*nodes_edges))[0]), list(list(zip(*nodes_edges))[1])\n",
    "    min_num_nodes = min(num_nodes)\n",
    "    max_num_nodes = max(num_nodes)\n",
    "    mean_num_nodes = np.mean(num_nodes)\n",
    "    min_num_edges = min(num_edges)\n",
    "    max_num_edges = max(num_edges)\n",
    "    mean_num_edges = np.mean(num_edges)\n",
    "    mean_degree = (mean_num_edges)/mean_num_nodes\n",
    "    \n",
    "    print(f\"min_num_nodes: {min_num_nodes}\")\n",
    "    print(f\"max_num_nodes: {max_num_nodes}\")\n",
    "    print(f\"mean_num_nodes: {mean_num_nodes}\")\n",
    "    print(f\"min_num_edges: {min_num_edges}\")\n",
    "    print(f\"max_num_edges: {max_num_edges}\")\n",
    "    print(f\"mean_num_edges: {mean_num_edges}\")\n",
    "    print(f\"mean nodes degree: {mean_degree}\")\n",
    "\n",
    "graph_stat(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    if isinstance(batch[0], Data):\n",
    "        return batch\n",
    "    else:\n",
    "        return default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import random_split\n",
    "\n",
    "# # Define the sizes of training, validation, and test sets\n",
    "# train_size = int(0.7 * len(dataset))  # 70% of the data for training\n",
    "# val_size = int(0.15 * len(dataset))   # 15% of the data for validation\n",
    "# test_size = len(dataset) - train_size - val_size  # Remaining data for testing\n",
    "\n",
    "# # Split the dataset into training, validation, and test sets\n",
    "# train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# # Create DataLoader for each set\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "\n",
    "# Define the size of the training set (e.g., 70% of the data)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "\n",
    "# Calculate the size of the testing set\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoader for each set\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=custom_collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=custom_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[11, 17], edge_index=[2, 14], y=[1, 9], batch=[11])\n"
     ]
    }
   ],
   "source": [
    "# len(train_loader.dataset)\n",
    "print(train_loader.dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_iter = iter(train_loader)\n",
    "batch = next(loader_iter)\n",
    "# print(batch)\n",
    "# print(batch.num_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConv(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNConv, self).__init__()\n",
    "        self.theta = nn.Parameter(torch.FloatTensor(in_channels, out_channels))\n",
    "        # Initialize the parameters.\n",
    "        stdv = 1. / math.sqrt(out_channels)\n",
    "        self.theta.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "            1. Generate the adjacency matrix with self-loop \\hat{A} using edge_index.\n",
    "            2. Calculate the diagonal degree matrix \\hat{D}.\n",
    "            3. Calculate the output X' with torch.mm using the equation above.\n",
    "        \"\"\"\n",
    "\n",
    "        num_nodes = x.shape[0]\n",
    "        A = torch.sparse_coo_tensor(edge_index, torch.ones(edge_index.shape[1]), (num_nodes, num_nodes))\n",
    "        A = A.to_dense()\n",
    "        A_hat = A + torch.eye(num_nodes)\n",
    "        \n",
    "        A_sum = torch.sum(A_hat, dim=1)\n",
    "        D = torch.pow(A_sum, -0.5)\n",
    "        D[D == float('inf')] = 0.0\n",
    "        D_hat_sqrt = torch.diag(D)\n",
    "        \n",
    "        first = torch.mm(torch.mm(D_hat_sqrt, A_hat), D_hat_sqrt)\n",
    "        second = torch.mm(x, self.theta)\n",
    "        \n",
    "        ret = torch.mm(first, second)\n",
    "        \n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (gcn1): GCNConv()\n",
       "  (a1): ReLU()\n",
       "  (gcn2): GCNConv()\n",
       "  (a2): ReLU()\n",
       "  (gcn3): GCNConv()\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (linear): Linear(in_features=128, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from torch_geometric.nn import GCNConv\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "            1. Define the first convolution layer using `GCNConv()`. Set `out_channels` to 64;\n",
    "            2. Define the first activation layer using `nn.ReLU()`;\n",
    "            3. Define the second convolution layer using `GCNConv()`. Set `out_channels` to 64;\n",
    "            4. Define the second activation layer using `nn.ReLU()`;\n",
    "            5. Define the third convolution layer using `GCNConv()`. Set `out_channels` to 64;\n",
    "            6. Define the dropout layer using `nn.Dropout()`;\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        num_node_features = 17\n",
    "        num_output_classes = 9\n",
    "        \n",
    "        # num_channels = 32\n",
    "        \n",
    "        self.gcn1 = GCNConv(in_channels=num_node_features, out_channels=128)\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.gcn2 = GCNConv(in_channels= 128, out_channels=128)\n",
    "        self.a2 = nn.ReLU()\n",
    "        self.gcn3 = GCNConv(in_channels=128, out_channels=128)\n",
    "        # self.a3 = nn.ReLU()\n",
    "        # self.gcn4 = GCNConv(in_channels=128, out_channels=128)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.linear = nn.Linear(in_features=128, out_features=num_output_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "    \n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = self.a1(x)\n",
    "        x = self.gcn2(x, edge_index)\n",
    "        x = self.a2(x)\n",
    "        x = self.gcn3(x, edge_index)\n",
    "        # x = self.a3(x)\n",
    "        # x = self.gcn4(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        probs = torch.nn.functional.softmax(x, dim=-1)\n",
    "        \n",
    "        return probs\n",
    "        \n",
    "        \n",
    "        \n",
    "GCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.2281, Test Acc: 0.1000\n",
      "Epoch: 002, Train Acc: 0.3246, Test Acc: 0.3200\n",
      "Epoch: 003, Train Acc: 0.3333, Test Acc: 0.3200\n",
      "Epoch: 004, Train Acc: 0.4211, Test Acc: 0.3000\n",
      "Epoch: 005, Train Acc: 0.4123, Test Acc: 0.2600\n",
      "Epoch: 006, Train Acc: 0.4211, Test Acc: 0.2600\n",
      "Epoch: 007, Train Acc: 0.4211, Test Acc: 0.2600\n",
      "Epoch: 008, Train Acc: 0.4298, Test Acc: 0.2600\n",
      "Epoch: 009, Train Acc: 0.4386, Test Acc: 0.2600\n",
      "Epoch: 010, Train Acc: 0.4298, Test Acc: 0.2800\n",
      "Epoch: 011, Train Acc: 0.4825, Test Acc: 0.3800\n",
      "Epoch: 012, Train Acc: 0.5000, Test Acc: 0.3800\n",
      "Epoch: 013, Train Acc: 0.5088, Test Acc: 0.3800\n",
      "Epoch: 014, Train Acc: 0.5088, Test Acc: 0.3600\n",
      "Epoch: 015, Train Acc: 0.5351, Test Acc: 0.4400\n",
      "Epoch: 016, Train Acc: 0.5351, Test Acc: 0.4000\n",
      "Epoch: 017, Train Acc: 0.5263, Test Acc: 0.4000\n",
      "Epoch: 018, Train Acc: 0.5351, Test Acc: 0.4200\n",
      "Epoch: 019, Train Acc: 0.5351, Test Acc: 0.3800\n",
      "Epoch: 020, Train Acc: 0.5526, Test Acc: 0.4400\n",
      "Epoch: 021, Train Acc: 0.5439, Test Acc: 0.4000\n",
      "Epoch: 022, Train Acc: 0.5614, Test Acc: 0.4000\n",
      "Epoch: 023, Train Acc: 0.5351, Test Acc: 0.3800\n",
      "Epoch: 024, Train Acc: 0.5702, Test Acc: 0.4200\n",
      "Epoch: 025, Train Acc: 0.5614, Test Acc: 0.4000\n",
      "Epoch: 026, Train Acc: 0.5877, Test Acc: 0.4800\n",
      "Epoch: 027, Train Acc: 0.5877, Test Acc: 0.4800\n",
      "Epoch: 028, Train Acc: 0.5702, Test Acc: 0.4200\n",
      "Epoch: 029, Train Acc: 0.5702, Test Acc: 0.4200\n",
      "Epoch: 030, Train Acc: 0.5702, Test Acc: 0.4800\n",
      "Epoch: 031, Train Acc: 0.5702, Test Acc: 0.4200\n",
      "Epoch: 032, Train Acc: 0.5702, Test Acc: 0.4200\n",
      "Epoch: 033, Train Acc: 0.5789, Test Acc: 0.4800\n",
      "Epoch: 034, Train Acc: 0.5614, Test Acc: 0.3800\n",
      "Epoch: 035, Train Acc: 0.5614, Test Acc: 0.3800\n",
      "Epoch: 036, Train Acc: 0.5965, Test Acc: 0.4200\n",
      "Epoch: 037, Train Acc: 0.4912, Test Acc: 0.4000\n",
      "Epoch: 038, Train Acc: 0.5614, Test Acc: 0.3800\n",
      "Epoch: 039, Train Acc: 0.5789, Test Acc: 0.3800\n",
      "Epoch: 040, Train Acc: 0.5877, Test Acc: 0.4800\n",
      "Epoch: 041, Train Acc: 0.5702, Test Acc: 0.4200\n",
      "Epoch: 042, Train Acc: 0.5877, Test Acc: 0.4800\n",
      "Epoch: 043, Train Acc: 0.5877, Test Acc: 0.4800\n",
      "Epoch: 044, Train Acc: 0.5789, Test Acc: 0.4800\n",
      "Epoch: 045, Train Acc: 0.5702, Test Acc: 0.4200\n",
      "Epoch: 046, Train Acc: 0.5614, Test Acc: 0.4200\n",
      "Epoch: 047, Train Acc: 0.5965, Test Acc: 0.4200\n",
      "Epoch: 048, Train Acc: 0.5614, Test Acc: 0.3800\n",
      "Epoch: 049, Train Acc: 0.5351, Test Acc: 0.4200\n",
      "Epoch: 050, Train Acc: 0.5965, Test Acc: 0.4200\n",
      "Epoch: 051, Train Acc: 0.5965, Test Acc: 0.4400\n",
      "Epoch: 052, Train Acc: 0.5965, Test Acc: 0.4800\n",
      "Epoch: 053, Train Acc: 0.6053, Test Acc: 0.4600\n",
      "Epoch: 054, Train Acc: 0.5965, Test Acc: 0.4600\n",
      "Epoch: 055, Train Acc: 0.5526, Test Acc: 0.3800\n",
      "Epoch: 056, Train Acc: 0.5877, Test Acc: 0.4400\n",
      "Epoch: 057, Train Acc: 0.5789, Test Acc: 0.3800\n",
      "Epoch: 058, Train Acc: 0.5789, Test Acc: 0.4000\n",
      "Epoch: 059, Train Acc: 0.5614, Test Acc: 0.3800\n",
      "Epoch: 060, Train Acc: 0.5965, Test Acc: 0.4400\n",
      "Epoch: 061, Train Acc: 0.5877, Test Acc: 0.4400\n",
      "Epoch: 062, Train Acc: 0.5702, Test Acc: 0.3800\n",
      "Epoch: 063, Train Acc: 0.5877, Test Acc: 0.4200\n",
      "Epoch: 064, Train Acc: 0.6053, Test Acc: 0.4800\n",
      "Epoch: 065, Train Acc: 0.5877, Test Acc: 0.4800\n",
      "Epoch: 066, Train Acc: 0.5877, Test Acc: 0.4200\n",
      "Epoch: 067, Train Acc: 0.5789, Test Acc: 0.4800\n",
      "Epoch: 068, Train Acc: 0.5965, Test Acc: 0.4200\n",
      "Epoch: 069, Train Acc: 0.5263, Test Acc: 0.4200\n",
      "Epoch: 070, Train Acc: 0.5614, Test Acc: 0.4600\n",
      "Epoch: 071, Train Acc: 0.5789, Test Acc: 0.4400\n",
      "Epoch: 072, Train Acc: 0.6053, Test Acc: 0.4800\n",
      "Epoch: 073, Train Acc: 0.6053, Test Acc: 0.4600\n",
      "Epoch: 074, Train Acc: 0.5965, Test Acc: 0.4600\n",
      "Epoch: 075, Train Acc: 0.6053, Test Acc: 0.4600\n",
      "Epoch: 076, Train Acc: 0.5789, Test Acc: 0.4600\n",
      "Epoch: 077, Train Acc: 0.6053, Test Acc: 0.4800\n",
      "Epoch: 078, Train Acc: 0.6053, Test Acc: 0.4400\n",
      "Epoch: 079, Train Acc: 0.5614, Test Acc: 0.4600\n",
      "Epoch: 080, Train Acc: 0.5877, Test Acc: 0.4200\n",
      "Epoch: 081, Train Acc: 0.5965, Test Acc: 0.4000\n",
      "Epoch: 082, Train Acc: 0.5614, Test Acc: 0.4000\n",
      "Epoch: 083, Train Acc: 0.5877, Test Acc: 0.4800\n",
      "Epoch: 084, Train Acc: 0.5877, Test Acc: 0.4800\n",
      "Epoch: 085, Train Acc: 0.5877, Test Acc: 0.4800\n",
      "Epoch: 086, Train Acc: 0.5789, Test Acc: 0.4800\n",
      "Epoch: 087, Train Acc: 0.6140, Test Acc: 0.4600\n",
      "Epoch: 088, Train Acc: 0.6053, Test Acc: 0.4600\n",
      "Epoch: 089, Train Acc: 0.5965, Test Acc: 0.4200\n",
      "Epoch: 090, Train Acc: 0.6140, Test Acc: 0.4600\n",
      "Epoch: 091, Train Acc: 0.5877, Test Acc: 0.4800\n",
      "Epoch: 092, Train Acc: 0.5789, Test Acc: 0.4800\n",
      "Epoch: 093, Train Acc: 0.5789, Test Acc: 0.4800\n",
      "Epoch: 094, Train Acc: 0.6053, Test Acc: 0.4800\n",
      "Epoch: 095, Train Acc: 0.6140, Test Acc: 0.4800\n",
      "Epoch: 096, Train Acc: 0.5877, Test Acc: 0.4200\n",
      "Epoch: 097, Train Acc: 0.6053, Test Acc: 0.4600\n",
      "Epoch: 098, Train Acc: 0.5965, Test Acc: 0.4600\n",
      "Epoch: 099, Train Acc: 0.6140, Test Acc: 0.4800\n",
      "Epoch: 100, Train Acc: 0.5702, Test Acc: 0.4400\n",
      "Epoch: 101, Train Acc: 0.5789, Test Acc: 0.4800\n",
      "Epoch: 102, Train Acc: 0.5877, Test Acc: 0.4000\n",
      "Epoch: 103, Train Acc: 0.5877, Test Acc: 0.4600\n",
      "Epoch: 104, Train Acc: 0.5439, Test Acc: 0.4400\n",
      "Epoch: 105, Train Acc: 0.5789, Test Acc: 0.4600\n",
      "Epoch: 106, Train Acc: 0.5702, Test Acc: 0.4200\n",
      "Epoch: 107, Train Acc: 0.5965, Test Acc: 0.4800\n",
      "Epoch: 108, Train Acc: 0.6053, Test Acc: 0.4200\n",
      "Epoch: 109, Train Acc: 0.5789, Test Acc: 0.4400\n",
      "Epoch: 110, Train Acc: 0.6140, Test Acc: 0.4600\n",
      "Epoch: 111, Train Acc: 0.5877, Test Acc: 0.4200\n",
      "Epoch: 112, Train Acc: 0.5965, Test Acc: 0.4200\n",
      "Epoch: 113, Train Acc: 0.5965, Test Acc: 0.4200\n",
      "Epoch: 114, Train Acc: 0.5614, Test Acc: 0.4200\n",
      "Epoch: 115, Train Acc: 0.6053, Test Acc: 0.4200\n",
      "Epoch: 116, Train Acc: 0.6053, Test Acc: 0.4400\n",
      "Epoch: 117, Train Acc: 0.6053, Test Acc: 0.4200\n",
      "Epoch: 118, Train Acc: 0.5877, Test Acc: 0.4200\n",
      "Epoch: 119, Train Acc: 0.5702, Test Acc: 0.4400\n",
      "Epoch: 120, Train Acc: 0.6053, Test Acc: 0.4800\n",
      "Epoch: 121, Train Acc: 0.6140, Test Acc: 0.4200\n",
      "Epoch: 122, Train Acc: 0.6140, Test Acc: 0.4800\n",
      "Epoch: 123, Train Acc: 0.6228, Test Acc: 0.4800\n",
      "Epoch: 124, Train Acc: 0.5877, Test Acc: 0.4600\n",
      "Epoch: 125, Train Acc: 0.6053, Test Acc: 0.4800\n",
      "Epoch: 126, Train Acc: 0.5877, Test Acc: 0.4800\n",
      "Epoch: 127, Train Acc: 0.5702, Test Acc: 0.5000\n",
      "Epoch: 128, Train Acc: 0.5965, Test Acc: 0.4800\n",
      "Epoch: 129, Train Acc: 0.6053, Test Acc: 0.4800\n",
      "Epoch: 130, Train Acc: 0.6228, Test Acc: 0.4800\n",
      "Epoch: 131, Train Acc: 0.6228, Test Acc: 0.4600\n",
      "Epoch: 132, Train Acc: 0.6404, Test Acc: 0.5200\n",
      "Epoch: 133, Train Acc: 0.6228, Test Acc: 0.4600\n",
      "Epoch: 134, Train Acc: 0.6316, Test Acc: 0.4800\n",
      "Epoch: 135, Train Acc: 0.6404, Test Acc: 0.4600\n",
      "Epoch: 136, Train Acc: 0.6491, Test Acc: 0.4800\n",
      "Epoch: 137, Train Acc: 0.5614, Test Acc: 0.5000\n",
      "Epoch: 138, Train Acc: 0.5702, Test Acc: 0.5000\n",
      "Epoch: 139, Train Acc: 0.6228, Test Acc: 0.5200\n",
      "Epoch: 140, Train Acc: 0.6316, Test Acc: 0.5400\n",
      "Epoch: 141, Train Acc: 0.6579, Test Acc: 0.5200\n",
      "Epoch: 142, Train Acc: 0.6491, Test Acc: 0.4800\n",
      "Epoch: 143, Train Acc: 0.6579, Test Acc: 0.5000\n",
      "Epoch: 144, Train Acc: 0.6579, Test Acc: 0.4800\n",
      "Epoch: 145, Train Acc: 0.6579, Test Acc: 0.4800\n",
      "Epoch: 146, Train Acc: 0.6579, Test Acc: 0.5400\n",
      "Epoch: 147, Train Acc: 0.6053, Test Acc: 0.5000\n",
      "Epoch: 148, Train Acc: 0.5965, Test Acc: 0.5000\n",
      "Epoch: 149, Train Acc: 0.6316, Test Acc: 0.4600\n",
      "Epoch: 150, Train Acc: 0.6579, Test Acc: 0.5200\n",
      "Epoch: 151, Train Acc: 0.6579, Test Acc: 0.5200\n",
      "Epoch: 152, Train Acc: 0.6579, Test Acc: 0.5200\n",
      "Epoch: 153, Train Acc: 0.6579, Test Acc: 0.5200\n",
      "Epoch: 154, Train Acc: 0.6667, Test Acc: 0.5200\n",
      "Epoch: 155, Train Acc: 0.6579, Test Acc: 0.5200\n",
      "Epoch: 156, Train Acc: 0.6579, Test Acc: 0.5200\n",
      "Epoch: 157, Train Acc: 0.6491, Test Acc: 0.5000\n",
      "Epoch: 158, Train Acc: 0.5877, Test Acc: 0.4400\n",
      "Epoch: 159, Train Acc: 0.6316, Test Acc: 0.4600\n",
      "Epoch: 160, Train Acc: 0.6228, Test Acc: 0.4600\n",
      "Epoch: 161, Train Acc: 0.6053, Test Acc: 0.4600\n",
      "Epoch: 162, Train Acc: 0.6053, Test Acc: 0.4600\n",
      "Epoch: 163, Train Acc: 0.6053, Test Acc: 0.4600\n",
      "Epoch: 164, Train Acc: 0.5702, Test Acc: 0.5000\n",
      "Epoch: 165, Train Acc: 0.5439, Test Acc: 0.4600\n",
      "Epoch: 166, Train Acc: 0.6316, Test Acc: 0.5400\n",
      "Epoch: 167, Train Acc: 0.6404, Test Acc: 0.5200\n",
      "Epoch: 168, Train Acc: 0.6404, Test Acc: 0.5200\n",
      "Epoch: 169, Train Acc: 0.6491, Test Acc: 0.5200\n",
      "Epoch: 170, Train Acc: 0.6667, Test Acc: 0.5400\n",
      "Epoch: 171, Train Acc: 0.6579, Test Acc: 0.4600\n",
      "Epoch: 172, Train Acc: 0.6579, Test Acc: 0.5200\n",
      "Epoch: 173, Train Acc: 0.6404, Test Acc: 0.4800\n",
      "Epoch: 174, Train Acc: 0.6491, Test Acc: 0.5000\n",
      "Epoch: 175, Train Acc: 0.6579, Test Acc: 0.5400\n",
      "Epoch: 176, Train Acc: 0.6579, Test Acc: 0.5400\n",
      "Epoch: 177, Train Acc: 0.6579, Test Acc: 0.5400\n",
      "Epoch: 178, Train Acc: 0.6579, Test Acc: 0.5400\n",
      "Epoch: 179, Train Acc: 0.6667, Test Acc: 0.5000\n",
      "Epoch: 180, Train Acc: 0.6667, Test Acc: 0.5000\n",
      "Epoch: 181, Train Acc: 0.6579, Test Acc: 0.4800\n",
      "Epoch: 182, Train Acc: 0.6579, Test Acc: 0.5200\n",
      "Epoch: 183, Train Acc: 0.6579, Test Acc: 0.5200\n",
      "Epoch: 184, Train Acc: 0.6667, Test Acc: 0.5200\n",
      "Epoch: 185, Train Acc: 0.6667, Test Acc: 0.5200\n",
      "Epoch: 186, Train Acc: 0.6579, Test Acc: 0.5200\n",
      "Epoch: 187, Train Acc: 0.6579, Test Acc: 0.5200\n",
      "Epoch: 188, Train Acc: 0.6667, Test Acc: 0.5200\n",
      "Epoch: 189, Train Acc: 0.6667, Test Acc: 0.5200\n",
      "Epoch: 190, Train Acc: 0.6316, Test Acc: 0.5400\n",
      "Epoch: 191, Train Acc: 0.6316, Test Acc: 0.5400\n",
      "Epoch: 192, Train Acc: 0.6491, Test Acc: 0.5400\n",
      "Epoch: 193, Train Acc: 0.6316, Test Acc: 0.4800\n",
      "Epoch: 194, Train Acc: 0.6491, Test Acc: 0.5400\n",
      "Epoch: 195, Train Acc: 0.6404, Test Acc: 0.5400\n",
      "Epoch: 196, Train Acc: 0.6404, Test Acc: 0.5000\n",
      "Epoch: 197, Train Acc: 0.6404, Test Acc: 0.5000\n",
      "Epoch: 198, Train Acc: 0.6404, Test Acc: 0.5200\n",
      "Epoch: 199, Train Acc: 0.6404, Test Acc: 0.5200\n",
      "Epoch: 200, Train Acc: 0.6404, Test Acc: 0.5200\n",
      "Training duration: 256.8498830795288 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gcn = GCN()\n",
    "\n",
    "# print(gcn.parameters())\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(gcn.parameters(), lr=0.001)\n",
    "# loss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "out_labels = []\n",
    "\n",
    "def train(train_loader):\n",
    "    gcn.train()\n",
    "    # print(gcn.parameters())\n",
    "    for batch_data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        for data in batch_data:\n",
    "            # print(data.x, data.edge_index, data.batch, data.y)\n",
    "            out = gcn(data.x, data.edge_index, data.batch)\n",
    "            # pred = out.argmax(dim=1)\n",
    "            # pred_out = torch.tensor(pred, dtype=torch.float16)\n",
    "            # print(out)\n",
    "            # print(data.y)\n",
    "            out_labels.append((out, data.y))\n",
    "            loss = criterion(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "testing_labels = []\n",
    "def test(loader):\n",
    "    gcn.eval()\n",
    "    correct = 0\n",
    "    for batch_data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        for data in batch_data:\n",
    "            out = gcn(data.x, data.edge_index, data.batch)  \n",
    "            pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "            testing_labels.append(pred)\n",
    "            y_label = (data.y.tolist())\n",
    "            y_label = y_label[0].index(1.0)\n",
    "            pred_label = (pred.tolist())[0]\n",
    "            # print(pred_label)\n",
    "            # print(y_label)\n",
    "            if y_label == pred_label:\n",
    "                correct += 1            \n",
    "            # correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Your training code here\n",
    "for epoch in range(200):\n",
    "    train(train_loader)\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch + 1:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the duration\n",
    "duration = end_time - start_time\n",
    "print(\"Training duration:\", duration, \"seconds\")\n",
    "# with open(\"out_labels.txt\", \"w\") as output:\n",
    "#         output.write(str(out_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gcn.state_dict(), 'gcn_model8.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\\comparator16.txt\n",
      "tensor([2])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "num = random.randint(0, len(verilog_files))\n",
    "print(verilog_files[num])\n",
    "data_trial = dataset[num]\n",
    "\n",
    "out = gcn(data_trial.x, data_trial.edge_index, data_trial.batch)\n",
    "pred = out.argmax(dim=1)\n",
    "print(pred)\n",
    "print((data_trial.y.tolist())[0].index(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[0.1118, 0.1097, 0.1018, 0.1003, 0.1178, 0.1129, 0.1081, 0.1210, 0.1167]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1059, 0.1114, 0.1021, 0.0979, 0.1187, 0.1096, 0.1097, 0.1217, 0.1228]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1078, 0.1124, 0.1022, 0.1001, 0.1166, 0.1129, 0.1110, 0.1191, 0.1179]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1095, 0.1032, 0.0960, 0.0981, 0.1257, 0.1091, 0.1091, 0.1260, 0.1233]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1096, 0.1091, 0.1006, 0.1017, 0.1147, 0.1134, 0.1094, 0.1264, 0.1150]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1065, 0.1128, 0.0992, 0.1019, 0.1142, 0.1175, 0.1083, 0.1225, 0.1171]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1139, 0.1077, 0.0977, 0.0989, 0.1158, 0.1183, 0.1071, 0.1264, 0.1142]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1071, 0.1127, 0.0988, 0.0998, 0.1145, 0.1159, 0.1104, 0.1251, 0.1158]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1081, 0.1133, 0.1001, 0.0981, 0.1155, 0.1141, 0.1137, 0.1236, 0.1135]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1088, 0.1155, 0.0976, 0.0986, 0.1130, 0.1117, 0.1142, 0.1264, 0.1141]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1208, 0.1097, 0.0887, 0.0928, 0.1110, 0.1075, 0.1250, 0.1413, 0.1031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1085, 0.1138, 0.0930, 0.0979, 0.1097, 0.1154, 0.1200, 0.1291, 0.1126]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1081, 0.1128, 0.0957, 0.0979, 0.1128, 0.1196, 0.1140, 0.1266, 0.1124]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1090, 0.1068, 0.0943, 0.0958, 0.1132, 0.1194, 0.1234, 0.1300, 0.1082]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1004, 0.1046, 0.0898, 0.0919, 0.1132, 0.1343, 0.1389, 0.1294, 0.0975]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1079, 0.1126, 0.0969, 0.1008, 0.1130, 0.1213, 0.1146, 0.1225, 0.1105]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1040, 0.1074, 0.0939, 0.0977, 0.1184, 0.1195, 0.1201, 0.1306, 0.1084]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1021, 0.1103, 0.1021, 0.1021, 0.1165, 0.1199, 0.1178, 0.1211, 0.1080]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1002, 0.0999, 0.0859, 0.1045, 0.1209, 0.1353, 0.1212, 0.1336, 0.0984]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1004, 0.1164, 0.0946, 0.0977, 0.1220, 0.1182, 0.1215, 0.1242, 0.1049]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1010, 0.1056, 0.0961, 0.0998, 0.1263, 0.1173, 0.1179, 0.1289, 0.1071]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.1034, 0.1058, 0.0977, 0.1001, 0.1193, 0.1232, 0.1170, 0.1245, 0.1091]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1033, 0.1066, 0.0917, 0.0978, 0.1267, 0.1307, 0.1195, 0.1241, 0.0995]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0995, 0.1101, 0.1022, 0.1006, 0.1219, 0.1193, 0.1169, 0.1203, 0.1091]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0970, 0.0955, 0.0993, 0.1000, 0.1293, 0.1240, 0.1209, 0.1316, 0.1024]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0919, 0.1066, 0.1006, 0.1029, 0.1235, 0.1216, 0.1224, 0.1208, 0.1096]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0944, 0.1025, 0.0988, 0.1020, 0.1265, 0.1249, 0.1308, 0.1184, 0.1018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0939, 0.1065, 0.1001, 0.1006, 0.1239, 0.1316, 0.1233, 0.1226, 0.0977]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1071, 0.1068, 0.0978, 0.1007, 0.1220, 0.1242, 0.1130, 0.1208, 0.1075]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1054, 0.1044, 0.1000, 0.1063, 0.1206, 0.1223, 0.1200, 0.1145, 0.1065]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0974, 0.1064, 0.1047, 0.1030, 0.1266, 0.1324, 0.1208, 0.1124, 0.0964]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0944, 0.1041, 0.1022, 0.0993, 0.1326, 0.1246, 0.1262, 0.1162, 0.1004]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0994, 0.1075, 0.1058, 0.1002, 0.1237, 0.1211, 0.1149, 0.1195, 0.1079]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0977, 0.0997, 0.1061, 0.0960, 0.1364, 0.1253, 0.1237, 0.1167, 0.0984]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0930, 0.1051, 0.1022, 0.0985, 0.1289, 0.1288, 0.1202, 0.1214, 0.1020]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0978, 0.1062, 0.1025, 0.0984, 0.1281, 0.1220, 0.1145, 0.1218, 0.1087]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0997, 0.1020, 0.1038, 0.1034, 0.1270, 0.1244, 0.1114, 0.1260, 0.1022]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0759, 0.0706, 0.1188, 0.1135, 0.1482, 0.1511, 0.1388, 0.1186, 0.0643]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0805, 0.0973, 0.1074, 0.0960, 0.1498, 0.1348, 0.1199, 0.1220, 0.0925]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0894, 0.0933, 0.1086, 0.1078, 0.1390, 0.1399, 0.1188, 0.1172, 0.0860]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0858, 0.1033, 0.1062, 0.1049, 0.1399, 0.1306, 0.1281, 0.1101, 0.0910]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0884, 0.0970, 0.1113, 0.1019, 0.1403, 0.1238, 0.1221, 0.1135, 0.1018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0979, 0.1051, 0.1036, 0.1089, 0.1342, 0.1239, 0.1208, 0.1134, 0.0922]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0926, 0.1024, 0.1066, 0.0980, 0.1387, 0.1230, 0.1176, 0.1191, 0.1021]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0728, 0.0866, 0.1092, 0.1093, 0.1527, 0.1318, 0.1412, 0.1135, 0.0829]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0647, 0.0729, 0.1220, 0.1259, 0.1680, 0.1497, 0.1247, 0.1015, 0.0706]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0875, 0.0965, 0.1112, 0.1158, 0.1427, 0.1351, 0.1272, 0.1067, 0.0772]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0951, 0.1059, 0.1139, 0.1059, 0.1449, 0.1223, 0.1218, 0.1043, 0.0860]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0815, 0.0841, 0.1227, 0.1163, 0.1655, 0.1343, 0.1398, 0.0931, 0.0628]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0928, 0.0950, 0.1144, 0.1094, 0.1429, 0.1284, 0.1221, 0.1065, 0.0884]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0831, 0.0934, 0.1097, 0.1119, 0.1585, 0.1274, 0.1259, 0.1127, 0.0774]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0792, 0.0763, 0.1274, 0.1077, 0.1611, 0.1331, 0.1588, 0.0936, 0.0628]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0915, 0.0899, 0.1135, 0.1170, 0.1493, 0.1277, 0.1354, 0.1039, 0.0718]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0563, 0.0535, 0.1198, 0.1389, 0.2035, 0.1588, 0.1424, 0.0878, 0.0389]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0815, 0.0586, 0.1195, 0.1449, 0.1896, 0.1302, 0.1423, 0.0831, 0.0502]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0813, 0.0809, 0.1272, 0.1156, 0.1574, 0.1325, 0.1383, 0.0939, 0.0729]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0705, 0.0663, 0.1214, 0.1423, 0.1719, 0.1237, 0.1695, 0.0827, 0.0517]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0589, 0.0549, 0.1517, 0.1126, 0.2043, 0.1377, 0.1818, 0.0606, 0.0376]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0811, 0.0663, 0.1082, 0.1254, 0.1625, 0.1573, 0.1661, 0.0928, 0.0404]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0783, 0.0715, 0.1137, 0.1247, 0.1709, 0.1421, 0.1617, 0.0913, 0.0457]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0697, 0.0553, 0.1361, 0.1254, 0.1759, 0.1472, 0.1726, 0.0755, 0.0423]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0853, 0.0426, 0.1335, 0.1308, 0.1678, 0.1615, 0.1717, 0.0825, 0.0242]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0614, 0.0519, 0.1104, 0.1750, 0.1683, 0.1925, 0.1534, 0.0631, 0.0240]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1032, 0.0836, 0.1148, 0.1244, 0.1465, 0.1387, 0.1373, 0.0882, 0.0632]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0904, 0.0638, 0.1120, 0.1380, 0.1465, 0.1600, 0.1571, 0.0868, 0.0454]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0745, 0.0717, 0.1204, 0.1380, 0.1804, 0.1574, 0.1557, 0.0687, 0.0331]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1000, 0.0819, 0.1204, 0.1079, 0.1708, 0.1505, 0.1268, 0.0843, 0.0574]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0896, 0.0675, 0.0923, 0.1379, 0.1691, 0.1610, 0.1472, 0.0805, 0.0549]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0941, 0.0767, 0.1136, 0.1291, 0.1560, 0.1427, 0.1536, 0.0851, 0.0491]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1035, 0.0598, 0.1109, 0.1437, 0.1532, 0.1655, 0.1315, 0.0876, 0.0443]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1138, 0.0710, 0.1010, 0.1349, 0.1380, 0.1734, 0.1204, 0.0932, 0.0543]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0723, 0.0677, 0.1047, 0.1543, 0.1820, 0.1725, 0.1473, 0.0662, 0.0329]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0920, 0.0721, 0.1033, 0.1391, 0.1913, 0.1488, 0.1276, 0.0799, 0.0460]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0911, 0.0236, 0.0775, 0.1725, 0.2374, 0.1754, 0.1570, 0.0548, 0.0108]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0948, 0.0616, 0.1025, 0.1620, 0.1551, 0.1587, 0.1203, 0.0937, 0.0513]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1131, 0.0589, 0.0982, 0.1332, 0.1599, 0.1827, 0.1146, 0.0979, 0.0415]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1069, 0.0462, 0.0937, 0.1657, 0.1639, 0.2076, 0.1072, 0.0775, 0.0313]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1009, 0.0497, 0.1074, 0.1371, 0.1863, 0.1817, 0.1217, 0.0840, 0.0311]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0682, 0.0411, 0.1219, 0.1727, 0.2034, 0.1782, 0.1250, 0.0639, 0.0257]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0885, 0.0495, 0.0845, 0.1705, 0.1931, 0.1843, 0.1153, 0.0839, 0.0305]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.1038, 0.0746, 0.1087, 0.1283, 0.1511, 0.1504, 0.1203, 0.0989, 0.0639]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0852, 0.0559, 0.0919, 0.1503, 0.1910, 0.1766, 0.1086, 0.0968, 0.0437]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1053, 0.0359, 0.0689, 0.2009, 0.2021, 0.2345, 0.0873, 0.0494, 0.0155]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0795, 0.0441, 0.0872, 0.1911, 0.1805, 0.1851, 0.1112, 0.0889, 0.0324]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0901, 0.0695, 0.0852, 0.1489, 0.1709, 0.1846, 0.0929, 0.1001, 0.0578]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0856, 0.0244, 0.0965, 0.1702, 0.2351, 0.2120, 0.0942, 0.0644, 0.0176]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0761, 0.0217, 0.0599, 0.3122, 0.2130, 0.1706, 0.0799, 0.0586, 0.0080]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0545, 0.0231, 0.0607, 0.2487, 0.2486, 0.2047, 0.0734, 0.0669, 0.0194]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0612, 0.0321, 0.0870, 0.1591, 0.2246, 0.2194, 0.0769, 0.1135, 0.0261]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0670, 0.0212, 0.0717, 0.2029, 0.2131, 0.2993, 0.0538, 0.0570, 0.0140]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0848, 0.0477, 0.0873, 0.1673, 0.1955, 0.1916, 0.0871, 0.0989, 0.0398]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0552, 0.0231, 0.0744, 0.1699, 0.3081, 0.2381, 0.0571, 0.0576, 0.0164]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0667, 0.0203, 0.0638, 0.2149, 0.2519, 0.2103, 0.0959, 0.0605, 0.0157]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0118, 0.0008, 0.0140, 0.2004, 0.5902, 0.1593, 0.0165, 0.0063, 0.0007]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0784, 0.0326, 0.0771, 0.1881, 0.2077, 0.2432, 0.0651, 0.0824, 0.0254]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0925, 0.0382, 0.0890, 0.1561, 0.1929, 0.1952, 0.1025, 0.0890, 0.0445]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0711, 0.0280, 0.0647, 0.1724, 0.2174, 0.2565, 0.0845, 0.0768, 0.0286]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0726, 0.0411, 0.0830, 0.1665, 0.2173, 0.2369, 0.0792, 0.0775, 0.0258]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0625, 0.0222, 0.0515, 0.1902, 0.2606, 0.2716, 0.0626, 0.0612, 0.0177]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0996, 0.0570, 0.0846, 0.1522, 0.1587, 0.1976, 0.0883, 0.1083, 0.0536]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0592, 0.0163, 0.0654, 0.2129, 0.2247, 0.2653, 0.0615, 0.0796, 0.0150]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0523, 0.0157, 0.0510, 0.2885, 0.1464, 0.3217, 0.0478, 0.0639, 0.0128]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0633, 0.0196, 0.0512, 0.2280, 0.1892, 0.3098, 0.0608, 0.0628, 0.0154]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0618, 0.0345, 0.0518, 0.2087, 0.2015, 0.2658, 0.0664, 0.0833, 0.0263]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0723, 0.0394, 0.0723, 0.1980, 0.1643, 0.2491, 0.0818, 0.0826, 0.0402]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0521, 0.0138, 0.0384, 0.2750, 0.1628, 0.3084, 0.0752, 0.0610, 0.0133]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0601, 0.0225, 0.0484, 0.2307, 0.1562, 0.3211, 0.0638, 0.0738, 0.0234]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0773, 0.0448, 0.0561, 0.2191, 0.1630, 0.2269, 0.0956, 0.0860, 0.0311]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0772, 0.0329, 0.0621, 0.2126, 0.1566, 0.2672, 0.0750, 0.0887, 0.0278]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0386, 0.0144, 0.0476, 0.2886, 0.1676, 0.3017, 0.0686, 0.0598, 0.0131]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0658, 0.0307, 0.0504, 0.2885, 0.1422, 0.2786, 0.0624, 0.0619, 0.0195]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0740, 0.0269, 0.0589, 0.2084, 0.1286, 0.2891, 0.0651, 0.1186, 0.0304]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0413, 0.0104, 0.0237, 0.2941, 0.0720, 0.4639, 0.0421, 0.0444, 0.0082]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0376, 0.0122, 0.0444, 0.3157, 0.1440, 0.3306, 0.0552, 0.0511, 0.0093]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0567, 0.0206, 0.0489, 0.2647, 0.1004, 0.3248, 0.0866, 0.0805, 0.0168]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0167, 0.0035, 0.0113, 0.3528, 0.0509, 0.4943, 0.0338, 0.0349, 0.0018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0424, 0.0180, 0.0320, 0.3218, 0.0776, 0.3445, 0.0602, 0.0920, 0.0115]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0423, 0.0183, 0.0389, 0.2447, 0.0965, 0.4033, 0.0743, 0.0709, 0.0107]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0227, 0.0031, 0.0160, 0.4263, 0.0451, 0.3910, 0.0464, 0.0463, 0.0031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0633, 0.0197, 0.0352, 0.2251, 0.0817, 0.4386, 0.0404, 0.0780, 0.0181]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.2967e-03, 3.0514e-04, 2.0014e-03, 1.5553e-01, 7.2512e-03, 8.1690e-01,\n",
       "           9.0341e-03, 6.6130e-03, 6.8204e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0160, 0.0048, 0.0108, 0.2517, 0.0270, 0.6313, 0.0183, 0.0374, 0.0027]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0218, 0.0034, 0.0113, 0.2594, 0.0311, 0.6152, 0.0244, 0.0303, 0.0031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0421, 0.0123, 0.0342, 0.2747, 0.0854, 0.4173, 0.0630, 0.0620, 0.0091]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0105, 0.0009, 0.0044, 0.3423, 0.0098, 0.5994, 0.0120, 0.0200, 0.0006]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0441, 0.0102, 0.0225, 0.2536, 0.0616, 0.4867, 0.0705, 0.0429, 0.0079]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0467, 0.0168, 0.0254, 0.2354, 0.0877, 0.4852, 0.0450, 0.0477, 0.0102]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0857, 0.0320, 0.0451, 0.2063, 0.0737, 0.3835, 0.0722, 0.0753, 0.0263]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0107, 0.0011, 0.0042, 0.1618, 0.0138, 0.7829, 0.0092, 0.0152, 0.0011]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0242, 0.0096, 0.0235, 0.1577, 0.0781, 0.6078, 0.0467, 0.0437, 0.0086]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0210, 0.0051, 0.0193, 0.0960, 0.0370, 0.7492, 0.0304, 0.0382, 0.0038]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0413, 0.0133, 0.0331, 0.1980, 0.0813, 0.5237, 0.0415, 0.0568, 0.0111]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0428, 0.0267, 0.0480, 0.1580, 0.1125, 0.4335, 0.0817, 0.0763, 0.0206]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0555, 0.0151, 0.0317, 0.1643, 0.0679, 0.5386, 0.0625, 0.0497, 0.0146]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0107, 0.0018, 0.0122, 0.1424, 0.0372, 0.7502, 0.0222, 0.0223, 0.0010]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0197, 0.0044, 0.0104, 0.1213, 0.0348, 0.7547, 0.0367, 0.0160, 0.0019]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0420, 0.0072, 0.0246, 0.1530, 0.0494, 0.6289, 0.0403, 0.0496, 0.0049]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0195, 0.0047, 0.0170, 0.1810, 0.0489, 0.6487, 0.0382, 0.0388, 0.0031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0715, 0.0339, 0.0470, 0.1921, 0.0884, 0.3864, 0.0743, 0.0822, 0.0241]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0259, 0.0101, 0.0224, 0.1371, 0.0530, 0.6529, 0.0502, 0.0430, 0.0054]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0673, 0.0236, 0.0417, 0.1817, 0.0845, 0.4283, 0.0647, 0.0840, 0.0242]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0288, 0.0098, 0.0206, 0.1397, 0.0657, 0.6240, 0.0501, 0.0550, 0.0063]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0168, 0.0033, 0.0104, 0.0998, 0.0304, 0.7608, 0.0308, 0.0446, 0.0031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0494, 0.0166, 0.0277, 0.1261, 0.0675, 0.6007, 0.0445, 0.0546, 0.0129]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0538, 0.0188, 0.0332, 0.1528, 0.0581, 0.5535, 0.0438, 0.0731, 0.0128]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0126, 0.0072, 0.0149, 0.1236, 0.0663, 0.6905, 0.0314, 0.0505, 0.0030]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0772, 0.0320, 0.0585, 0.1501, 0.1274, 0.3228, 0.0883, 0.1123, 0.0314]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0253, 0.0074, 0.0192, 0.1550, 0.0760, 0.6231, 0.0337, 0.0557, 0.0046]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0584, 0.0169, 0.0469, 0.1486, 0.0997, 0.4695, 0.0648, 0.0787, 0.0165]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0343, 0.0166, 0.0389, 0.1245, 0.0596, 0.5945, 0.0518, 0.0719, 0.0079]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0442, 0.0201, 0.0515, 0.1662, 0.1167, 0.4086, 0.0670, 0.1088, 0.0168]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0284, 0.0092, 0.0192, 0.1370, 0.0848, 0.6219, 0.0372, 0.0553, 0.0069]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.0060e-03, 4.8164e-05, 8.4278e-04, 3.1442e-02, 7.7538e-03, 9.4764e-01,\n",
       "           2.2061e-03, 9.0409e-03, 2.1262e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0292, 0.0057, 0.0174, 0.1454, 0.0467, 0.6747, 0.0343, 0.0433, 0.0033]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0292, 0.0074, 0.0287, 0.1566, 0.0963, 0.5007, 0.0693, 0.1013, 0.0106]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[3.8636e-04, 1.3970e-05, 2.9851e-04, 2.2131e-02, 5.7988e-03, 9.6613e-01,\n",
       "           1.6749e-03, 3.5520e-03, 1.3233e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0585, 0.0106, 0.0396, 0.2032, 0.0987, 0.4234, 0.0688, 0.0832, 0.0141]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0557, 0.0348, 0.0509, 0.1239, 0.1347, 0.3851, 0.0909, 0.0996, 0.0243]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0310, 0.0089, 0.0298, 0.1151, 0.0745, 0.5905, 0.0539, 0.0883, 0.0080]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0495, 0.0136, 0.0358, 0.1523, 0.0870, 0.5029, 0.0676, 0.0800, 0.0114]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0515, 0.0223, 0.0399, 0.1866, 0.1234, 0.3783, 0.0640, 0.1147, 0.0192]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0326, 0.0062, 0.0224, 0.1481, 0.0588, 0.6024, 0.0428, 0.0809, 0.0059]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0253, 0.0081, 0.0215, 0.1295, 0.0799, 0.5898, 0.0733, 0.0671, 0.0055]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[2.3440e-03, 3.1362e-04, 2.3222e-03, 4.9673e-02, 2.1704e-02, 9.0007e-01,\n",
       "           1.4016e-02, 9.3979e-03, 1.5432e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0295, 0.0074, 0.0268, 0.1803, 0.0807, 0.5572, 0.0526, 0.0592, 0.0063]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0349, 0.0148, 0.0383, 0.1368, 0.1252, 0.4874, 0.0633, 0.0867, 0.0127]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0164, 0.0012, 0.0075, 0.1054, 0.0504, 0.6958, 0.0151, 0.1064, 0.0019]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0215, 0.0070, 0.0232, 0.1430, 0.0970, 0.6010, 0.0468, 0.0557, 0.0047]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0252, 0.0138, 0.0354, 0.1752, 0.1157, 0.4686, 0.0717, 0.0833, 0.0112]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0256, 0.0094, 0.0228, 0.1536, 0.0922, 0.5211, 0.0784, 0.0859, 0.0110]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0114, 0.0046, 0.0171, 0.1237, 0.0899, 0.6408, 0.0432, 0.0641, 0.0052]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0665, 0.0367, 0.0558, 0.1542, 0.0992, 0.3254, 0.0823, 0.1403, 0.0397]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0083, 0.0021, 0.0080, 0.1071, 0.0438, 0.7587, 0.0298, 0.0407, 0.0015]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0395, 0.0159, 0.0461, 0.1422, 0.1251, 0.4356, 0.0660, 0.1136, 0.0159]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0246, 0.0059, 0.0250, 0.0913, 0.0848, 0.6198, 0.0596, 0.0843, 0.0046]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0528, 0.0212, 0.0483, 0.1493, 0.1153, 0.3800, 0.0746, 0.1331, 0.0254]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0244, 0.0054, 0.0199, 0.1647, 0.0671, 0.6103, 0.0545, 0.0493, 0.0044]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0622, 0.0226, 0.0542, 0.1412, 0.1273, 0.3620, 0.0961, 0.1132, 0.0212]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[4.8658e-03, 6.2723e-04, 3.5370e-03, 9.5234e-02, 3.5559e-02, 8.3107e-01,\n",
       "           1.1991e-02, 1.6639e-02, 4.7539e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0176, 0.0030, 0.0097, 0.1679, 0.0614, 0.6604, 0.0213, 0.0564, 0.0023]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0219, 0.0037, 0.0203, 0.1361, 0.0520, 0.6250, 0.0318, 0.1050, 0.0041]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0197, 0.0033, 0.0191, 0.1333, 0.0829, 0.6528, 0.0316, 0.0531, 0.0042]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0469, 0.0105, 0.0333, 0.1662, 0.0899, 0.4705, 0.0736, 0.1010, 0.0082]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0140, 0.0021, 0.0155, 0.1017, 0.0554, 0.7225, 0.0248, 0.0626, 0.0016]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0150, 0.0022, 0.0115, 0.1441, 0.0762, 0.6216, 0.0376, 0.0897, 0.0021]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0363, 0.0088, 0.0223, 0.1311, 0.1092, 0.5040, 0.0627, 0.1125, 0.0133]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0465, 0.0184, 0.0443, 0.1663, 0.1383, 0.3702, 0.0779, 0.1204, 0.0177]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0198, 0.0035, 0.0188, 0.1095, 0.1197, 0.6210, 0.0520, 0.0519, 0.0037]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0275, 0.0026, 0.0152, 0.1316, 0.0583, 0.6620, 0.0383, 0.0619, 0.0026]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0424, 0.0118, 0.0372, 0.1449, 0.1157, 0.4818, 0.0536, 0.1027, 0.0098]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0551, 0.0252, 0.0532, 0.1472, 0.1241, 0.3636, 0.0815, 0.1267, 0.0233]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0511, 0.0178, 0.0482, 0.1235, 0.1455, 0.3787, 0.0712, 0.1371, 0.0268]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0335, 0.0067, 0.0197, 0.1409, 0.1470, 0.4866, 0.0495, 0.1062, 0.0097]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0636, 0.0287, 0.0618, 0.1507, 0.1459, 0.2998, 0.0880, 0.1295, 0.0320]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0170, 0.0022, 0.0111, 0.1742, 0.0790, 0.5901, 0.0387, 0.0858, 0.0019]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0124, 0.0018, 0.0163, 0.1550, 0.1507, 0.5502, 0.0426, 0.0688, 0.0021]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0253, 0.0055, 0.0217, 0.1537, 0.1099, 0.5226, 0.0548, 0.0968, 0.0097]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0456, 0.0119, 0.0347, 0.1358, 0.0990, 0.5300, 0.0655, 0.0685, 0.0089]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0367, 0.0082, 0.0244, 0.1455, 0.1383, 0.4489, 0.0522, 0.1375, 0.0083]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0348, 0.0111, 0.0306, 0.1464, 0.1314, 0.4605, 0.0559, 0.1187, 0.0106]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0597, 0.0170, 0.0427, 0.1495, 0.1268, 0.3506, 0.0848, 0.1519, 0.0169]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0480, 0.0198, 0.0360, 0.1729, 0.1620, 0.3070, 0.1043, 0.1299, 0.0200]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0328, 0.0186, 0.0388, 0.1644, 0.1581, 0.3993, 0.0652, 0.1079, 0.0150]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0194, 0.0013, 0.0097, 0.1074, 0.0689, 0.6829, 0.0350, 0.0735, 0.0020]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0287, 0.0056, 0.0344, 0.1447, 0.1068, 0.4834, 0.0751, 0.1156, 0.0057]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0539, 0.0133, 0.0376, 0.1903, 0.1276, 0.3420, 0.0782, 0.1395, 0.0176]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0709, 0.0380, 0.0698, 0.1660, 0.1431, 0.2367, 0.1171, 0.1203, 0.0382]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0786, 0.0480, 0.0693, 0.1329, 0.1525, 0.2305, 0.1060, 0.1247, 0.0574]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.1453e-04, 3.5857e-06, 1.4002e-04, 2.9182e-02, 1.0359e-02, 9.5206e-01,\n",
       "           1.7240e-03, 6.2075e-03, 4.9101e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0522, 0.0157, 0.0428, 0.2002, 0.1234, 0.3605, 0.0936, 0.0924, 0.0192]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0642, 0.0127, 0.0373, 0.1861, 0.1541, 0.3089, 0.0868, 0.1338, 0.0162]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0422, 0.0078, 0.0226, 0.1987, 0.1281, 0.4440, 0.0717, 0.0790, 0.0060]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0871, 0.0454, 0.0665, 0.1398, 0.1503, 0.2213, 0.1040, 0.1320, 0.0535]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0452, 0.0169, 0.0530, 0.1954, 0.1850, 0.2625, 0.1010, 0.1187, 0.0222]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0648, 0.0239, 0.0601, 0.1556, 0.1555, 0.2735, 0.1081, 0.1325, 0.0261]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0184, 0.0016, 0.0078, 0.2803, 0.1084, 0.4645, 0.0512, 0.0663, 0.0015]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0307, 0.0084, 0.0315, 0.2177, 0.1370, 0.3637, 0.0933, 0.1112, 0.0065]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0484, 0.0202, 0.0409, 0.2243, 0.1178, 0.3321, 0.0908, 0.1061, 0.0193]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0749, 0.0443, 0.0776, 0.1501, 0.1372, 0.2306, 0.1131, 0.1237, 0.0485]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0449, 0.0150, 0.0365, 0.2476, 0.1387, 0.3220, 0.0778, 0.1009, 0.0165]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0594, 0.0181, 0.0502, 0.2369, 0.1422, 0.2327, 0.1003, 0.1389, 0.0214]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.8595e-03, 2.9371e-04, 3.2481e-03, 4.9506e-01, 7.7968e-02, 3.8345e-01,\n",
       "           1.4730e-02, 2.3208e-02, 1.8038e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0600, 0.0186, 0.0454, 0.2229, 0.1327, 0.2922, 0.1099, 0.1021, 0.0161]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0331, 0.0019, 0.0139, 0.3394, 0.0541, 0.4479, 0.0442, 0.0636, 0.0020]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0696, 0.0310, 0.0660, 0.1993, 0.1384, 0.2412, 0.1159, 0.1047, 0.0340]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0268, 0.0033, 0.0176, 0.2968, 0.0719, 0.4533, 0.0566, 0.0708, 0.0031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0868, 0.0319, 0.0816, 0.1807, 0.1281, 0.2245, 0.1037, 0.1210, 0.0418]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0652, 0.0319, 0.0671, 0.1893, 0.1471, 0.2572, 0.1081, 0.1043, 0.0299]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0473, 0.0076, 0.0395, 0.2757, 0.0817, 0.3803, 0.0890, 0.0714, 0.0074]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0609, 0.0134, 0.0432, 0.2169, 0.1124, 0.3579, 0.0850, 0.0923, 0.0180]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0824, 0.0327, 0.0672, 0.1671, 0.1294, 0.2695, 0.1142, 0.1042, 0.0334]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0761, 0.0481, 0.0783, 0.1547, 0.1374, 0.2297, 0.1329, 0.0999, 0.0429]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0734, 0.0231, 0.0655, 0.1663, 0.1173, 0.3025, 0.1101, 0.1151, 0.0268]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[8.8159e-03, 6.0923e-04, 8.4433e-03, 1.9427e-01, 4.0449e-02, 6.8429e-01,\n",
       "           4.1066e-02, 2.1164e-02, 8.9709e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0433, 0.0089, 0.0438, 0.2315, 0.0828, 0.4048, 0.0983, 0.0774, 0.0091]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0800, 0.0199, 0.0583, 0.2072, 0.1138, 0.3215, 0.1040, 0.0750, 0.0203]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0461, 0.0119, 0.0484, 0.2744, 0.1351, 0.3063, 0.0940, 0.0714, 0.0125]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0819, 0.0305, 0.0624, 0.2216, 0.1206, 0.2381, 0.1098, 0.0977, 0.0374]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0342, 0.0040, 0.0319, 0.2765, 0.0608, 0.4518, 0.0702, 0.0668, 0.0038]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0768, 0.0491, 0.0870, 0.1850, 0.1341, 0.2134, 0.1164, 0.0955, 0.0428]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.6946e-03, 3.6741e-05, 3.2339e-03, 3.5913e-01, 2.7354e-02, 5.4899e-01,\n",
       "           4.6323e-02, 1.1186e-02, 4.7200e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0487, 0.0136, 0.0673, 0.2761, 0.1132, 0.2925, 0.0964, 0.0783, 0.0139]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0451, 0.0122, 0.0546, 0.3136, 0.1221, 0.2881, 0.0880, 0.0660, 0.0103]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0710, 0.0205, 0.0566, 0.2243, 0.1320, 0.2992, 0.0890, 0.0832, 0.0241]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0141, 0.0008, 0.0094, 0.3070, 0.0438, 0.5808, 0.0197, 0.0227, 0.0017]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0432, 0.0132, 0.0467, 0.2279, 0.1138, 0.3841, 0.0817, 0.0746, 0.0148]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0402, 0.0096, 0.0451, 0.2318, 0.0735, 0.4340, 0.0905, 0.0643, 0.0110]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0186, 0.0025, 0.0135, 0.2251, 0.0594, 0.6136, 0.0337, 0.0308, 0.0028]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0593, 0.0283, 0.0546, 0.1926, 0.1407, 0.3131, 0.0909, 0.0883, 0.0321]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0506, 0.0145, 0.0570, 0.2065, 0.1396, 0.3212, 0.1200, 0.0748, 0.0159]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0386, 0.0023, 0.0212, 0.2556, 0.0576, 0.5332, 0.0522, 0.0368, 0.0024]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0614, 0.0143, 0.0427, 0.1893, 0.0848, 0.4213, 0.0808, 0.0920, 0.0133]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0554, 0.0174, 0.0620, 0.1878, 0.1382, 0.3451, 0.0982, 0.0784, 0.0175]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0467, 0.0136, 0.0500, 0.1865, 0.1194, 0.3949, 0.0948, 0.0776, 0.0165]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0975, 0.0496, 0.0829, 0.1439, 0.1242, 0.2422, 0.1104, 0.1035, 0.0458]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0830, 0.0409, 0.0779, 0.1494, 0.1242, 0.2694, 0.1024, 0.1057, 0.0470]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0277, 0.0059, 0.0556, 0.1602, 0.1238, 0.4471, 0.0946, 0.0782, 0.0068]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.2805e-03, 4.9053e-05, 1.5539e-03, 3.5752e-02, 6.6068e-03, 9.4597e-01,\n",
       "           5.9896e-03, 2.7571e-03, 4.1143e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0423, 0.0145, 0.0526, 0.1376, 0.1227, 0.4660, 0.0754, 0.0700, 0.0189]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0446, 0.0082, 0.0374, 0.1851, 0.1199, 0.4737, 0.0659, 0.0592, 0.0060]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.5401e-05, 1.6089e-08, 1.3805e-05, 3.7343e-03, 2.3489e-04, 9.9582e-01,\n",
       "           5.4741e-05, 1.1343e-04, 3.3377e-08]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0210, 0.0032, 0.0147, 0.1537, 0.0501, 0.6810, 0.0256, 0.0475, 0.0033]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0156, 0.0019, 0.0111, 0.0893, 0.0431, 0.7749, 0.0261, 0.0356, 0.0026]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0562, 0.0268, 0.0656, 0.1456, 0.1446, 0.3571, 0.0876, 0.0858, 0.0309]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0601, 0.0100, 0.0345, 0.1661, 0.1036, 0.5010, 0.0591, 0.0544, 0.0112]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0090, 0.0012, 0.0051, 0.1076, 0.0189, 0.8299, 0.0101, 0.0170, 0.0011]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0194, 0.0026, 0.0179, 0.1235, 0.0532, 0.6945, 0.0415, 0.0444, 0.0032]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0177, 0.0015, 0.0104, 0.1403, 0.0381, 0.7257, 0.0307, 0.0331, 0.0025]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.6210e-03, 1.5184e-05, 5.4552e-04, 3.3802e-02, 2.6953e-03, 9.5394e-01,\n",
       "           1.9098e-03, 4.4471e-03, 2.6128e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0175, 0.0008, 0.0059, 0.1360, 0.0221, 0.7778, 0.0181, 0.0208, 0.0009]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0507, 0.0149, 0.0498, 0.1736, 0.1394, 0.4221, 0.0671, 0.0643, 0.0181]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0197, 0.0016, 0.0145, 0.0822, 0.0375, 0.7911, 0.0210, 0.0301, 0.0023]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0077, 0.0013, 0.0109, 0.1134, 0.0667, 0.7431, 0.0247, 0.0311, 0.0012]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[5.3927e-03, 1.6984e-04, 1.2831e-03, 3.9222e-02, 8.3252e-03, 9.3051e-01,\n",
       "           4.3729e-03, 1.0525e-02, 1.9836e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0190, 0.0011, 0.0119, 0.1156, 0.0352, 0.7718, 0.0158, 0.0283, 0.0014]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0430, 0.0139, 0.0354, 0.1266, 0.0713, 0.5775, 0.0608, 0.0574, 0.0141]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0184, 0.0029, 0.0136, 0.0632, 0.0542, 0.8005, 0.0204, 0.0243, 0.0024]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[9.5568e-03, 8.3943e-04, 5.7512e-03, 9.8759e-02, 2.9747e-02, 8.2081e-01,\n",
       "           1.2525e-02, 2.1329e-02, 6.8718e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.0504e-02, 5.4642e-04, 6.0157e-03, 6.3735e-02, 3.3636e-02, 8.4922e-01,\n",
       "           1.7857e-02, 1.7855e-02, 6.3194e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.3072e-02, 6.4665e-04, 6.2002e-03, 6.9584e-02, 2.1103e-02, 8.6498e-01,\n",
       "           1.1038e-02, 1.2744e-02, 6.3274e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0313, 0.0060, 0.0381, 0.1064, 0.0715, 0.6431, 0.0416, 0.0547, 0.0074]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0211, 0.0018, 0.0109, 0.1260, 0.0304, 0.7684, 0.0169, 0.0226, 0.0018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0191, 0.0037, 0.0148, 0.1202, 0.0791, 0.6488, 0.0467, 0.0620, 0.0056]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[5.0436e-03, 1.5003e-04, 2.6697e-03, 3.4019e-02, 2.0853e-02, 9.2157e-01,\n",
       "           6.9617e-03, 8.5433e-03, 1.8611e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.0902e-03, 3.4768e-05, 1.0194e-03, 3.4278e-02, 1.3362e-02, 9.4171e-01,\n",
       "           3.7113e-03, 4.7631e-03, 3.0669e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.1986e-05, 4.3504e-08, 2.3622e-05, 3.4064e-03, 7.6640e-04, 9.9550e-01,\n",
       "           1.7253e-04, 1.1876e-04, 1.3296e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[6.4232e-03, 3.8399e-04, 3.3108e-03, 6.1325e-02, 1.5853e-02, 8.9078e-01,\n",
       "           9.5876e-03, 1.1919e-02, 4.1320e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[4.6553e-03, 6.6659e-04, 9.6380e-03, 6.1867e-02, 3.3770e-02, 8.4947e-01,\n",
       "           2.0845e-02, 1.8174e-02, 9.1897e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[4.9640e-03, 4.3088e-04, 1.0027e-02, 6.3524e-02, 5.1438e-02, 8.2166e-01,\n",
       "           2.4959e-02, 2.2176e-02, 8.2189e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0098, 0.0025, 0.0105, 0.0913, 0.0529, 0.7947, 0.0188, 0.0177, 0.0016]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0373, 0.0071, 0.0288, 0.1358, 0.0795, 0.6047, 0.0402, 0.0592, 0.0075]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.6003e-03, 8.0909e-05, 2.4186e-03, 3.1774e-02, 1.8325e-02, 9.3202e-01,\n",
       "           6.1285e-03, 6.5577e-03, 9.1599e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[1.7956e-03, 7.0113e-05, 9.3268e-04, 3.4926e-02, 7.8277e-03, 9.4695e-01,\n",
       "           2.0287e-03, 5.3526e-03, 1.1869e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0288, 0.0077, 0.0299, 0.1553, 0.0914, 0.5716, 0.0571, 0.0500, 0.0083]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.5164e-03, 1.0616e-04, 1.1056e-03, 3.1736e-02, 1.6240e-02, 9.3937e-01,\n",
       "           4.2070e-03, 4.6406e-03, 7.8487e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[8.7266e-04, 2.0282e-05, 1.6437e-03, 3.0768e-02, 1.1347e-02, 9.4873e-01,\n",
       "           4.0269e-03, 2.5603e-03, 3.2302e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.1991e-03, 1.1119e-04, 3.1791e-03, 6.0622e-02, 2.5335e-02, 8.8993e-01,\n",
       "           8.4732e-03, 8.8673e-03, 2.7930e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0181, 0.0022, 0.0175, 0.1138, 0.0664, 0.7212, 0.0310, 0.0266, 0.0031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.8840e-03, 4.0429e-05, 1.2859e-03, 7.3859e-02, 7.9795e-03, 9.0702e-01,\n",
       "           3.5822e-03, 4.3059e-03, 4.0768e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0186, 0.0026, 0.0305, 0.1179, 0.0889, 0.6776, 0.0280, 0.0323, 0.0037]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[8.8308e-05, 1.3776e-07, 2.4991e-05, 7.2382e-03, 1.3879e-03, 9.9067e-01,\n",
       "           1.4896e-04, 4.4366e-04, 8.7022e-08]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0183, 0.0009, 0.0122, 0.0770, 0.0421, 0.7833, 0.0259, 0.0382, 0.0019]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.6675e-03, 8.4220e-05, 7.7132e-04, 3.1897e-02, 1.0839e-02, 9.4757e-01,\n",
       "           4.0726e-03, 2.0509e-03, 4.4120e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[3.7397e-03, 1.2030e-04, 2.2087e-03, 6.9303e-02, 1.7918e-02, 8.9554e-01,\n",
       "           5.5687e-03, 5.4395e-03, 1.5967e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0222, 0.0071, 0.0197, 0.1035, 0.0820, 0.6874, 0.0399, 0.0335, 0.0046]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0205, 0.0015, 0.0095, 0.1430, 0.0651, 0.7158, 0.0189, 0.0239, 0.0018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.0100e-04, 8.2423e-07, 7.2047e-05, 8.7077e-03, 5.0910e-03, 9.8521e-01,\n",
       "           4.3402e-04, 3.8308e-04, 4.9143e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0244, 0.0012, 0.0144, 0.1215, 0.0627, 0.7194, 0.0287, 0.0258, 0.0019]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0274, 0.0053, 0.0214, 0.1306, 0.0667, 0.6492, 0.0355, 0.0555, 0.0084]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[2.6988e-03, 2.6830e-04, 1.8813e-03, 6.3423e-02, 1.7775e-02, 9.0330e-01,\n",
       "           5.1145e-03, 5.2169e-03, 3.1926e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0161, 0.0017, 0.0094, 0.0995, 0.0446, 0.7787, 0.0195, 0.0283, 0.0023]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0265, 0.0019, 0.0141, 0.1449, 0.0770, 0.6670, 0.0312, 0.0332, 0.0043]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[5.7467e-03, 2.7168e-04, 5.9011e-03, 8.7144e-02, 4.3795e-02, 8.3207e-01,\n",
       "           1.0871e-02, 1.3817e-02, 3.8490e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.6484e-03, 8.2820e-05, 4.1505e-03, 1.8410e-01, 4.1590e-02, 7.4223e-01,\n",
       "           1.2327e-02, 1.2688e-02, 1.8509e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0300, 0.0058, 0.0203, 0.1219, 0.0947, 0.6365, 0.0440, 0.0401, 0.0068]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[4.3343e-03, 8.8411e-05, 1.6207e-03, 5.3760e-02, 2.7186e-02, 9.0170e-01,\n",
       "           5.8585e-03, 5.3147e-03, 1.3518e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0313, 0.0057, 0.0287, 0.1937, 0.1252, 0.5054, 0.0616, 0.0418, 0.0064]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.5503e-02, 7.5912e-04, 7.2919e-03, 8.6872e-02, 4.8623e-02, 7.8929e-01,\n",
       "           1.5896e-02, 3.4348e-02, 1.4177e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0366, 0.0098, 0.0433, 0.1356, 0.1517, 0.4391, 0.0708, 0.0992, 0.0140]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[6.9314e-05, 3.2684e-07, 5.6569e-05, 3.6625e-02, 6.2398e-03, 9.5645e-01,\n",
       "           3.6664e-04, 1.9371e-04, 3.7855e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0435, 0.0065, 0.0347, 0.1206, 0.2306, 0.4406, 0.0508, 0.0612, 0.0116]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0393, 0.0039, 0.0235, 0.1901, 0.1304, 0.4956, 0.0543, 0.0556, 0.0073]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[5.2883e-03, 2.8170e-04, 6.7409e-03, 2.0027e-01, 1.0574e-01, 6.4250e-01,\n",
       "           2.5106e-02, 1.3657e-02, 4.2640e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[8.2839e-03, 2.2496e-04, 4.4602e-03, 1.0420e-01, 4.4727e-02, 8.1230e-01,\n",
       "           1.1257e-02, 1.4117e-02, 4.2058e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0733, 0.0190, 0.0479, 0.1520, 0.1618, 0.3595, 0.0867, 0.0724, 0.0275]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0283, 0.0032, 0.0190, 0.1887, 0.1119, 0.5880, 0.0318, 0.0262, 0.0029]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0420, 0.0091, 0.0236, 0.1686, 0.1173, 0.5100, 0.0648, 0.0557, 0.0089]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0252, 0.0026, 0.0259, 0.1727, 0.1024, 0.5590, 0.0745, 0.0346, 0.0031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0466, 0.0104, 0.0367, 0.2061, 0.1645, 0.3832, 0.0860, 0.0564, 0.0101]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0443, 0.0093, 0.0478, 0.1579, 0.1276, 0.4470, 0.0900, 0.0664, 0.0097]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0425, 0.0031, 0.0261, 0.2306, 0.0980, 0.4857, 0.0614, 0.0488, 0.0038]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0445, 0.0072, 0.0407, 0.2223, 0.1621, 0.3318, 0.0782, 0.1047, 0.0086]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0771, 0.0274, 0.0657, 0.1491, 0.1533, 0.3012, 0.0947, 0.0953, 0.0362]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0776, 0.0279, 0.0787, 0.1858, 0.1413, 0.2464, 0.1086, 0.1023, 0.0315]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0509, 0.0091, 0.0531, 0.1765, 0.1395, 0.3923, 0.0875, 0.0769, 0.0142]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0114, 0.0006, 0.0097, 0.2349, 0.1075, 0.5592, 0.0485, 0.0271, 0.0011]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0436, 0.0071, 0.0377, 0.2308, 0.1444, 0.3979, 0.0956, 0.0367, 0.0062]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0507, 0.0053, 0.0369, 0.1972, 0.1083, 0.4525, 0.0755, 0.0652, 0.0083]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0919, 0.0408, 0.0713, 0.1508, 0.1539, 0.2216, 0.1091, 0.1176, 0.0429]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0665, 0.0271, 0.0587, 0.1986, 0.1371, 0.3116, 0.0977, 0.0811, 0.0216]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0670, 0.0220, 0.0767, 0.1751, 0.1783, 0.2588, 0.1072, 0.0898, 0.0250]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0604, 0.0115, 0.0582, 0.2140, 0.1417, 0.3156, 0.1188, 0.0697, 0.0102]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0659, 0.0157, 0.0457, 0.2366, 0.1362, 0.2948, 0.1155, 0.0731, 0.0166]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0803, 0.0485, 0.1008, 0.1224, 0.1703, 0.1968, 0.1213, 0.1029, 0.0567]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0890, 0.0396, 0.0845, 0.1618, 0.1473, 0.2190, 0.1115, 0.1018, 0.0455]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0746, 0.0104, 0.0593, 0.1876, 0.1449, 0.3171, 0.0949, 0.0966, 0.0147]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0746, 0.0277, 0.0685, 0.2157, 0.1480, 0.2261, 0.1136, 0.0981, 0.0278]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0646, 0.0226, 0.0603, 0.2214, 0.1589, 0.2228, 0.1217, 0.1015, 0.0261]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0786, 0.0245, 0.0732, 0.1795, 0.1320, 0.2721, 0.1119, 0.0997, 0.0285]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0650, 0.0133, 0.0720, 0.1894, 0.1435, 0.2973, 0.1290, 0.0761, 0.0145]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0964, 0.0352, 0.0840, 0.1629, 0.1350, 0.2207, 0.1017, 0.1167, 0.0474]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0764, 0.0229, 0.0644, 0.1655, 0.1450, 0.2854, 0.1061, 0.1056, 0.0287]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0373, 0.0034, 0.0349, 0.2296, 0.1143, 0.4141, 0.0997, 0.0611, 0.0057]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0554, 0.0113, 0.0588, 0.1689, 0.1335, 0.3548, 0.1162, 0.0892, 0.0118]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0244, 0.0027, 0.0348, 0.2348, 0.1532, 0.4080, 0.0973, 0.0419, 0.0029]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0459, 0.0108, 0.0497, 0.2229, 0.1487, 0.3053, 0.1107, 0.0903, 0.0156]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0610, 0.0258, 0.0752, 0.1888, 0.1569, 0.2336, 0.1069, 0.1231, 0.0286]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0610, 0.0107, 0.0558, 0.2186, 0.0932, 0.3460, 0.1013, 0.1006, 0.0128]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0822, 0.0457, 0.0946, 0.1396, 0.1650, 0.1629, 0.1216, 0.1237, 0.0646]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0600, 0.0127, 0.0644, 0.1967, 0.1635, 0.2622, 0.1201, 0.1022, 0.0183]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0474, 0.0129, 0.0653, 0.1751, 0.1582, 0.3020, 0.1173, 0.1042, 0.0175]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0125, 0.0007, 0.0146, 0.1895, 0.1341, 0.5538, 0.0505, 0.0435, 0.0008]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0862, 0.0509, 0.0893, 0.1384, 0.1519, 0.2062, 0.1164, 0.1084, 0.0523]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0739, 0.0286, 0.0728, 0.1880, 0.1669, 0.2312, 0.1230, 0.0900, 0.0255]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0635, 0.0287, 0.0832, 0.1634, 0.1728, 0.2328, 0.1411, 0.0849, 0.0296]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0640, 0.0384, 0.0777, 0.1670, 0.1888, 0.2056, 0.1257, 0.0930, 0.0397]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0439, 0.0150, 0.0640, 0.2379, 0.1636, 0.2340, 0.1582, 0.0686, 0.0147]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0719, 0.0320, 0.0793, 0.1705, 0.1449, 0.2370, 0.1216, 0.1045, 0.0382]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0652, 0.0232, 0.0715, 0.2035, 0.1507, 0.2406, 0.1297, 0.0914, 0.0242]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0450, 0.0152, 0.0763, 0.1846, 0.1853, 0.2156, 0.1445, 0.1162, 0.0173]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0616, 0.0178, 0.0596, 0.1941, 0.1677, 0.2767, 0.1165, 0.0906, 0.0154]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0520, 0.0122, 0.0614, 0.2046, 0.1908, 0.2576, 0.1176, 0.0863, 0.0175]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0430, 0.0081, 0.0690, 0.1884, 0.2250, 0.2692, 0.1072, 0.0812, 0.0088]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0849, 0.0473, 0.0910, 0.1595, 0.1687, 0.1652, 0.1311, 0.1040, 0.0484]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0079, 0.0005, 0.0150, 0.2699, 0.1815, 0.3820, 0.0781, 0.0646, 0.0007]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0849, 0.0500, 0.0824, 0.1680, 0.1675, 0.1863, 0.1162, 0.0990, 0.0455]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0262, 0.0023, 0.0258, 0.3760, 0.1281, 0.3271, 0.0690, 0.0427, 0.0028]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0761, 0.0322, 0.0946, 0.1528, 0.1708, 0.2173, 0.1220, 0.0976, 0.0367]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0690, 0.0447, 0.0864, 0.1760, 0.1789, 0.1810, 0.1362, 0.0904, 0.0373]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0368, 0.0069, 0.0427, 0.1944, 0.1866, 0.3589, 0.1088, 0.0553, 0.0096]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[8.9578e-03, 8.0168e-04, 1.1752e-02, 4.9535e-01, 1.2197e-01, 2.5994e-01,\n",
       "           7.7337e-02, 2.3489e-02, 3.9841e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.6647e-04, 6.2516e-07, 3.0290e-04, 3.7969e-01, 1.4865e-02, 5.8800e-01,\n",
       "           1.5902e-02, 9.6785e-04, 2.4811e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0509, 0.0161, 0.0721, 0.2170, 0.1919, 0.2017, 0.1306, 0.0996, 0.0202]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0322, 0.0033, 0.0349, 0.2617, 0.1657, 0.3582, 0.0905, 0.0493, 0.0042]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0504, 0.0094, 0.0541, 0.1946, 0.1593, 0.3265, 0.1301, 0.0647, 0.0108]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0720, 0.0243, 0.0803, 0.1663, 0.1842, 0.2192, 0.1280, 0.0972, 0.0285]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0673, 0.0285, 0.0808, 0.1600, 0.1804, 0.2134, 0.1237, 0.1113, 0.0347]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0440, 0.0136, 0.0595, 0.2061, 0.1603, 0.2939, 0.1353, 0.0759, 0.0115]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0104, 0.0004, 0.0191, 0.3209, 0.1864, 0.3894, 0.0483, 0.0245, 0.0005]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0450, 0.0108, 0.0488, 0.1771, 0.1614, 0.3827, 0.1025, 0.0611, 0.0106]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0698, 0.0285, 0.0755, 0.1608, 0.1428, 0.2701, 0.1251, 0.1002, 0.0272]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0414, 0.0083, 0.0554, 0.2321, 0.1420, 0.3078, 0.1094, 0.0915, 0.0122]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[6.7043e-03, 1.7912e-04, 1.3032e-02, 2.0665e-01, 6.4837e-02, 6.4179e-01,\n",
       "           4.0856e-02, 2.5534e-02, 4.1998e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0790, 0.0308, 0.0728, 0.1573, 0.1576, 0.2390, 0.1377, 0.0946, 0.0311]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0661, 0.0251, 0.0676, 0.1628, 0.1868, 0.2164, 0.1375, 0.1013, 0.0363]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0373, 0.0071, 0.0490, 0.1457, 0.2005, 0.3697, 0.1259, 0.0553, 0.0095]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0447, 0.0156, 0.0608, 0.1592, 0.2322, 0.2672, 0.1305, 0.0744, 0.0153]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0242, 0.0027, 0.0296, 0.1502, 0.1555, 0.5047, 0.0962, 0.0335, 0.0035]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0448, 0.0101, 0.0473, 0.1444, 0.1494, 0.4241, 0.1013, 0.0687, 0.0101]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0708, 0.0265, 0.0662, 0.1461, 0.1560, 0.2827, 0.1279, 0.0977, 0.0259]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0400, 0.0098, 0.0446, 0.1249, 0.1936, 0.3700, 0.1153, 0.0893, 0.0125]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0663, 0.0337, 0.0728, 0.1479, 0.1706, 0.2390, 0.1318, 0.0991, 0.0390]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0328, 0.0031, 0.0281, 0.1410, 0.1440, 0.4715, 0.1179, 0.0568, 0.0047]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0410, 0.0081, 0.0381, 0.1244, 0.1686, 0.4012, 0.1119, 0.0964, 0.0103]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0596, 0.0274, 0.0579, 0.1618, 0.1759, 0.2736, 0.1306, 0.0900, 0.0232]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0513, 0.0202, 0.0674, 0.1373, 0.1914, 0.2853, 0.1213, 0.0998, 0.0260]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0359, 0.0118, 0.0591, 0.1351, 0.1721, 0.3249, 0.1422, 0.1031, 0.0157]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0732, 0.0254, 0.0765, 0.1239, 0.1662, 0.2792, 0.1396, 0.0847, 0.0314]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[2.4173e-03, 4.7859e-05, 2.2589e-03, 5.8806e-02, 7.6475e-02, 8.2252e-01,\n",
       "           2.8194e-02, 9.2211e-03, 5.8832e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0324, 0.0041, 0.0411, 0.1300, 0.1556, 0.4719, 0.1210, 0.0382, 0.0056]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.2923e-03, 1.0087e-05, 1.7392e-03, 3.8844e-02, 4.3297e-02, 8.6686e-01,\n",
       "           4.5495e-02, 2.4534e-03, 1.1604e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0496, 0.0064, 0.0430, 0.1363, 0.1574, 0.4018, 0.1289, 0.0680, 0.0088]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0351, 0.0051, 0.0450, 0.1220, 0.1745, 0.4161, 0.1382, 0.0532, 0.0107]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0689, 0.0354, 0.0763, 0.1468, 0.1620, 0.2199, 0.1570, 0.0973, 0.0364]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0486, 0.0082, 0.0501, 0.1208, 0.1654, 0.4033, 0.1221, 0.0707, 0.0108]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0831, 0.0483, 0.0849, 0.1145, 0.1578, 0.1929, 0.1327, 0.1277, 0.0581]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0571, 0.0115, 0.0431, 0.1587, 0.1381, 0.3788, 0.1235, 0.0774, 0.0118]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0499, 0.0136, 0.0545, 0.1545, 0.1386, 0.3715, 0.1246, 0.0787, 0.0140]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0515, 0.0124, 0.0584, 0.1361, 0.1679, 0.3472, 0.1417, 0.0691, 0.0157]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0760, 0.0335, 0.0785, 0.1366, 0.1624, 0.2361, 0.1395, 0.0960, 0.0413]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0478, 0.0084, 0.0410, 0.1700, 0.1682, 0.3381, 0.1517, 0.0632, 0.0116]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0578, 0.0150, 0.0592, 0.1339, 0.1514, 0.3810, 0.1106, 0.0726, 0.0185]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0579, 0.0163, 0.0547, 0.1367, 0.1766, 0.3329, 0.1201, 0.0844, 0.0203]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.7019e-03, 7.3369e-05, 2.8247e-03, 1.8651e-01, 7.0547e-02, 6.5508e-01,\n",
       "           6.9104e-02, 1.2043e-02, 1.1487e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0510, 0.0100, 0.0543, 0.1647, 0.1641, 0.2987, 0.1536, 0.0856, 0.0181]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0762, 0.0327, 0.0823, 0.1284, 0.1551, 0.2403, 0.1378, 0.1102, 0.0369]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0609, 0.0175, 0.0595, 0.1556, 0.1440, 0.3533, 0.1034, 0.0771, 0.0287]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0162, 0.0019, 0.0167, 0.1163, 0.1641, 0.5525, 0.0859, 0.0434, 0.0032]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0204, 0.0036, 0.0229, 0.1429, 0.1519, 0.5497, 0.0699, 0.0339, 0.0048]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0190, 0.0023, 0.0195, 0.1234, 0.0969, 0.6251, 0.0775, 0.0343, 0.0021]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0758, 0.0372, 0.0837, 0.1402, 0.1459, 0.2551, 0.1106, 0.1078, 0.0438]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[1.0897e-02, 5.6326e-04, 1.8740e-02, 1.3102e-01, 1.1400e-01, 6.6019e-01,\n",
       "           4.3292e-02, 1.9389e-02, 1.9030e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0595, 0.0117, 0.0670, 0.1201, 0.1552, 0.3589, 0.1298, 0.0810, 0.0168]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0610, 0.0188, 0.0614, 0.1353, 0.1318, 0.3362, 0.1176, 0.1122, 0.0258]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0335, 0.0043, 0.0397, 0.0916, 0.0782, 0.6359, 0.0719, 0.0403, 0.0047]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[7.3242e-03, 1.9575e-04, 9.5126e-03, 5.2268e-02, 4.6091e-02, 8.5048e-01,\n",
       "           1.9341e-02, 1.4496e-02, 2.9088e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[7.2930e-03, 6.9166e-04, 1.2036e-02, 1.0643e-01, 6.4548e-02, 7.2875e-01,\n",
       "           5.1762e-02, 2.7681e-02, 8.0644e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0576, 0.0144, 0.0659, 0.1609, 0.1333, 0.3467, 0.1140, 0.0876, 0.0195]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0298, 0.0039, 0.0452, 0.1570, 0.1234, 0.4695, 0.0916, 0.0718, 0.0078]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0548, 0.0161, 0.0566, 0.1510, 0.1307, 0.3665, 0.0949, 0.1125, 0.0169]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0555, 0.0146, 0.0670, 0.1592, 0.1261, 0.3364, 0.1024, 0.1163, 0.0225]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0262, 0.0029, 0.0307, 0.1368, 0.1043, 0.5494, 0.0875, 0.0573, 0.0047]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[4.7947e-03, 2.3045e-04, 8.5734e-03, 1.2327e-01, 4.1779e-02, 7.8245e-01,\n",
       "           2.3946e-02, 1.4582e-02, 3.7029e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0469, 0.0054, 0.0383, 0.1585, 0.1356, 0.4288, 0.1174, 0.0606, 0.0085]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.8013e-03, 3.5813e-05, 3.0361e-03, 7.1114e-02, 2.2653e-02, 8.6818e-01,\n",
       "           1.9187e-02, 1.1917e-02, 7.0728e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0502, 0.0058, 0.0372, 0.1526, 0.1166, 0.4760, 0.0702, 0.0832, 0.0082]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[4.4857e-06, 5.3940e-10, 1.1012e-05, 6.9655e-03, 2.8741e-04, 9.9229e-01,\n",
       "           1.4475e-04, 2.9511e-04, 1.7880e-08]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0331, 0.0044, 0.0224, 0.1716, 0.0854, 0.5555, 0.0602, 0.0633, 0.0040]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0202, 0.0008, 0.0222, 0.0996, 0.0595, 0.7217, 0.0463, 0.0283, 0.0013]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0262, 0.0054, 0.0393, 0.1438, 0.1309, 0.5098, 0.0700, 0.0645, 0.0101]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0421, 0.0114, 0.0581, 0.1280, 0.1358, 0.4413, 0.0959, 0.0684, 0.0189]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0254, 0.0023, 0.0425, 0.1189, 0.1306, 0.5462, 0.0756, 0.0531, 0.0055]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0391, 0.0033, 0.0356, 0.1350, 0.1200, 0.5457, 0.0658, 0.0496, 0.0060]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0585, 0.0184, 0.0809, 0.1603, 0.1689, 0.2837, 0.1081, 0.0959, 0.0254]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0329, 0.0040, 0.0431, 0.1216, 0.1137, 0.5498, 0.0666, 0.0612, 0.0072]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0350, 0.0061, 0.0535, 0.1564, 0.1489, 0.4309, 0.0952, 0.0658, 0.0082]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0637, 0.0138, 0.0781, 0.1214, 0.1307, 0.3635, 0.1172, 0.0908, 0.0208]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0802, 0.0396, 0.0897, 0.1306, 0.1677, 0.2224, 0.1176, 0.1074, 0.0448]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0548, 0.0048, 0.0483, 0.1683, 0.1280, 0.4301, 0.0909, 0.0666, 0.0082]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0569, 0.0099, 0.0681, 0.1704, 0.1336, 0.3562, 0.0927, 0.0962, 0.0161]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0287, 0.0022, 0.0250, 0.1376, 0.0695, 0.6450, 0.0526, 0.0367, 0.0027]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.2015e-02, 4.5406e-04, 1.5500e-02, 1.4146e-01, 1.1208e-01, 6.5504e-01,\n",
       "           4.2723e-02, 1.9327e-02, 1.4021e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0713, 0.0275, 0.0874, 0.1502, 0.1585, 0.2274, 0.1345, 0.1082, 0.0351]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[8.2820e-05, 1.1329e-08, 1.0387e-04, 2.2055e-02, 3.5955e-03, 9.7025e-01,\n",
       "           3.8165e-03, 9.6099e-05, 5.3351e-08]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0768, 0.0159, 0.0622, 0.1489, 0.1397, 0.3203, 0.1130, 0.0979, 0.0253]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0871, 0.0366, 0.0820, 0.1404, 0.1557, 0.2358, 0.1113, 0.1049, 0.0462]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0551, 0.0038, 0.0483, 0.1364, 0.1232, 0.4956, 0.0674, 0.0631, 0.0071]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0280, 0.0014, 0.0401, 0.1013, 0.1198, 0.6062, 0.0639, 0.0362, 0.0031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0722, 0.0131, 0.0534, 0.1789, 0.1357, 0.3513, 0.0994, 0.0796, 0.0165]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0928, 0.0349, 0.0927, 0.1365, 0.1434, 0.2305, 0.1181, 0.1054, 0.0458]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0792, 0.0224, 0.0721, 0.1606, 0.1516, 0.2858, 0.1071, 0.0927, 0.0284]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0908, 0.0308, 0.0795, 0.1626, 0.1487, 0.2455, 0.1035, 0.0975, 0.0412]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0786, 0.0235, 0.0785, 0.1535, 0.1396, 0.2746, 0.1312, 0.0927, 0.0278]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0794, 0.0248, 0.0799, 0.1347, 0.1688, 0.2491, 0.1258, 0.1006, 0.0369]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1011, 0.0585, 0.0964, 0.1261, 0.1353, 0.1884, 0.1143, 0.1154, 0.0644]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0739, 0.0284, 0.0833, 0.1446, 0.1619, 0.2403, 0.1266, 0.1011, 0.0399]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0567, 0.0101, 0.0549, 0.1738, 0.1442, 0.3448, 0.1011, 0.0961, 0.0182]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0718, 0.0182, 0.0735, 0.1780, 0.1539, 0.2903, 0.1069, 0.0835, 0.0238]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0945, 0.0273, 0.0798, 0.1458, 0.1533, 0.2334, 0.1235, 0.1061, 0.0362]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0982, 0.0596, 0.0991, 0.1260, 0.1363, 0.1673, 0.1206, 0.1203, 0.0728]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0926, 0.0355, 0.0962, 0.1342, 0.1663, 0.1942, 0.1288, 0.1067, 0.0454]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0963, 0.0588, 0.0989, 0.1282, 0.1377, 0.1780, 0.1241, 0.1088, 0.0692]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0906, 0.0392, 0.0843, 0.1411, 0.1484, 0.2221, 0.1215, 0.1027, 0.0501]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[2.8827e-02, 5.1956e-04, 1.5076e-02, 1.6954e-01, 9.7590e-02, 6.1624e-01,\n",
       "           4.2468e-02, 2.8756e-02, 9.7868e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0990, 0.0626, 0.0989, 0.1215, 0.1382, 0.1681, 0.1203, 0.1199, 0.0716]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0973, 0.0422, 0.0887, 0.1193, 0.1558, 0.2064, 0.1202, 0.1118, 0.0582]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1056, 0.0656, 0.1009, 0.1204, 0.1327, 0.1553, 0.1194, 0.1201, 0.0800]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[7.9091e-04, 2.5918e-07, 3.6338e-04, 4.5238e-02, 7.7582e-03, 9.3710e-01,\n",
       "           7.9220e-03, 8.2900e-04, 1.9724e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0519, 0.0100, 0.0541, 0.1644, 0.1357, 0.3764, 0.1084, 0.0829, 0.0162]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0805, 0.0209, 0.0768, 0.1664, 0.1434, 0.2556, 0.1134, 0.1101, 0.0329]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0386, 0.0009, 0.0396, 0.1281, 0.1211, 0.5467, 0.0667, 0.0553, 0.0030]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0857, 0.0291, 0.0894, 0.1441, 0.1522, 0.2217, 0.1219, 0.1105, 0.0454]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0883, 0.0338, 0.0885, 0.1315, 0.1625, 0.2205, 0.1176, 0.1085, 0.0488]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1004, 0.0654, 0.1016, 0.1235, 0.1397, 0.1554, 0.1239, 0.1177, 0.0724]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0925, 0.0364, 0.0936, 0.1440, 0.1509, 0.2156, 0.1199, 0.1020, 0.0452]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0965, 0.0354, 0.0832, 0.1500, 0.1494, 0.1941, 0.1232, 0.1168, 0.0514]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0941, 0.0393, 0.0896, 0.1423, 0.1421, 0.2035, 0.1173, 0.1171, 0.0548]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1009, 0.0592, 0.0969, 0.1320, 0.1367, 0.1599, 0.1203, 0.1231, 0.0712]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0917, 0.0350, 0.0913, 0.1540, 0.1518, 0.1980, 0.1213, 0.1097, 0.0472]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1048, 0.0668, 0.0966, 0.1294, 0.1345, 0.1497, 0.1224, 0.1200, 0.0758]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0926, 0.0430, 0.0890, 0.1346, 0.1670, 0.1963, 0.1263, 0.1074, 0.0438]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0965, 0.0652, 0.0998, 0.1224, 0.1429, 0.1598, 0.1199, 0.1212, 0.0723]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0854, 0.0399, 0.0891, 0.1411, 0.1454, 0.2009, 0.1319, 0.1149, 0.0514]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0972, 0.0701, 0.1017, 0.1220, 0.1427, 0.1473, 0.1213, 0.1177, 0.0800]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1064, 0.0671, 0.1013, 0.1200, 0.1364, 0.1563, 0.1173, 0.1184, 0.0769]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.5655e-02, 3.2035e-04, 2.2072e-02, 2.4972e-01, 1.1190e-01, 5.0702e-01,\n",
       "           4.6187e-02, 4.6268e-02, 8.6893e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0946, 0.0415, 0.0927, 0.1472, 0.1540, 0.1819, 0.1307, 0.1104, 0.0471]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0664, 0.0148, 0.0747, 0.1840, 0.1586, 0.2340, 0.1326, 0.1171, 0.0178]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0570, 0.0145, 0.0674, 0.1869, 0.1593, 0.2763, 0.1160, 0.1033, 0.0192]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1000, 0.0541, 0.1000, 0.1302, 0.1487, 0.1525, 0.1286, 0.1228, 0.0632]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0572, 0.0087, 0.0727, 0.2008, 0.1602, 0.2693, 0.1206, 0.0949, 0.0155]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1032, 0.0588, 0.0988, 0.1264, 0.1356, 0.1523, 0.1237, 0.1283, 0.0729]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0335, 0.0005, 0.0285, 0.2217, 0.0972, 0.4954, 0.0775, 0.0449, 0.0009]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1036, 0.0600, 0.0989, 0.1303, 0.1424, 0.1565, 0.1253, 0.1182, 0.0649]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1026, 0.0653, 0.1017, 0.1276, 0.1390, 0.1363, 0.1257, 0.1238, 0.0779]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0965, 0.0558, 0.0907, 0.1376, 0.1429, 0.1544, 0.1295, 0.1250, 0.0677]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0925, 0.0462, 0.0983, 0.1395, 0.1583, 0.1646, 0.1308, 0.1154, 0.0543]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0893, 0.0373, 0.0910, 0.1714, 0.1434, 0.1796, 0.1362, 0.1134, 0.0384]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0950, 0.0507, 0.1033, 0.1387, 0.1462, 0.1564, 0.1285, 0.1175, 0.0637]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0760, 0.0232, 0.0782, 0.2018, 0.1547, 0.2021, 0.1238, 0.1094, 0.0308]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0600, 0.0059, 0.0523, 0.2549, 0.1246, 0.2702, 0.1220, 0.1017, 0.0085]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0523, 0.0074, 0.0539, 0.2532, 0.1362, 0.2557, 0.1171, 0.1116, 0.0126]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0761, 0.0244, 0.0715, 0.1918, 0.1558, 0.2260, 0.1221, 0.1048, 0.0275]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0790, 0.0195, 0.0671, 0.1949, 0.1485, 0.1970, 0.1451, 0.1191, 0.0298]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0881, 0.0298, 0.0855, 0.1645, 0.1387, 0.1819, 0.1356, 0.1365, 0.0394]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0795, 0.0179, 0.0731, 0.1998, 0.1444, 0.2181, 0.1358, 0.1083, 0.0231]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0816, 0.0195, 0.0733, 0.1854, 0.1539, 0.2108, 0.1301, 0.1149, 0.0306]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0703, 0.0175, 0.0750, 0.1973, 0.1480, 0.2084, 0.1375, 0.1230, 0.0230]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0330, 0.0012, 0.0297, 0.3097, 0.1287, 0.3218, 0.1213, 0.0525, 0.0020]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.5077e-02, 2.4557e-04, 1.5038e-02, 3.8496e-01, 9.9823e-02, 3.4351e-01,\n",
       "           9.0183e-02, 4.0070e-02, 1.0899e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0737, 0.0162, 0.0753, 0.1998, 0.1478, 0.2200, 0.1484, 0.0994, 0.0194]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0697, 0.0141, 0.0651, 0.2239, 0.1763, 0.1961, 0.1397, 0.0997, 0.0155]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0892, 0.0323, 0.0880, 0.1826, 0.1406, 0.1777, 0.1347, 0.1166, 0.0383]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0755, 0.0231, 0.0807, 0.1830, 0.1559, 0.2375, 0.1112, 0.1035, 0.0295]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0796, 0.0367, 0.0800, 0.1660, 0.1548, 0.1898, 0.1238, 0.1277, 0.0418]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0549, 0.0077, 0.0560, 0.2657, 0.1400, 0.2457, 0.1217, 0.0981, 0.0102]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0710, 0.0212, 0.0700, 0.1988, 0.1751, 0.2104, 0.1273, 0.1014, 0.0249]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0688, 0.0119, 0.0641, 0.2145, 0.1809, 0.2167, 0.1322, 0.0962, 0.0148]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0433, 0.0036, 0.0499, 0.2571, 0.1281, 0.3426, 0.0994, 0.0689, 0.0072]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0691, 0.0102, 0.0648, 0.2303, 0.1474, 0.2431, 0.1199, 0.1014, 0.0138]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0301, 0.0013, 0.0322, 0.2836, 0.1697, 0.3262, 0.0946, 0.0596, 0.0026]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0669, 0.0059, 0.0522, 0.2034, 0.1638, 0.2870, 0.1267, 0.0855, 0.0085]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0838, 0.0209, 0.0709, 0.2050, 0.1428, 0.2147, 0.1149, 0.1167, 0.0305]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0698, 0.0147, 0.0762, 0.1901, 0.1700, 0.2224, 0.1213, 0.1135, 0.0222]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0750, 0.0193, 0.0795, 0.1833, 0.1567, 0.2144, 0.1336, 0.1115, 0.0266]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0544, 0.0037, 0.0465, 0.2536, 0.1680, 0.2854, 0.1176, 0.0658, 0.0049]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0881, 0.0285, 0.0769, 0.1750, 0.1536, 0.1929, 0.1308, 0.1195, 0.0346]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0888, 0.0254, 0.0796, 0.1715, 0.1429, 0.2209, 0.1136, 0.1213, 0.0358]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0482, 0.0049, 0.0406, 0.2957, 0.1460, 0.3095, 0.0748, 0.0733, 0.0069]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0605, 0.0071, 0.0484, 0.2406, 0.1402, 0.2890, 0.1247, 0.0801, 0.0093]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0614, 0.0055, 0.0584, 0.1786, 0.1452, 0.3711, 0.0948, 0.0762, 0.0087]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0953, 0.0329, 0.0837, 0.1579, 0.1475, 0.1974, 0.1277, 0.1199, 0.0378]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0323, 0.0028, 0.0451, 0.2532, 0.2038, 0.2999, 0.1134, 0.0446, 0.0049]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0247, 0.0013, 0.0298, 0.2518, 0.1156, 0.4448, 0.0865, 0.0428, 0.0027]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.9489e-03, 7.8343e-06, 2.3157e-03, 2.9443e-01, 5.0124e-02, 6.1496e-01,\n",
       "           2.7495e-02, 6.7044e-03, 1.7184e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0690, 0.0103, 0.0576, 0.1627, 0.2089, 0.2771, 0.1173, 0.0797, 0.0174]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0670, 0.0167, 0.0679, 0.1900, 0.1670, 0.2374, 0.1318, 0.0986, 0.0236]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0499, 0.0061, 0.0446, 0.2175, 0.1666, 0.2907, 0.1137, 0.1008, 0.0101]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0907, 0.0294, 0.0792, 0.1641, 0.1806, 0.2213, 0.1223, 0.0886, 0.0238]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0319, 0.0046, 0.0392, 0.2143, 0.1791, 0.3728, 0.0967, 0.0537, 0.0077]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0850, 0.0083, 0.0476, 0.1795, 0.1638, 0.3067, 0.1262, 0.0736, 0.0093]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0755, 0.0262, 0.0880, 0.1538, 0.1648, 0.2380, 0.1096, 0.1090, 0.0351]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0526, 0.0035, 0.0328, 0.2001, 0.1617, 0.4071, 0.0830, 0.0555, 0.0037]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0672, 0.0129, 0.0592, 0.1814, 0.1602, 0.2971, 0.1076, 0.0923, 0.0221]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0388, 0.0006, 0.0263, 0.2817, 0.1812, 0.3852, 0.0569, 0.0275, 0.0018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[4.1932e-03, 3.0251e-05, 4.1978e-03, 2.0855e-01, 7.6807e-02, 6.6607e-01,\n",
       "           3.4957e-02, 5.1268e-03, 6.4327e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0449, 0.0013, 0.0252, 0.2201, 0.1512, 0.4467, 0.0573, 0.0494, 0.0040]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0747, 0.0131, 0.0645, 0.1725, 0.1570, 0.3226, 0.0859, 0.0909, 0.0188]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0827, 0.0209, 0.0646, 0.1664, 0.1782, 0.2566, 0.1083, 0.0981, 0.0242]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0807, 0.0126, 0.0763, 0.1681, 0.1522, 0.2814, 0.1052, 0.1045, 0.0189]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0910, 0.0228, 0.0703, 0.1475, 0.1908, 0.2436, 0.1089, 0.0889, 0.0362]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0438, 0.0020, 0.0294, 0.1859, 0.1261, 0.4987, 0.0564, 0.0548, 0.0029]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0728, 0.0192, 0.0687, 0.1279, 0.1931, 0.2781, 0.1291, 0.0869, 0.0243]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0414, 0.0030, 0.0459, 0.1436, 0.1881, 0.4299, 0.0942, 0.0483, 0.0055]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0519, 0.0033, 0.0508, 0.1393, 0.1925, 0.4082, 0.0668, 0.0798, 0.0074]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.8290e-03, 5.5726e-06, 3.1003e-03, 1.0511e-01, 8.1381e-02, 7.9835e-01,\n",
       "           6.3338e-03, 3.8572e-03, 2.7878e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0601, 0.0074, 0.0593, 0.1523, 0.1959, 0.3633, 0.0945, 0.0555, 0.0117]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0726, 0.0114, 0.0637, 0.1558, 0.1436, 0.3409, 0.0891, 0.1055, 0.0174]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0873, 0.0243, 0.0857, 0.1418, 0.1802, 0.2543, 0.0916, 0.1006, 0.0343]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[5.4432e-03, 3.1443e-06, 1.3684e-03, 3.3509e-02, 2.4225e-02, 9.2877e-01,\n",
       "           4.5620e-03, 2.1069e-03, 1.3580e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.7651e-02, 4.8778e-04, 2.5753e-02, 1.4609e-01, 1.1653e-01, 6.3369e-01,\n",
       "           4.1731e-02, 1.7033e-02, 1.0313e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0428, 0.0027, 0.0305, 0.1323, 0.1782, 0.4999, 0.0663, 0.0436, 0.0037]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0652, 0.0049, 0.0672, 0.1455, 0.2048, 0.3686, 0.0772, 0.0586, 0.0080]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0716, 0.0075, 0.0725, 0.1613, 0.1747, 0.3259, 0.0804, 0.0916, 0.0146]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0857, 0.0205, 0.0808, 0.1478, 0.1823, 0.2649, 0.1076, 0.0818, 0.0286]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0615, 0.0104, 0.0843, 0.1266, 0.2101, 0.3197, 0.1021, 0.0679, 0.0174]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0896, 0.0287, 0.0818, 0.1375, 0.1690, 0.2618, 0.1067, 0.0910, 0.0339]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.4251e-03, 6.7285e-07, 1.2397e-03, 6.1020e-02, 3.8445e-02, 8.9126e-01,\n",
       "           4.0551e-03, 1.5471e-03, 6.2119e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0462, 0.0034, 0.0555, 0.1592, 0.1651, 0.4412, 0.0699, 0.0523, 0.0072]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.7823e-03, 1.2831e-06, 9.3926e-04, 6.5138e-02, 3.5684e-02, 8.9302e-01,\n",
       "           1.7761e-03, 1.6490e-03, 5.0643e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0394, 0.0007, 0.0340, 0.1188, 0.1455, 0.5704, 0.0527, 0.0362, 0.0022]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[4.3101e-04, 1.2084e-07, 1.4915e-04, 2.3956e-02, 1.6401e-02, 9.5714e-01,\n",
       "           1.7196e-03, 1.9850e-04, 4.6423e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0475, 0.0025, 0.0407, 0.1173, 0.1317, 0.5566, 0.0617, 0.0385, 0.0036]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[2.1328e-04, 1.4467e-08, 6.4575e-05, 9.2537e-03, 6.8090e-03, 9.8306e-01,\n",
       "           5.1251e-04, 8.3288e-05, 9.5502e-08]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0473, 0.0040, 0.0426, 0.1189, 0.1858, 0.4644, 0.0819, 0.0473, 0.0079]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0819, 0.0062, 0.0463, 0.1274, 0.1874, 0.3756, 0.1071, 0.0564, 0.0117]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0872, 0.0256, 0.0828, 0.1201, 0.1657, 0.2829, 0.1147, 0.0922, 0.0288]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0624, 0.0050, 0.0574, 0.1241, 0.1905, 0.3693, 0.1118, 0.0671, 0.0123]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0926, 0.0270, 0.0936, 0.1188, 0.1702, 0.2624, 0.1178, 0.0842, 0.0334]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0573, 0.0041, 0.0429, 0.1181, 0.2143, 0.4228, 0.0806, 0.0518, 0.0081]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.6853e-02, 5.6298e-04, 1.5784e-02, 9.1545e-02, 8.6926e-02, 7.3007e-01,\n",
       "           4.0239e-02, 1.7176e-02, 8.4273e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0900, 0.0081, 0.0639, 0.1238, 0.1747, 0.3919, 0.0763, 0.0585, 0.0128]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0354, 0.0015, 0.0308, 0.0847, 0.1599, 0.5967, 0.0559, 0.0333, 0.0020]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0966, 0.0293, 0.0932, 0.1156, 0.1698, 0.2276, 0.1187, 0.1082, 0.0410]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0264, 0.0010, 0.0198, 0.1171, 0.1896, 0.5609, 0.0596, 0.0238, 0.0018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0621, 0.0039, 0.0553, 0.0914, 0.2162, 0.4195, 0.0761, 0.0675, 0.0081]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0844, 0.0139, 0.0769, 0.1191, 0.2203, 0.2753, 0.1077, 0.0797, 0.0227]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0823, 0.0142, 0.0801, 0.1173, 0.2054, 0.3069, 0.0908, 0.0799, 0.0232]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0401, 0.0032, 0.0538, 0.1006, 0.2025, 0.4880, 0.0681, 0.0384, 0.0053]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0616, 0.0052, 0.0500, 0.0940, 0.1745, 0.4974, 0.0670, 0.0456, 0.0045]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0300, 0.0008, 0.0190, 0.0875, 0.2364, 0.5720, 0.0383, 0.0149, 0.0010]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0442, 0.0028, 0.0469, 0.1383, 0.1988, 0.4525, 0.0654, 0.0472, 0.0039]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0577, 0.0072, 0.0481, 0.1170, 0.2191, 0.4102, 0.0842, 0.0487, 0.0078]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0483, 0.0061, 0.0510, 0.1506, 0.1720, 0.4289, 0.0691, 0.0604, 0.0137]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.8162e-06, 2.2930e-12, 2.4271e-06, 7.3854e-04, 6.3580e-03, 9.9284e-01,\n",
       "           4.9737e-05, 7.2994e-06, 8.6266e-11]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0900, 0.0158, 0.0745, 0.1332, 0.1811, 0.2944, 0.0986, 0.0899, 0.0224]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0280, 0.0009, 0.0272, 0.0911, 0.2100, 0.5481, 0.0631, 0.0302, 0.0015]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0653, 0.0072, 0.0520, 0.1201, 0.2212, 0.3826, 0.0820, 0.0555, 0.0141]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0387, 0.0011, 0.0416, 0.1048, 0.2073, 0.5245, 0.0504, 0.0290, 0.0026]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0385, 0.0013, 0.0392, 0.0870, 0.1951, 0.5612, 0.0493, 0.0267, 0.0018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[5.9525e-03, 2.3720e-05, 4.3264e-03, 5.3099e-02, 1.7454e-01, 7.4670e-01,\n",
       "           1.1343e-02, 3.9583e-03, 6.0971e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0727, 0.0128, 0.0817, 0.1091, 0.1898, 0.3361, 0.0970, 0.0834, 0.0175]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0224, 0.0007, 0.0299, 0.1060, 0.1797, 0.5910, 0.0426, 0.0264, 0.0012]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0788, 0.0083, 0.0716, 0.1133, 0.1656, 0.3962, 0.0828, 0.0693, 0.0140]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0492, 0.0055, 0.0525, 0.1076, 0.2319, 0.3965, 0.0886, 0.0562, 0.0120]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[1.3127e-02, 1.9658e-04, 1.1524e-02, 1.3729e-01, 9.5579e-02, 7.0825e-01,\n",
       "           1.5768e-02, 1.7914e-02, 3.5064e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0640, 0.0061, 0.0541, 0.1266, 0.2086, 0.3989, 0.0905, 0.0429, 0.0083]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0554, 0.0026, 0.0346, 0.1478, 0.1811, 0.4774, 0.0481, 0.0496, 0.0034]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0683, 0.0113, 0.0666, 0.1368, 0.2092, 0.3226, 0.0850, 0.0800, 0.0202]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0600, 0.0046, 0.0578, 0.0987, 0.2086, 0.4085, 0.0789, 0.0706, 0.0123]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0534, 0.0050, 0.0486, 0.1256, 0.2325, 0.4091, 0.0851, 0.0357, 0.0050]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0465, 0.0007, 0.0284, 0.1410, 0.1566, 0.5308, 0.0583, 0.0360, 0.0018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0516, 0.0071, 0.0494, 0.1450, 0.2047, 0.4208, 0.0728, 0.0422, 0.0064]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0708, 0.0081, 0.0577, 0.1591, 0.1901, 0.3212, 0.1049, 0.0754, 0.0127]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.9246e-02, 4.0045e-04, 1.6510e-02, 1.3925e-01, 1.5192e-01, 6.2869e-01,\n",
       "           2.9120e-02, 1.3993e-02, 8.6685e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0427, 0.0012, 0.0278, 0.1234, 0.1351, 0.5840, 0.0495, 0.0344, 0.0018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0596, 0.0059, 0.0555, 0.1270, 0.2159, 0.3922, 0.0878, 0.0470, 0.0091]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0744, 0.0061, 0.0632, 0.1468, 0.2060, 0.3316, 0.0879, 0.0701, 0.0140]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0734, 0.0030, 0.0536, 0.1711, 0.1535, 0.4289, 0.0582, 0.0518, 0.0064]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1003, 0.0225, 0.0981, 0.1131, 0.1903, 0.2365, 0.1083, 0.0979, 0.0332]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0311, 0.0016, 0.0341, 0.1274, 0.1440, 0.5745, 0.0541, 0.0313, 0.0019]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0909, 0.0091, 0.0629, 0.1358, 0.1974, 0.3340, 0.0914, 0.0656, 0.0130]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.2209e-02, 7.0802e-05, 1.0742e-02, 1.1461e-01, 1.0202e-01, 7.2496e-01,\n",
       "           2.8516e-02, 6.6424e-03, 2.2536e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0625, 0.0098, 0.0788, 0.1307, 0.1963, 0.3609, 0.0744, 0.0705, 0.0160]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0351, 0.0017, 0.0331, 0.1567, 0.1640, 0.5482, 0.0387, 0.0207, 0.0018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0960, 0.0295, 0.1042, 0.1177, 0.1644, 0.2488, 0.1003, 0.0975, 0.0416]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0891, 0.0189, 0.0914, 0.1362, 0.1746, 0.2815, 0.0900, 0.0899, 0.0284]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0768, 0.0055, 0.0714, 0.1610, 0.1315, 0.3973, 0.0687, 0.0794, 0.0084]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.9307e-03, 3.2678e-06, 5.2637e-03, 7.3315e-02, 4.7274e-02, 8.5575e-01,\n",
       "           8.6316e-03, 5.7878e-03, 4.3043e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0658, 0.0055, 0.0727, 0.1459, 0.1771, 0.3839, 0.0755, 0.0639, 0.0096]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0791, 0.0131, 0.0765, 0.1558, 0.1660, 0.2916, 0.0997, 0.0957, 0.0225]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1007, 0.0261, 0.0981, 0.1229, 0.1636, 0.2330, 0.1184, 0.1050, 0.0321]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0321, 0.0014, 0.0415, 0.1342, 0.1877, 0.4849, 0.0730, 0.0416, 0.0035]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0909, 0.0283, 0.0978, 0.1340, 0.1710, 0.2381, 0.1125, 0.0966, 0.0308]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.1027, 0.0143, 0.0894, 0.1490, 0.1601, 0.2840, 0.0923, 0.0859, 0.0223]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1001, 0.0118, 0.0957, 0.1332, 0.1661, 0.2885, 0.1059, 0.0799, 0.0188]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.2112e-03, 5.9346e-06, 2.4503e-03, 5.8930e-02, 2.6802e-02, 8.9852e-01,\n",
       "           8.7037e-03, 1.3715e-03, 8.1023e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0712, 0.0056, 0.0546, 0.1786, 0.1697, 0.3722, 0.0782, 0.0605, 0.0095]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0885, 0.0193, 0.0886, 0.1283, 0.1931, 0.2631, 0.1177, 0.0772, 0.0241]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0600, 0.0036, 0.0437, 0.1582, 0.1400, 0.4391, 0.0758, 0.0713, 0.0081]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0888, 0.0280, 0.1025, 0.1346, 0.1739, 0.2109, 0.1232, 0.1061, 0.0321]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.6727e-05, 2.9860e-10, 1.0854e-04, 4.5540e-02, 1.3337e-02, 9.4032e-01,\n",
       "           6.3379e-04, 3.0102e-05, 6.6746e-09]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1036, 0.0473, 0.1112, 0.1233, 0.1517, 0.1913, 0.1136, 0.1024, 0.0556]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0968, 0.0359, 0.1096, 0.1189, 0.1605, 0.2083, 0.1139, 0.1106, 0.0454]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0912, 0.0229, 0.1013, 0.1318, 0.1819, 0.2390, 0.1172, 0.0905, 0.0242]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0721, 0.0104, 0.0794, 0.1469, 0.1671, 0.3230, 0.0807, 0.0999, 0.0206]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1011, 0.0197, 0.0802, 0.1453, 0.1499, 0.2951, 0.1033, 0.0805, 0.0249]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0901, 0.0145, 0.0810, 0.1389, 0.1589, 0.2918, 0.0933, 0.1037, 0.0278]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0913, 0.0356, 0.1094, 0.1257, 0.1709, 0.1959, 0.1206, 0.1080, 0.0427]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0734, 0.0117, 0.0750, 0.1512, 0.1582, 0.3462, 0.0984, 0.0713, 0.0146]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0655, 0.0139, 0.0806, 0.1282, 0.1662, 0.3072, 0.1277, 0.0907, 0.0201]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1038, 0.0335, 0.0986, 0.1334, 0.1564, 0.2097, 0.1107, 0.1136, 0.0402]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0951, 0.0281, 0.1109, 0.1243, 0.1600, 0.2168, 0.1158, 0.1031, 0.0461]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0553, 0.0044, 0.0591, 0.1814, 0.1348, 0.3988, 0.0996, 0.0586, 0.0081]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0880, 0.0231, 0.0907, 0.1390, 0.1798, 0.2378, 0.1350, 0.0817, 0.0250]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0967, 0.0374, 0.0994, 0.1208, 0.1854, 0.1838, 0.1253, 0.1053, 0.0459]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1101, 0.0517, 0.0996, 0.1235, 0.1525, 0.1713, 0.1191, 0.1157, 0.0564]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0913, 0.0354, 0.0927, 0.1192, 0.2079, 0.1921, 0.1282, 0.0938, 0.0394]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0795, 0.0108, 0.1096, 0.1282, 0.1859, 0.2479, 0.1180, 0.1004, 0.0198]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1143, 0.0238, 0.0914, 0.1548, 0.1670, 0.2165, 0.1091, 0.0935, 0.0297]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0908, 0.0334, 0.0983, 0.1245, 0.1749, 0.2033, 0.1228, 0.1112, 0.0409]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0937, 0.0329, 0.0970, 0.1136, 0.1829, 0.2139, 0.1219, 0.0993, 0.0448]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[1.4368e-02, 1.8603e-04, 2.8430e-02, 9.5073e-02, 1.9854e-01, 5.9114e-01,\n",
       "           4.7224e-02, 2.4552e-02, 4.8126e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.3616e-02, 2.1173e-04, 2.0069e-02, 9.8120e-02, 1.3305e-01, 6.8159e-01,\n",
       "           2.9999e-02, 2.2339e-02, 1.0126e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0831, 0.0049, 0.0739, 0.1424, 0.1618, 0.3354, 0.0880, 0.0999, 0.0106]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0335, 0.0017, 0.0505, 0.1622, 0.2086, 0.4059, 0.0899, 0.0447, 0.0029]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[8.1270e-03, 1.4251e-05, 6.2418e-03, 7.6829e-02, 1.4013e-01, 7.4336e-01,\n",
       "           2.0566e-02, 4.6611e-03, 7.9827e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0672, 0.0077, 0.0719, 0.1244, 0.1988, 0.3303, 0.1075, 0.0769, 0.0153]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0858, 0.0190, 0.0893, 0.1184, 0.1784, 0.2515, 0.1311, 0.0982, 0.0283]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0421, 0.0016, 0.0592, 0.1086, 0.2254, 0.4138, 0.0925, 0.0523, 0.0044]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0897, 0.0203, 0.0904, 0.1367, 0.1934, 0.2264, 0.1084, 0.1103, 0.0243]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.5221e-03, 1.0784e-06, 2.6836e-03, 3.5026e-02, 2.5537e-02, 9.2305e-01,\n",
       "           9.7508e-03, 2.4187e-03, 8.3190e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0386, 0.0014, 0.0347, 0.1523, 0.1562, 0.5108, 0.0676, 0.0360, 0.0023]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0957, 0.0277, 0.0949, 0.1212, 0.1625, 0.2000, 0.1339, 0.1227, 0.0415]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[1.6040e-02, 4.0320e-04, 2.5700e-02, 9.1616e-02, 1.6311e-01, 5.9462e-01,\n",
       "           7.7645e-02, 2.9605e-02, 1.2599e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0900, 0.0125, 0.0775, 0.1324, 0.1604, 0.3011, 0.1121, 0.0933, 0.0206]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0282, 0.0010, 0.0385, 0.1336, 0.1744, 0.4848, 0.0900, 0.0471, 0.0024]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0881, 0.0237, 0.0991, 0.1056, 0.1717, 0.2506, 0.1152, 0.1092, 0.0366]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0942, 0.0208, 0.0868, 0.1377, 0.1597, 0.2599, 0.1129, 0.0997, 0.0283]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0523, 0.0061, 0.0636, 0.1073, 0.1848, 0.3957, 0.1132, 0.0687, 0.0084]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0813, 0.0218, 0.0834, 0.1176, 0.1827, 0.2705, 0.1263, 0.0924, 0.0240]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[2.2920e-03, 7.0075e-07, 1.1610e-03, 3.4530e-02, 2.3427e-02, 9.3137e-01,\n",
       "           5.5792e-03, 1.6311e-03, 1.3043e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0949, 0.0228, 0.0876, 0.1214, 0.1609, 0.2543, 0.1225, 0.1046, 0.0309]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.8648e-04, 1.3539e-08, 2.4567e-04, 8.1128e-03, 5.7829e-03, 9.8395e-01,\n",
       "           1.2591e-03, 4.6725e-04, 1.4965e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0497, 0.0077, 0.0768, 0.0965, 0.2390, 0.3268, 0.1116, 0.0773, 0.0147]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0749, 0.0098, 0.0833, 0.0913, 0.2275, 0.2995, 0.1207, 0.0785, 0.0145]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0907, 0.0283, 0.1041, 0.1088, 0.1709, 0.2404, 0.1229, 0.1008, 0.0331]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[8.8445e-04, 9.0254e-08, 4.5316e-04, 9.0519e-03, 1.2230e-02, 9.7114e-01,\n",
       "           5.1886e-03, 1.0500e-03, 9.6520e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0978, 0.0341, 0.1009, 0.1137, 0.1774, 0.1842, 0.1268, 0.1181, 0.0472]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0716, 0.0060, 0.0622, 0.1219, 0.1873, 0.3514, 0.1098, 0.0789, 0.0110]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[1.1165e-03, 3.5691e-07, 1.0297e-03, 4.1795e-02, 5.3991e-02, 8.8261e-01,\n",
       "           1.7276e-02, 2.1749e-03, 1.6193e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0924, 0.0259, 0.0911, 0.1146, 0.1910, 0.2289, 0.1306, 0.0970, 0.0286]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0771, 0.0098, 0.0710, 0.1312, 0.1606, 0.3237, 0.1181, 0.0898, 0.0187]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1029, 0.0215, 0.0837, 0.0926, 0.2343, 0.2124, 0.1314, 0.0925, 0.0288]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0860, 0.0093, 0.0734, 0.1401, 0.1603, 0.3204, 0.1033, 0.0952, 0.0121]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.6616e-02, 1.8077e-04, 1.9768e-02, 1.0641e-01, 5.5606e-02, 6.9727e-01,\n",
       "           5.7520e-02, 2.6165e-02, 4.6786e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0319, 0.0011, 0.0308, 0.1040, 0.1343, 0.5680, 0.0968, 0.0310, 0.0022]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0931, 0.0218, 0.0888, 0.1192, 0.1627, 0.2609, 0.1367, 0.0905, 0.0264]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0772, 0.0116, 0.0766, 0.1201, 0.2022, 0.2728, 0.1182, 0.1019, 0.0194]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0651, 0.0070, 0.0716, 0.0984, 0.2632, 0.2868, 0.1346, 0.0631, 0.0101]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.2308e-02, 5.8348e-05, 7.9575e-03, 9.3742e-02, 1.3380e-01, 6.8125e-01,\n",
       "           5.3034e-02, 1.7641e-02, 2.1243e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0871, 0.0146, 0.0689, 0.1200, 0.2116, 0.3092, 0.1024, 0.0725, 0.0137]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0826, 0.0184, 0.0968, 0.1009, 0.2198, 0.2225, 0.1277, 0.1041, 0.0273]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0573, 0.0052, 0.0597, 0.1242, 0.1557, 0.4121, 0.0953, 0.0803, 0.0102]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.7785e-02, 3.0777e-04, 1.5647e-02, 1.0680e-01, 1.0254e-01, 6.4832e-01,\n",
       "           7.3165e-02, 3.4354e-02, 1.0917e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1065, 0.0250, 0.0906, 0.1138, 0.1608, 0.2316, 0.1201, 0.1148, 0.0366]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1114, 0.0280, 0.0837, 0.1219, 0.1617, 0.2195, 0.1243, 0.1141, 0.0353]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0893, 0.0089, 0.0637, 0.1392, 0.1666, 0.3086, 0.1081, 0.0980, 0.0176]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0280, 0.0007, 0.0249, 0.1260, 0.1733, 0.5370, 0.0656, 0.0428, 0.0015]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0679, 0.0062, 0.0675, 0.1069, 0.1693, 0.3913, 0.0990, 0.0805, 0.0115]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0813, 0.0158, 0.0756, 0.1159, 0.1934, 0.2754, 0.1223, 0.0981, 0.0222]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0833, 0.0204, 0.0826, 0.1153, 0.1840, 0.2727, 0.1225, 0.0910, 0.0283]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0997, 0.0264, 0.0904, 0.1211, 0.1681, 0.2302, 0.1060, 0.1126, 0.0455]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1008, 0.0277, 0.0948, 0.1017, 0.1758, 0.2188, 0.1246, 0.1187, 0.0371]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0946, 0.0106, 0.0807, 0.1145, 0.1624, 0.3020, 0.1246, 0.0970, 0.0137]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[5.9159e-03, 3.1939e-05, 3.2650e-03, 4.4915e-02, 4.8543e-02, 8.6180e-01,\n",
       "           2.5486e-02, 9.9636e-03, 7.7341e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0866, 0.0078, 0.0879, 0.1106, 0.1666, 0.3190, 0.0988, 0.1074, 0.0153]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0966, 0.0297, 0.0966, 0.0951, 0.1782, 0.2379, 0.1281, 0.1068, 0.0308]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[7.6997e-03, 2.2290e-04, 1.2393e-02, 7.0858e-02, 1.3513e-01, 7.0835e-01,\n",
       "           4.6153e-02, 1.8424e-02, 7.6963e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0372, 0.0013, 0.0302, 0.1089, 0.1280, 0.5358, 0.1070, 0.0484, 0.0033]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0531, 0.0035, 0.0573, 0.0906, 0.2166, 0.3889, 0.0934, 0.0873, 0.0092]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0375, 0.0010, 0.0335, 0.0910, 0.1614, 0.5576, 0.0625, 0.0533, 0.0022]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0983, 0.0368, 0.0993, 0.1125, 0.1694, 0.2006, 0.1142, 0.1149, 0.0539]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0876, 0.0091, 0.0595, 0.1375, 0.1562, 0.3253, 0.1110, 0.1012, 0.0126]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0474, 0.0026, 0.0443, 0.1269, 0.1676, 0.4418, 0.0940, 0.0701, 0.0053]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[3.7353e-07, 5.7695e-15, 1.0336e-07, 2.8528e-04, 7.6066e-05, 9.9959e-01,\n",
       "           4.4816e-05, 1.5243e-06, 6.5039e-13]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0675, 0.0038, 0.0539, 0.1063, 0.1885, 0.3558, 0.1003, 0.1103, 0.0136]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0995, 0.0250, 0.0956, 0.1101, 0.1707, 0.2182, 0.1256, 0.1175, 0.0377]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0656, 0.0037, 0.0416, 0.1190, 0.1999, 0.3590, 0.1052, 0.0992, 0.0068]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0876, 0.0219, 0.0947, 0.1114, 0.1831, 0.2267, 0.1312, 0.1068, 0.0365]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0543, 0.0045, 0.0533, 0.1147, 0.1583, 0.4423, 0.0998, 0.0630, 0.0098]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.4268e-03, 4.6720e-07, 6.4393e-04, 4.8895e-02, 1.9255e-02, 9.1924e-01,\n",
       "           8.0745e-03, 2.4584e-03, 4.1139e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.6752e-03, 6.7114e-06, 3.1123e-03, 4.7285e-02, 5.0628e-02, 8.6070e-01,\n",
       "           2.1109e-02, 1.4370e-02, 1.0898e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0575, 0.0054, 0.0569, 0.1321, 0.1611, 0.3555, 0.1199, 0.0991, 0.0126]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1105, 0.0285, 0.0935, 0.1228, 0.1536, 0.2125, 0.1295, 0.1104, 0.0388]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1043, 0.0389, 0.0991, 0.1172, 0.1491, 0.1947, 0.1284, 0.1178, 0.0504]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0810, 0.0213, 0.0881, 0.1213, 0.1952, 0.2409, 0.1332, 0.0983, 0.0207]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0508, 0.0034, 0.0536, 0.1153, 0.1663, 0.4315, 0.0991, 0.0717, 0.0082]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0593, 0.0042, 0.0640, 0.1269, 0.1498, 0.4084, 0.1177, 0.0620, 0.0077]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0600, 0.0024, 0.0524, 0.1190, 0.1119, 0.4918, 0.0841, 0.0711, 0.0073]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0646, 0.0033, 0.0551, 0.1108, 0.1715, 0.4211, 0.1005, 0.0673, 0.0059]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0897, 0.0062, 0.0582, 0.1438, 0.1668, 0.3545, 0.0973, 0.0721, 0.0115]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0907, 0.0202, 0.0863, 0.1322, 0.1588, 0.2712, 0.1089, 0.1006, 0.0312]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0604, 0.0049, 0.0409, 0.1596, 0.1217, 0.4481, 0.0850, 0.0711, 0.0083]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0872, 0.0059, 0.0705, 0.1339, 0.1288, 0.3612, 0.1120, 0.0884, 0.0123]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0900, 0.0170, 0.0906, 0.1354, 0.1851, 0.2276, 0.1156, 0.1070, 0.0317]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0542, 0.0032, 0.0503, 0.1350, 0.1460, 0.4586, 0.0889, 0.0590, 0.0050]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[1.0811e-02, 5.4054e-05, 9.3744e-03, 7.5009e-02, 4.6837e-02, 8.2909e-01,\n",
       "           2.0704e-02, 7.9453e-03, 1.7038e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0788, 0.0169, 0.0931, 0.1320, 0.1947, 0.2553, 0.1225, 0.0839, 0.0227]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[8.1149e-03, 3.7612e-05, 8.5657e-03, 1.0992e-01, 7.6846e-02, 7.6137e-01,\n",
       "           2.7724e-02, 7.2835e-03, 1.4314e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0474, 0.0035, 0.0610, 0.1263, 0.2177, 0.3624, 0.1013, 0.0722, 0.0082]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0458, 0.0020, 0.0538, 0.0997, 0.1549, 0.4961, 0.0810, 0.0591, 0.0076]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0326, 0.0017, 0.0421, 0.1260, 0.1518, 0.5121, 0.0867, 0.0435, 0.0034]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0580, 0.0022, 0.0523, 0.1693, 0.1790, 0.3799, 0.0882, 0.0662, 0.0049]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0868, 0.0212, 0.0971, 0.1320, 0.1741, 0.2455, 0.1187, 0.0947, 0.0299]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0470, 0.0068, 0.0688, 0.1024, 0.2194, 0.3640, 0.1191, 0.0608, 0.0117]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0840, 0.0206, 0.1038, 0.1120, 0.1990, 0.2355, 0.1094, 0.1012, 0.0343]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.3623e-02, 2.0746e-04, 1.5912e-02, 1.2704e-01, 6.0358e-02, 7.0189e-01,\n",
       "           4.1678e-02, 2.8704e-02, 5.8630e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[4.8285e-02, 4.6788e-04, 2.7925e-02, 1.9006e-01, 1.2382e-01, 5.0009e-01,\n",
       "           7.7816e-02, 3.0545e-02, 9.9719e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0408, 0.0022, 0.0753, 0.1063, 0.2753, 0.3488, 0.0930, 0.0524, 0.0060]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0913, 0.0198, 0.0920, 0.1306, 0.1878, 0.2445, 0.1163, 0.0882, 0.0295]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[1.4708e-02, 9.7714e-05, 2.5191e-02, 1.0275e-01, 1.7510e-01, 5.9959e-01,\n",
       "           5.9874e-02, 2.2239e-02, 4.4758e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[1.7086e-02, 1.9330e-04, 2.2845e-02, 9.5299e-02, 1.4435e-01, 6.5512e-01,\n",
       "           4.5925e-02, 1.8714e-02, 4.6421e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0655, 0.0044, 0.0665, 0.1320, 0.1935, 0.3731, 0.0886, 0.0695, 0.0071]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0541, 0.0012, 0.0564, 0.1515, 0.1735, 0.4067, 0.0835, 0.0685, 0.0046]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0870, 0.0172, 0.1112, 0.1045, 0.2208, 0.2164, 0.1062, 0.1059, 0.0310]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0578, 0.0055, 0.0875, 0.1037, 0.2693, 0.2970, 0.1110, 0.0567, 0.0115]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.6911e-02, 2.1569e-04, 2.2580e-02, 1.0265e-01, 1.5388e-01, 6.3877e-01,\n",
       "           4.4006e-02, 2.0296e-02, 6.9228e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.0367e-02, 6.4999e-05, 2.0096e-02, 1.0162e-01, 1.6315e-01, 6.4748e-01,\n",
       "           4.4464e-02, 1.2581e-02, 1.7173e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0489, 0.0054, 0.0684, 0.1446, 0.2475, 0.3029, 0.1096, 0.0639, 0.0089]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0445, 0.0025, 0.0707, 0.1124, 0.2406, 0.3667, 0.0835, 0.0739, 0.0052]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0879, 0.0169, 0.0929, 0.1282, 0.2049, 0.2344, 0.1295, 0.0826, 0.0227]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1024, 0.0124, 0.0779, 0.1230, 0.2291, 0.2415, 0.1130, 0.0789, 0.0217]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[5.4176e-07, 2.2320e-14, 2.1612e-07, 2.2857e-03, 3.9561e-04, 9.9718e-01,\n",
       "           1.3615e-04, 9.0908e-07, 2.8579e-12]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0732, 0.0155, 0.0884, 0.1119, 0.2564, 0.2384, 0.1152, 0.0794, 0.0217]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0525, 0.0035, 0.0526, 0.1157, 0.2092, 0.3967, 0.1084, 0.0554, 0.0061]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0407, 0.0023, 0.0645, 0.1212, 0.2824, 0.3357, 0.0901, 0.0563, 0.0068]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0418, 0.0012, 0.0620, 0.1112, 0.2219, 0.4241, 0.0940, 0.0395, 0.0043]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0545, 0.0055, 0.0708, 0.1190, 0.2465, 0.3078, 0.1246, 0.0631, 0.0083]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0828, 0.0134, 0.0967, 0.1160, 0.2438, 0.2168, 0.0990, 0.1085, 0.0230]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0871, 0.0204, 0.1035, 0.1170, 0.1966, 0.2119, 0.1236, 0.1058, 0.0342]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[1.7175e-03, 5.0588e-07, 2.7210e-03, 4.2988e-02, 4.5778e-02, 8.9225e-01,\n",
       "           1.1728e-02, 2.8122e-03, 6.6120e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0505, 0.0036, 0.0699, 0.1168, 0.2406, 0.3397, 0.1062, 0.0640, 0.0086]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0294, 0.0023, 0.0603, 0.1146, 0.2229, 0.4158, 0.0976, 0.0507, 0.0063]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0694, 0.0092, 0.0997, 0.1049, 0.2453, 0.2497, 0.1277, 0.0772, 0.0169]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0679, 0.0097, 0.0766, 0.1200, 0.2186, 0.2785, 0.1183, 0.0917, 0.0188]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0737, 0.0147, 0.0915, 0.1195, 0.2124, 0.2506, 0.1245, 0.0893, 0.0238]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[9.3109e-03, 4.9946e-05, 1.4204e-02, 1.0392e-01, 1.2136e-01, 6.8483e-01,\n",
       "           4.8451e-02, 1.7622e-02, 2.4035e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0623, 0.0041, 0.0659, 0.1426, 0.1763, 0.3341, 0.1279, 0.0778, 0.0091]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0646, 0.0041, 0.0729, 0.1470, 0.2122, 0.3149, 0.0930, 0.0814, 0.0099]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.0691e-04, 7.3386e-08, 1.6676e-03, 5.7655e-02, 1.0786e-01, 8.1624e-01,\n",
       "           1.5558e-02, 7.1582e-04, 1.2455e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0895, 0.0204, 0.1057, 0.1211, 0.1971, 0.1972, 0.1341, 0.1077, 0.0272]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0706, 0.0077, 0.0819, 0.1185, 0.2045, 0.2999, 0.1314, 0.0702, 0.0153]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[3.3165e-02, 2.6503e-04, 2.5067e-02, 1.9928e-01, 1.0835e-01, 5.3649e-01,\n",
       "           6.9466e-02, 2.7250e-02, 6.7056e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.6869e-02, 3.1362e-04, 3.9930e-02, 1.2672e-01, 1.4428e-01, 5.2683e-01,\n",
       "           1.0357e-01, 3.0718e-02, 7.7290e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.5203e-07, 4.8981e-16, 5.2992e-08, 3.4080e-03, 2.9636e-04, 9.9627e-01,\n",
       "           2.4790e-05, 1.6476e-07, 1.5931e-13]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[6.2410e-04, 1.1237e-06, 2.4186e-03, 7.8492e-02, 1.3182e-01, 7.6124e-01,\n",
       "           2.4108e-02, 1.2977e-03, 4.4133e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0636, 0.0087, 0.0857, 0.1317, 0.2155, 0.2617, 0.1243, 0.0929, 0.0159]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0927, 0.0154, 0.0907, 0.1137, 0.2110, 0.2354, 0.1344, 0.0873, 0.0193]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0550, 0.0027, 0.0760, 0.1145, 0.2386, 0.3446, 0.0991, 0.0644, 0.0051]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0755, 0.0078, 0.0773, 0.1164, 0.2363, 0.2573, 0.1337, 0.0836, 0.0120]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0485, 0.0035, 0.0603, 0.0942, 0.2802, 0.3142, 0.1328, 0.0603, 0.0060]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0515, 0.0037, 0.0771, 0.1538, 0.2065, 0.3104, 0.1042, 0.0837, 0.0090]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0688, 0.0095, 0.0857, 0.1257, 0.2455, 0.2429, 0.1154, 0.0874, 0.0192]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0474, 0.0023, 0.0540, 0.1004, 0.2744, 0.3492, 0.1047, 0.0635, 0.0041]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.5990e-04, 2.3059e-08, 7.0870e-04, 2.7269e-02, 3.5484e-02, 9.2689e-01,\n",
       "           8.7109e-03, 5.7417e-04, 3.1722e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0512, 0.0041, 0.0684, 0.1127, 0.2463, 0.3206, 0.1209, 0.0691, 0.0067]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[2.7664e-02, 2.4165e-04, 1.8883e-02, 1.5936e-01, 1.8246e-01, 4.8703e-01,\n",
       "           6.8008e-02, 5.5708e-02, 6.3770e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0802, 0.0162, 0.0864, 0.0907, 0.3034, 0.1775, 0.1420, 0.0856, 0.0180]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0730, 0.0091, 0.0953, 0.1072, 0.2929, 0.2063, 0.1137, 0.0899, 0.0126]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0925, 0.0307, 0.1038, 0.1072, 0.2107, 0.1792, 0.1328, 0.1081, 0.0351]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1041, 0.0224, 0.1001, 0.1221, 0.2127, 0.1781, 0.1244, 0.1015, 0.0345]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0674, 0.0051, 0.0873, 0.1222, 0.2626, 0.2407, 0.1150, 0.0898, 0.0099]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0400, 0.0021, 0.0499, 0.1202, 0.2565, 0.3433, 0.1190, 0.0637, 0.0052]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0743, 0.0209, 0.1102, 0.0890, 0.2707, 0.1765, 0.1153, 0.1107, 0.0322]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0525, 0.0051, 0.0873, 0.0740, 0.4145, 0.1572, 0.1152, 0.0845, 0.0096]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0995, 0.0065, 0.0819, 0.1037, 0.2572, 0.2027, 0.1146, 0.1229, 0.0109]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1044, 0.0443, 0.1151, 0.1025, 0.1870, 0.1543, 0.1227, 0.1174, 0.0524]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1008, 0.0392, 0.1028, 0.1133, 0.1899, 0.1473, 0.1259, 0.1319, 0.0489]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.2144e-02, 9.3604e-05, 3.2464e-02, 1.0779e-01, 2.8476e-01, 3.6789e-01,\n",
       "           9.0771e-02, 9.3553e-02, 5.2131e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0799, 0.0221, 0.1025, 0.1063, 0.2586, 0.1704, 0.1281, 0.1066, 0.0254]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1139, 0.0308, 0.1086, 0.1024, 0.2047, 0.1524, 0.1369, 0.1150, 0.0352]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1013, 0.0247, 0.1003, 0.0941, 0.2439, 0.1566, 0.1228, 0.1185, 0.0378]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1052, 0.0227, 0.1109, 0.1034, 0.2232, 0.1575, 0.1170, 0.1232, 0.0370]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1076, 0.0342, 0.1073, 0.1022, 0.2175, 0.1379, 0.1468, 0.1081, 0.0386]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1300, 0.0199, 0.0981, 0.1081, 0.2442, 0.1508, 0.1144, 0.1129, 0.0217]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0982, 0.0401, 0.1048, 0.0976, 0.2231, 0.1396, 0.1315, 0.1162, 0.0489]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1020, 0.0351, 0.1094, 0.0973, 0.1898, 0.1650, 0.1243, 0.1286, 0.0486]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0715, 0.0044, 0.0771, 0.0924, 0.3027, 0.2382, 0.1270, 0.0796, 0.0071]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1091, 0.0262, 0.0895, 0.1027, 0.2236, 0.1629, 0.1305, 0.1253, 0.0303]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0860, 0.0165, 0.0950, 0.0920, 0.2505, 0.1919, 0.1283, 0.1094, 0.0305]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.1473e-02, 3.6097e-04, 2.5544e-02, 6.2497e-02, 3.9972e-01, 3.4227e-01,\n",
       "           9.3792e-02, 4.2964e-02, 1.3820e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1023, 0.0287, 0.0897, 0.1129, 0.2052, 0.1818, 0.1316, 0.1136, 0.0341]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0788, 0.0116, 0.0873, 0.0886, 0.3048, 0.1936, 0.1345, 0.0851, 0.0156]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0820, 0.0104, 0.0971, 0.1084, 0.2319, 0.2197, 0.1354, 0.1010, 0.0139]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[2.7931e-03, 7.7134e-07, 1.9165e-03, 9.4313e-02, 1.9546e-01, 6.4798e-01,\n",
       "           4.5701e-02, 1.1830e-02, 1.6143e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1074, 0.0388, 0.0999, 0.0953, 0.2073, 0.1503, 0.1299, 0.1249, 0.0462]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.9926e-03, 8.9203e-07, 6.4528e-03, 6.8655e-02, 3.0564e-01, 5.5360e-01,\n",
       "           5.0974e-02, 1.1681e-02, 1.0795e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1199, 0.0207, 0.1091, 0.1056, 0.2126, 0.1614, 0.1268, 0.1176, 0.0263]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0859, 0.0060, 0.0896, 0.0936, 0.3138, 0.1739, 0.1177, 0.1087, 0.0109]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0647, 0.0073, 0.0857, 0.0734, 0.3632, 0.1645, 0.1277, 0.1008, 0.0126]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[5.1832e-03, 3.8668e-06, 8.0238e-03, 1.0945e-01, 2.0991e-01, 6.0686e-01,\n",
       "           4.2355e-02, 1.8199e-02, 1.0463e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0447, 0.0012, 0.0564, 0.0799, 0.2565, 0.3989, 0.1116, 0.0476, 0.0033]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0910, 0.0345, 0.1097, 0.1133, 0.1781, 0.1864, 0.1197, 0.1198, 0.0475]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1041, 0.0175, 0.1058, 0.0966, 0.2018, 0.1944, 0.1205, 0.1277, 0.0316]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0404, 0.0010, 0.0326, 0.1266, 0.2324, 0.4058, 0.0946, 0.0639, 0.0027]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0859, 0.0058, 0.1056, 0.0881, 0.2488, 0.2574, 0.1185, 0.0781, 0.0119]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0620, 0.0031, 0.0453, 0.1210, 0.2414, 0.3461, 0.1220, 0.0543, 0.0049]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.5385e-03, 3.2538e-06, 2.7868e-03, 8.8315e-02, 8.8349e-02, 7.8382e-01,\n",
       "           2.5610e-02, 7.5539e-03, 2.2208e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1083, 0.0129, 0.1104, 0.0986, 0.2079, 0.2245, 0.1277, 0.0889, 0.0209]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0973, 0.0081, 0.0951, 0.1134, 0.2204, 0.2235, 0.1156, 0.1087, 0.0180]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0529, 0.0042, 0.0698, 0.1448, 0.2025, 0.3266, 0.1106, 0.0811, 0.0076]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1059, 0.0296, 0.1001, 0.1185, 0.1698, 0.2046, 0.1193, 0.1103, 0.0420]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0612, 0.0056, 0.0899, 0.1213, 0.2204, 0.3134, 0.1000, 0.0783, 0.0100]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.5863e-02, 9.5941e-05, 1.2847e-02, 1.1690e-01, 8.6257e-02, 7.0125e-01,\n",
       "           3.7886e-02, 1.8558e-02, 3.5094e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[1.8516e-02, 4.6675e-04, 3.8391e-02, 1.1118e-01, 2.3426e-01, 4.9378e-01,\n",
       "           6.8653e-02, 3.3754e-02, 9.9404e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0427, 0.0010, 0.0415, 0.1075, 0.2132, 0.4515, 0.0851, 0.0543, 0.0031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0639, 0.0039, 0.0647, 0.1084, 0.2331, 0.3476, 0.1100, 0.0619, 0.0065]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0759, 0.0072, 0.0843, 0.1186, 0.1784, 0.3123, 0.1105, 0.0979, 0.0148]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0669, 0.0050, 0.0819, 0.1149, 0.2157, 0.3069, 0.1226, 0.0788, 0.0072]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[9.8415e-03, 2.4956e-05, 8.3376e-03, 1.1613e-01, 8.3731e-02, 7.1423e-01,\n",
       "           3.8752e-02, 2.8769e-02, 1.7953e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0775, 0.0138, 0.0885, 0.1363, 0.1913, 0.2534, 0.1087, 0.1061, 0.0244]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0258, 0.0007, 0.0360, 0.1198, 0.1083, 0.5989, 0.0657, 0.0434, 0.0013]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[3.5079e-03, 1.3220e-05, 5.1300e-03, 6.7412e-02, 4.2691e-02, 8.5199e-01,\n",
       "           2.3475e-02, 5.7262e-03, 5.6945e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[7.0444e-10, 7.1713e-18, 1.0387e-08, 6.2350e-05, 2.5873e-06, 9.9993e-01,\n",
       "           2.2927e-06, 2.7043e-08, 7.5059e-16]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.3887e-03, 2.1214e-06, 1.8871e-03, 5.4368e-02, 1.9224e-02, 9.0862e-01,\n",
       "           9.9172e-03, 3.5748e-03, 1.4472e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[4.0677e-03, 6.5503e-06, 2.6923e-03, 1.0706e-01, 3.2269e-02, 8.3219e-01,\n",
       "           1.5061e-02, 6.6265e-03, 3.4436e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[1.0769e-02, 4.5637e-05, 1.3453e-02, 7.0605e-02, 8.9452e-02, 7.6650e-01,\n",
       "           3.0379e-02, 1.8569e-02, 2.3133e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0595, 0.0036, 0.0619, 0.1607, 0.1371, 0.3992, 0.0901, 0.0807, 0.0072]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0597, 0.0058, 0.0884, 0.1346, 0.1748, 0.3503, 0.0958, 0.0815, 0.0091]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0329, 0.0013, 0.0413, 0.1183, 0.1452, 0.5466, 0.0668, 0.0447, 0.0030]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.0311e-05, 2.2504e-10, 4.2295e-05, 3.0573e-02, 1.2043e-03, 9.6769e-01,\n",
       "           3.1589e-04, 1.5360e-04, 6.3623e-09]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.0998e-03, 3.3322e-07, 9.9497e-04, 3.7305e-02, 8.7372e-03, 9.3760e-01,\n",
       "           8.9852e-03, 4.2697e-03, 4.9726e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.4477e-02, 6.7981e-05, 1.1033e-02, 1.0739e-01, 8.0783e-02, 7.3643e-01,\n",
       "           3.5594e-02, 1.4048e-02, 1.7565e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[2.6062e-03, 8.7317e-06, 3.4537e-03, 1.1920e-01, 1.0175e-01, 7.5274e-01,\n",
       "           1.4403e-02, 5.8138e-03, 2.3115e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0956, 0.0177, 0.0891, 0.1390, 0.1702, 0.2504, 0.1185, 0.0962, 0.0231]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0878, 0.0184, 0.0819, 0.1199, 0.1863, 0.2860, 0.1082, 0.0877, 0.0239]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[1.3884e-02, 9.1714e-05, 1.4851e-02, 9.2978e-02, 8.9825e-02, 7.2477e-01,\n",
       "           3.2364e-02, 3.1019e-02, 2.2142e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0889, 0.0122, 0.0992, 0.1552, 0.1549, 0.2637, 0.1074, 0.0984, 0.0202]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0678, 0.0017, 0.0465, 0.1390, 0.1059, 0.4918, 0.0757, 0.0674, 0.0043]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0880, 0.0172, 0.0978, 0.1167, 0.1898, 0.2734, 0.1090, 0.0866, 0.0214]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0664, 0.0043, 0.0778, 0.1582, 0.1355, 0.3470, 0.1076, 0.0944, 0.0089]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[4.1102e-03, 3.6902e-06, 5.7054e-03, 8.4879e-02, 1.9997e-02, 8.6807e-01,\n",
       "           1.0963e-02, 6.2410e-03, 2.8610e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0467, 0.0044, 0.0728, 0.1476, 0.2165, 0.3461, 0.0963, 0.0620, 0.0076]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0260, 0.0005, 0.0236, 0.2170, 0.1107, 0.4953, 0.0757, 0.0503, 0.0009]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0760, 0.0071, 0.0692, 0.1618, 0.1886, 0.2763, 0.1071, 0.1006, 0.0133]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1049, 0.0353, 0.1085, 0.1148, 0.1838, 0.1859, 0.1180, 0.1115, 0.0372]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0989, 0.0049, 0.0919, 0.1223, 0.1992, 0.2821, 0.1006, 0.0903, 0.0099]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0418, 0.0011, 0.0343, 0.1372, 0.1247, 0.5458, 0.0694, 0.0424, 0.0033]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[6.0434e-04, 6.9120e-08, 4.9615e-04, 8.6754e-02, 7.7581e-03, 8.9701e-01,\n",
       "           4.2065e-03, 3.1731e-03, 1.3034e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0980, 0.0108, 0.1059, 0.1130, 0.2006, 0.2390, 0.1200, 0.0931, 0.0195]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1023, 0.0249, 0.1054, 0.1197, 0.1953, 0.1806, 0.1194, 0.1180, 0.0344]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.1065, 0.0245, 0.1171, 0.1052, 0.1876, 0.1903, 0.1243, 0.1069, 0.0377]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[2.2891e-03, 9.2138e-07, 2.2220e-03, 1.7685e-01, 3.5359e-02, 7.6637e-01,\n",
       "           1.3373e-02, 3.5212e-03, 6.4389e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1156, 0.0227, 0.1192, 0.1147, 0.1734, 0.1992, 0.1079, 0.1125, 0.0348]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.9055e-04, 3.5681e-08, 3.5296e-04, 6.6401e-02, 1.7277e-02, 9.1192e-01,\n",
       "           2.5999e-03, 1.1568e-03, 4.5870e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0923, 0.0104, 0.0904, 0.1401, 0.1626, 0.2781, 0.1101, 0.0914, 0.0246]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1119, 0.0166, 0.1344, 0.0987, 0.2165, 0.1741, 0.1091, 0.1057, 0.0330]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0905, 0.0119, 0.1102, 0.1103, 0.2200, 0.2196, 0.1201, 0.0980, 0.0195]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0974, 0.0174, 0.1123, 0.1072, 0.2046, 0.2004, 0.1306, 0.0987, 0.0314]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0977, 0.0253, 0.1059, 0.1207, 0.1875, 0.1938, 0.1097, 0.1193, 0.0401]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.4275e-05, 3.0579e-10, 1.2933e-05, 1.5366e-02, 1.3090e-03, 9.8279e-01,\n",
       "           4.5582e-04, 3.1928e-05, 5.5483e-09]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1012, 0.0064, 0.0806, 0.1239, 0.2296, 0.2703, 0.1006, 0.0756, 0.0118]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.0595e-02, 5.1301e-04, 2.4407e-02, 1.8251e-01, 1.0728e-01, 5.4869e-01,\n",
       "           7.7425e-02, 2.6856e-02, 1.7343e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0947, 0.0112, 0.1060, 0.1270, 0.2148, 0.2550, 0.1059, 0.0691, 0.0165]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0767, 0.0048, 0.0586, 0.1772, 0.1474, 0.3645, 0.0936, 0.0681, 0.0092]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[3.7302e-03, 1.2483e-05, 6.1699e-03, 1.2581e-01, 1.0991e-01, 7.2828e-01,\n",
       "           2.0612e-02, 5.4066e-03, 7.4213e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0926, 0.0286, 0.1057, 0.1244, 0.1925, 0.2050, 0.1274, 0.0901, 0.0337]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0476, 0.0011, 0.0357, 0.1753, 0.1493, 0.4538, 0.0736, 0.0596, 0.0040]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0615, 0.0030, 0.0590, 0.1332, 0.1977, 0.3816, 0.0933, 0.0634, 0.0075]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0745, 0.0038, 0.0582, 0.1569, 0.1946, 0.3484, 0.0922, 0.0655, 0.0060]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0393, 0.0008, 0.0313, 0.2029, 0.1268, 0.4891, 0.0557, 0.0510, 0.0033]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.8835e-05, 2.2652e-11, 1.2516e-05, 5.2833e-02, 1.7567e-03, 9.4496e-01,\n",
       "           3.6673e-04, 5.2643e-05, 2.9691e-10]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0285, 0.0005, 0.0215, 0.2284, 0.1090, 0.5140, 0.0655, 0.0308, 0.0017]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[4.4803e-03, 6.8495e-05, 5.3047e-03, 2.2135e-01, 6.2316e-02, 6.7630e-01,\n",
       "           1.9128e-02, 1.0881e-02, 1.7490e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0823, 0.0138, 0.0877, 0.1367, 0.1824, 0.2584, 0.1185, 0.0972, 0.0231]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1009, 0.0249, 0.1013, 0.1394, 0.1533, 0.2303, 0.1118, 0.1013, 0.0368]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0748, 0.0148, 0.0756, 0.1519, 0.1888, 0.2677, 0.1132, 0.0916, 0.0217]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0679, 0.0144, 0.0894, 0.1526, 0.1733, 0.2665, 0.1187, 0.0905, 0.0266]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.4722e-02, 5.6117e-04, 2.7263e-02, 1.6292e-01, 1.3630e-01, 5.7504e-01,\n",
       "           4.1107e-02, 3.0220e-02, 1.8711e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0790, 0.0100, 0.0847, 0.1648, 0.1829, 0.2798, 0.1026, 0.0837, 0.0125]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[2.1835e-02, 3.2765e-04, 1.8945e-02, 2.9743e-01, 9.6197e-02, 4.9233e-01,\n",
       "           4.5319e-02, 2.6783e-02, 8.3265e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0731, 0.0104, 0.0799, 0.1666, 0.1622, 0.3226, 0.0876, 0.0784, 0.0193]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[6.1646e-03, 4.6419e-05, 6.8653e-03, 2.6123e-01, 6.9545e-02, 6.2841e-01,\n",
       "           1.9535e-02, 8.0310e-03, 1.7041e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0602, 0.0071, 0.0730, 0.1485, 0.2006, 0.3394, 0.0886, 0.0674, 0.0150]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.8084e-02, 4.4121e-04, 3.1435e-02, 2.0229e-01, 1.5840e-01, 4.9253e-01,\n",
       "           5.1216e-02, 3.4356e-02, 1.2547e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0324, 0.0014, 0.0414, 0.1923, 0.1490, 0.4790, 0.0548, 0.0464, 0.0034]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0323, 0.0014, 0.0271, 0.2367, 0.1668, 0.4393, 0.0581, 0.0350, 0.0032]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[3.8600e-03, 1.0620e-05, 4.4141e-03, 2.0484e-01, 5.5908e-02, 7.0997e-01,\n",
       "           1.2309e-02, 8.6411e-03, 4.3176e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[6.0688e-03, 6.5275e-05, 1.1643e-02, 1.7902e-01, 8.3932e-02, 6.6886e-01,\n",
       "           3.3561e-02, 1.6514e-02, 3.3803e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0412, 0.0015, 0.0502, 0.1829, 0.2399, 0.3693, 0.0632, 0.0467, 0.0053]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.2636e-02, 2.6852e-04, 1.2798e-02, 3.3461e-01, 1.2990e-01, 4.6446e-01,\n",
       "           2.1808e-02, 2.2880e-02, 6.3752e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.9411e-02, 3.5399e-04, 1.1088e-02, 2.2676e-01, 6.7245e-02, 6.0513e-01,\n",
       "           4.8413e-02, 2.0955e-02, 6.4775e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[1.8343e-03, 4.5441e-06, 3.7663e-03, 2.8216e-01, 2.1070e-02, 6.7757e-01,\n",
       "           9.7356e-03, 3.8480e-03, 9.9684e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0728, 0.0105, 0.0872, 0.1682, 0.1864, 0.2849, 0.0933, 0.0804, 0.0162]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0644, 0.0106, 0.0701, 0.1930, 0.1720, 0.2824, 0.0987, 0.0872, 0.0215]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0478, 0.0026, 0.0502, 0.1787, 0.1921, 0.3732, 0.0896, 0.0601, 0.0057]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0566, 0.0056, 0.0639, 0.1912, 0.1543, 0.3559, 0.0910, 0.0718, 0.0098]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[2.0984e-02, 3.9326e-04, 2.9128e-02, 1.8745e-01, 1.5587e-01, 5.3281e-01,\n",
       "           5.0279e-02, 2.1983e-02, 1.0968e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0763, 0.0182, 0.0782, 0.1866, 0.1624, 0.2515, 0.1162, 0.0853, 0.0252]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[2.3975e-08, 8.5826e-17, 1.3355e-08, 3.6971e-02, 6.5444e-06, 9.6302e-01,\n",
       "           1.5335e-06, 7.1980e-08, 1.2645e-14]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0852, 0.0153, 0.0892, 0.1575, 0.1917, 0.2471, 0.1004, 0.0880, 0.0256]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[7.5030e-03, 6.3248e-05, 1.1026e-02, 1.8980e-01, 7.3889e-02, 6.6412e-01,\n",
       "           2.9785e-02, 2.3600e-02, 2.1140e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.1595e-04, 1.8085e-08, 9.5959e-05, 1.0947e-01, 1.1182e-02, 8.7767e-01,\n",
       "           1.2545e-03, 2.1418e-04, 6.6928e-08]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0770, 0.0061, 0.0607, 0.1781, 0.1608, 0.3532, 0.0801, 0.0736, 0.0104]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[4.4726e-04, 1.4753e-07, 9.9070e-04, 1.6566e-01, 1.4706e-02, 8.0544e-01,\n",
       "           1.0052e-02, 2.6990e-03, 2.6216e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[6.3584e-03, 2.0956e-05, 6.4765e-03, 2.1117e-01, 7.9289e-02, 6.5709e-01,\n",
       "           2.8121e-02, 1.1342e-02, 1.3634e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[9.4993e-04, 1.4701e-07, 9.3432e-04, 2.1226e-01, 1.5681e-02, 7.6726e-01,\n",
       "           2.1420e-03, 7.7323e-04, 8.5606e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0800, 0.0063, 0.1000, 0.1383, 0.2353, 0.2372, 0.0949, 0.0929, 0.0151]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1103, 0.0313, 0.1097, 0.1252, 0.1997, 0.1782, 0.1139, 0.0931, 0.0386]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0674, 0.0024, 0.0701, 0.1442, 0.2412, 0.3390, 0.0799, 0.0502, 0.0055]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1084, 0.0321, 0.1118, 0.1134, 0.1867, 0.1789, 0.1122, 0.1115, 0.0450]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[5.0090e-03, 1.0226e-05, 4.5788e-03, 1.3396e-01, 4.4911e-02, 7.8960e-01,\n",
       "           1.7192e-02, 4.6910e-03, 4.8637e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1116, 0.0213, 0.1091, 0.1105, 0.2228, 0.1866, 0.1214, 0.0901, 0.0266]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[1.0156e-02, 1.5859e-05, 8.4047e-03, 2.3805e-01, 1.0142e-01, 6.0195e-01,\n",
       "           2.3603e-02, 1.6301e-02, 1.0082e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1142, 0.0407, 0.1081, 0.1129, 0.1899, 0.1655, 0.1123, 0.1082, 0.0481]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0969, 0.0257, 0.0933, 0.1391, 0.1658, 0.2187, 0.1135, 0.1085, 0.0385]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[1.6885e-02, 8.0813e-05, 1.1198e-02, 2.2169e-01, 1.4521e-01, 5.3291e-01,\n",
       "           5.2568e-02, 1.9218e-02, 2.4215e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.1308, 0.0453, 0.1123, 0.1042, 0.1874, 0.1430, 0.1096, 0.1059, 0.0614]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[3.7562e-02, 4.0708e-04, 2.5219e-02, 1.6415e-01, 1.0293e-01, 5.9702e-01,\n",
       "           4.4986e-02, 2.6374e-02, 1.3527e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.6135e-02, 1.1230e-04, 9.9799e-03, 1.9414e-01, 3.9284e-02, 6.9766e-01,\n",
       "           2.8173e-02, 1.4284e-02, 2.2789e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[8.7449e-05, 1.0089e-09, 6.0170e-05, 4.6628e-02, 3.7353e-03, 9.4876e-01,\n",
       "           5.8848e-04, 1.4144e-04, 6.8248e-08]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0990, 0.0210, 0.1035, 0.1240, 0.2146, 0.1947, 0.1051, 0.1018, 0.0364]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.0682e-02, 1.5268e-04, 1.6666e-02, 2.2732e-01, 8.4266e-02, 5.7524e-01,\n",
       "           3.9840e-02, 3.5054e-02, 7.7801e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1152, 0.0510, 0.1121, 0.1078, 0.1682, 0.1541, 0.1177, 0.1125, 0.0612]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0787, 0.0067, 0.0843, 0.1309, 0.2153, 0.2919, 0.1072, 0.0717, 0.0135]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1095, 0.0217, 0.0939, 0.1220, 0.1810, 0.2245, 0.1176, 0.0974, 0.0325]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[1.6393e-08, 2.0252e-17, 1.0312e-08, 4.4779e-03, 6.8078e-06, 9.9551e-01,\n",
       "           4.5188e-06, 8.9195e-08, 7.5604e-15]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[7.9107e-04, 2.9215e-07, 1.0523e-03, 2.1543e-01, 3.6378e-02, 7.3537e-01,\n",
       "           9.8032e-03, 1.1776e-03, 2.0309e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1165, 0.0279, 0.1145, 0.1044, 0.1898, 0.1823, 0.1165, 0.1069, 0.0411]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1025, 0.0170, 0.0985, 0.1038, 0.2261, 0.2123, 0.1038, 0.1042, 0.0318]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0672, 0.0062, 0.0688, 0.1384, 0.1629, 0.3662, 0.1097, 0.0665, 0.0141]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1223, 0.0398, 0.1158, 0.1046, 0.1719, 0.1648, 0.1119, 0.1110, 0.0580]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0720, 0.0063, 0.0712, 0.1394, 0.1626, 0.3484, 0.1112, 0.0758, 0.0131]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0550, 0.0016, 0.0497, 0.1734, 0.1453, 0.4565, 0.0694, 0.0455, 0.0036]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1102, 0.0470, 0.1072, 0.1123, 0.1582, 0.1661, 0.1210, 0.1175, 0.0604]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1042, 0.0129, 0.1061, 0.1161, 0.1834, 0.2613, 0.0972, 0.0955, 0.0234]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0495, 0.0010, 0.0336, 0.1784, 0.1146, 0.5267, 0.0573, 0.0349, 0.0041]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0601, 0.0048, 0.0557, 0.1652, 0.1365, 0.4045, 0.0998, 0.0636, 0.0099]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1153, 0.0128, 0.1055, 0.1125, 0.1849, 0.2492, 0.0963, 0.1032, 0.0203]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " ...]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn = GCN()\n",
    "gcn.load_state_dict(torch.load('gcn_model8.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode of Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 321 verilog files \n",
    "* only 3 features             [type, operation_type, num_of_connections]\n",
    "* no edge attribute\n",
    "* 18 classes \n",
    "* 200 epochs \n",
    "* learning rate = 0.01\n",
    "* Dropoout = 0.4\n",
    "* Adam Optimizer\n",
    "* train 70, test 30 (on whole dataset, not each class)\n",
    "* time of training = seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train acc:  0.2902\n",
    "* Test Acc: 0.1959\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested Modifications for upcoming experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Clean dataset (by removing unnecessay, uninformative or wrong code files)\n",
    "2) remove reduntant parsing (different files but same parsing)\n",
    "3) include more informative features\n",
    "4) improve encoding format\n",
    "5) try using less classes (most important ones, so that less classes but more balanced dataset)\n",
    "6) adding more files\n",
    "7) adjusting hyperparameters such as learning rate, dropout, ...etc\n",
    "8) splitting train, val, test\n",
    "9) using equal percentages of each class (adjusting splitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode of Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested Modifications for upcoming experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr = 0.001\n",
    "\n",
    "droput 0.4\n",
    "\n",
    "314 files\n",
    "\n",
    "17 features (node_type)\n",
    "\n",
    "16 classes\n",
    "\n",
    "conv relu conv relu conv relu conv linear\n",
    "\n",
    "train = 40, test = 27\n",
    "\n",
    "200 epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experiment 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same as 5 but 100 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train = 43, test = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr = 0.001\n",
    "\n",
    "conv relu conv relu conv dropout linear\n",
    "\n",
    "9 classes\n",
    "\n",
    "164 file\n",
    "\n",
    "train = 34, test = 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr = 0.001\n",
    "\n",
    "9 classes\n",
    "\n",
    "conv relu conv relu conv dropout linear \n",
    "\n",
    "train = 64, test = 52\n",
    "\n",
    "164 \n",
    "\n",
    "17 features (node type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
