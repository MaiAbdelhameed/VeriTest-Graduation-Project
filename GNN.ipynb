{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\mai\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (2022.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "!pip install torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "!pip install torch_geometric -q\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data import random_split\n",
    "import math\n",
    "from torch_geometric.utils import to_dense_adj, add_self_loops\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "DATA_PATH = \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['done\\\\adder11.txt', 'done\\\\adder12.txt', 'done\\\\adder13.txt', 'done\\\\adder14.txt', 'done\\\\adder15.txt', 'done\\\\adder16.txt', 'done\\\\adder17.txt', 'done\\\\adder18.txt', 'done\\\\adder19.txt', 'done\\\\adder2.txt', 'done\\\\adder20.txt', 'done\\\\adder5.txt', 'done\\\\adder6.txt', 'done\\\\adder8.txt', 'done\\\\ALU10.txt', 'done\\\\ALU13.txt', 'done\\\\ALU14.txt', 'done\\\\ALU15.txt', 'done\\\\ALU2.txt', 'done\\\\ALU6.txt', 'done\\\\ALU7.txt', 'done\\\\ALU8.txt', 'done\\\\ALU9.txt', 'done\\\\and1.txt', 'done\\\\and10.txt', 'done\\\\and12.txt', 'done\\\\and13.txt', 'done\\\\and14.txt', 'done\\\\and15.txt', 'done\\\\and16.txt', 'done\\\\and17.txt', 'done\\\\and18.txt', 'done\\\\and19.txt', 'done\\\\and2.txt', 'done\\\\and20.txt', 'done\\\\and21.txt', 'done\\\\and23.txt', 'done\\\\and25.txt', 'done\\\\and26.txt', 'done\\\\and27.txt', 'done\\\\and28.txt', 'done\\\\and29.txt', 'done\\\\and3.txt', 'done\\\\and30.txt', 'done\\\\and6.txt', 'done\\\\and7.txt', 'done\\\\and8.txt', 'done\\\\and9.txt', 'done\\\\comparator1.txt', 'done\\\\comparator13.txt', 'done\\\\comparator14.txt', 'done\\\\comparator15.txt', 'done\\\\comparator16.txt', 'done\\\\comparator17.txt', 'done\\\\comparator18.txt', 'done\\\\comparator19.txt', 'done\\\\comparator2.txt', 'done\\\\comparator20.txt', 'done\\\\comparator21.txt', 'done\\\\comparator22.txt', 'done\\\\comparator23.txt', 'done\\\\comparator6.txt', 'done\\\\comparator7.txt', 'done\\\\comparator8.txt', 'done\\\\comparator9.txt', 'done\\\\decoder1.txt', 'done\\\\decoder11.txt', 'done\\\\decoder12.txt', 'done\\\\decoder13.txt', 'done\\\\decoder14.txt', 'done\\\\decoder15.txt', 'done\\\\decoder16.txt', 'done\\\\decoder17.txt', 'done\\\\decoder18.txt', 'done\\\\decoder19.txt', 'done\\\\decoder2.txt', 'done\\\\decoder20.txt', 'done\\\\decoder21.txt', 'done\\\\decoder22.txt', 'done\\\\decoder23.txt', 'done\\\\decoder24.txt', 'done\\\\decoder25.txt', 'done\\\\decoder26.txt', 'done\\\\decoder27.txt', 'done\\\\decoder28.txt', 'done\\\\decoder29.txt', 'done\\\\decoder3.txt', 'done\\\\decoder30.txt', 'done\\\\decoder31.txt', 'done\\\\decoder32.txt', 'done\\\\decoder4.txt', 'done\\\\encoder1.txt', 'done\\\\encoder10.txt', 'done\\\\encoder11.txt', 'done\\\\encoder12.txt', 'done\\\\encoder13.txt', 'done\\\\encoder14.txt', 'done\\\\encoder15.txt', 'done\\\\encoder16.txt', 'done\\\\encoder17.txt', 'done\\\\encoder18.txt', 'done\\\\encoder19.txt', 'done\\\\encoder2.txt', 'done\\\\encoder20.txt', 'done\\\\encoder21.txt', 'done\\\\encoder24.txt', 'done\\\\encoder25.txt', 'done\\\\encoder3.txt', 'done\\\\encoder4.txt', 'done\\\\encoder5.txt', 'done\\\\encoder6.txt', 'done\\\\encoder7.txt', 'done\\\\encoder8.txt', 'done\\\\encoder9.txt', 'done\\\\mult1.txt', 'done\\\\mult10.txt', 'done\\\\mult11.txt', 'done\\\\mult12.txt', 'done\\\\mult13.txt', 'done\\\\mult14.txt', 'done\\\\mult15.txt', 'done\\\\mult16.txt', 'done\\\\mult17.txt', 'done\\\\mult18.txt', 'done\\\\mult19.txt', 'done\\\\mult2.txt', 'done\\\\mult3.txt', 'done\\\\mult30.txt', 'done\\\\mult31.txt', 'done\\\\mult32.txt', 'done\\\\mult33.txt', 'done\\\\mult34.txt', 'done\\\\mult35.txt', 'done\\\\mult4.txt', 'done\\\\mult5.txt', 'done\\\\mult6.txt', 'done\\\\mult8.txt', 'done\\\\mult9.txt', 'done\\\\mux1.txt', 'done\\\\mux10.txt', 'done\\\\mux11.txt', 'done\\\\mux12.txt', 'done\\\\mux13.txt', 'done\\\\mux14.txt', 'done\\\\mux15.txt', 'done\\\\mux16.txt', 'done\\\\mux17.txt', 'done\\\\mux18.txt', 'done\\\\mux19.txt', 'done\\\\mux2.txt', 'done\\\\mux20.txt', 'done\\\\mux21.txt', 'done\\\\mux22.txt', 'done\\\\mux23.txt', 'done\\\\mux24.txt', 'done\\\\mux25.txt', 'done\\\\mux26.txt', 'done\\\\mux3.txt', 'done\\\\mux4.txt', 'done\\\\mux5.txt', 'done\\\\mux6.txt', 'done\\\\mux7.txt', 'done\\\\mux8.txt', 'done\\\\mux9.txt', 'done\\\\nand1.txt', 'done\\\\nand10.txt', 'done\\\\nand11.txt', 'done\\\\nand12.txt', 'done\\\\nand14.txt', 'done\\\\nand15.txt', 'done\\\\nand16.txt', 'done\\\\nand17.txt', 'done\\\\nand18.txt', 'done\\\\nand19.txt', 'done\\\\nand2.txt', 'done\\\\nand20.txt', 'done\\\\nand21.txt', 'done\\\\nand22.txt', 'done\\\\nand3.txt', 'done\\\\nand4.txt', 'done\\\\nand6.txt', 'done\\\\nand7.txt', 'done\\\\nand8.txt', 'done\\\\nand9.txt', 'done\\\\nor1.txt', 'done\\\\nor10.txt', 'done\\\\nor11.txt', 'done\\\\nor12.txt', 'done\\\\nor13.txt', 'done\\\\nor14.txt', 'done\\\\nor15.txt', 'done\\\\nor16.txt', 'done\\\\nor17.txt', 'done\\\\nor2.txt', 'done\\\\nor3.txt', 'done\\\\nor4.txt', 'done\\\\nor6.txt', 'done\\\\nor7.txt', 'done\\\\nor8.txt', 'done\\\\nor9.txt', 'done\\\\not1.txt', 'done\\\\not10.txt', 'done\\\\not11.txt', 'done\\\\not12.txt', 'done\\\\not13.txt', 'done\\\\not14.txt', 'done\\\\not2.txt', 'done\\\\not3.txt', 'done\\\\not6.txt', 'done\\\\not7.txt', 'done\\\\not9.txt', 'done\\\\or1.txt', 'done\\\\or10.txt', 'done\\\\or11.txt', 'done\\\\or12.txt', 'done\\\\or13.txt', 'done\\\\or14.txt', 'done\\\\or15.txt', 'done\\\\or16.txt', 'done\\\\or17.txt', 'done\\\\or18.txt', 'done\\\\or19.txt', 'done\\\\or2.txt', 'done\\\\or20.txt', 'done\\\\or21.txt', 'done\\\\or22.txt', 'done\\\\or23.txt', 'done\\\\or24.txt', 'done\\\\or25.txt', 'done\\\\or26.txt', 'done\\\\or28.txt', 'done\\\\or4.txt', 'done\\\\or7.txt', 'done\\\\or8.txt', 'done\\\\or9.txt', 'done\\\\pe1.txt', 'done\\\\pe14.txt', 'done\\\\pe15.txt', 'done\\\\pe16.txt', 'done\\\\pe17.txt', 'done\\\\pe18.txt', 'done\\\\pe19.txt', 'done\\\\pe2.txt', 'done\\\\pe20.txt', 'done\\\\pe21.txt', 'done\\\\pe22.txt', 'done\\\\pe23.txt', 'done\\\\pe24.txt', 'done\\\\pe25.txt', 'done\\\\pe26.txt', 'done\\\\pe27.txt', 'done\\\\pe28.txt', 'done\\\\pe29.txt', 'done\\\\pe3.txt', 'done\\\\pe30.txt', 'done\\\\pe4.txt', 'done\\\\pe5.txt', 'done\\\\pe6.txt', 'done\\\\pe7.txt', 'done\\\\sub1.txt', 'done\\\\sub10.txt', 'done\\\\sub11.txt', 'done\\\\sub12.txt', 'done\\\\sub2.txt', 'done\\\\sub5.txt', 'done\\\\sub7.txt', 'done\\\\sub8.txt', 'done\\\\sub9.txt', 'done\\\\xnor1.txt', 'done\\\\xnor10.txt', 'done\\\\xnor11.txt', 'done\\\\xnor12.txt', 'done\\\\xnor13.txt', 'done\\\\xnor14.txt', 'done\\\\xnor15.txt', 'done\\\\xnor16.txt', 'done\\\\xnor17.txt', 'done\\\\xnor18.txt', 'done\\\\xnor19.txt', 'done\\\\xnor2.txt', 'done\\\\xnor20.txt', 'done\\\\xnor21.txt', 'done\\\\xnor22.txt', 'done\\\\xnor23.txt', 'done\\\\xnor24.txt', 'done\\\\xnor25.txt', 'done\\\\xnor4.txt', 'done\\\\xnor6.txt', 'done\\\\xnor7.txt', 'done\\\\xnor8.txt', 'done\\\\xnor9.txt', 'done\\\\xor1.txt', 'done\\\\xor10.txt', 'done\\\\xor12.txt', 'done\\\\xor13.txt', 'done\\\\xor14.txt', 'done\\\\xor15.txt', 'done\\\\xor16.txt', 'done\\\\xor17.txt', 'done\\\\xor18.txt', 'done\\\\xor19.txt', 'done\\\\xor2.txt', 'done\\\\xor20.txt', 'done\\\\xor21.txt', 'done\\\\xor22.txt', 'done\\\\xor23.txt', 'done\\\\xor24.txt', 'done\\\\xor25.txt', 'done\\\\xor26.txt', 'done\\\\xor3.txt', 'done\\\\xor6.txt', 'done\\\\xor7.txt', 'done\\\\xor8.txt', 'done\\\\xor9.txt']\n",
      "314\n"
     ]
    }
   ],
   "source": [
    "def get_files_in_folder(folder_path):\n",
    "    file_list = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            file_list.append(file_path)\n",
    "    return file_list\n",
    "\n",
    "# Replace 'folder_path' with the path to the folder you want to read files from\n",
    "verilog_files = get_files_in_folder(DATA_PATH)\n",
    "print(verilog_files)\n",
    "print(len(verilog_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset in-place\n",
    "random.shuffle(verilog_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracting_attributes(verilog_file):\n",
    "    try:\n",
    "        if os.path.isfile(verilog_file):\n",
    "            with open(verilog_file, \"r\") as file:\n",
    "                loaded_data = json.load(file)\n",
    "                nodes = loaded_data[0]\n",
    "                edges = loaded_data[1]\n",
    "                # edge_atr = loaded_data[2]\n",
    "                label = loaded_data[3]\n",
    "                \n",
    "                x = torch.tensor(nodes, dtype=torch.float)\n",
    "                edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "                # edge_atr = torch.tensor(edge_atr, dtype=torch.long)\n",
    "                y = torch.tensor(label, dtype=torch.float)\n",
    "                num_nodes = x.size(0)\n",
    "                # print(num_nodes)\n",
    "                \n",
    "                # Create batch assignment vector (assuming one graph per file)\n",
    "                batch = torch.zeros(num_nodes, dtype=torch.long)\n",
    "                # data = Data(x=x, edge_index=edge_index, edge_attr=edge_atr ,y = y, batch = batch)\n",
    "                data = Data(x=x, edge_index=edge_index, y = y, batch = batch)\n",
    "                return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return e\n",
    "\n",
    "# temp=extracting_attributes(\"./done/adder6.txt\")\n",
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 314 Verilog files.\n",
      "314\n"
     ]
    }
   ],
   "source": [
    "class VerilogDataset(Dataset):  # Using Dataset from torch_geometric\n",
    "    def __init__(self, verilog_files):\n",
    "        print(f\"Loaded {len(verilog_files)} Verilog files.\")\n",
    "        self.verilog_files = verilog_files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.verilog_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        verilog_file = self.verilog_files[idx]\n",
    "        data = extracting_attributes(verilog_file)\n",
    "        return data\n",
    "\n",
    "dataset = VerilogDataset(verilog_files)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\\pe22.txt\n",
      "done\\pe22.txt\n"
     ]
    }
   ],
   "source": [
    "print(verilog_files[0])\n",
    "print(dataset.verilog_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data objects are unique.\n"
     ]
    }
   ],
   "source": [
    "def are_all_data_objects_unique(dataset):\n",
    "    data_objects = []\n",
    "    for data in dataset:\n",
    "        if data in data_objects:\n",
    "            return False\n",
    "        data_objects.append(data)\n",
    "    return True\n",
    "\n",
    "# Example usage:\n",
    "is_unique = are_all_data_objects_unique(dataset)\n",
    "if is_unique:\n",
    "    print(\"All data objects are unique.\")\n",
    "else:\n",
    "    print(\"Duplicate data objects found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done\\\\xor10.txt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = random.randint(0, len(verilog_files))\n",
    "verilog_files[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApQAAAHzCAYAAACe1o1DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAABbzElEQVR4nO3deXhU9d3+8fvMTJJJQkISiAmBAGETBCEQ3MWV+rOK2rrUulTEtdY+1p3WLla7WBWXaheXWsWndrHVRyu2tcWVSq2GfVORJSSEQAgJWSeZ5fz+OEwEkrBlTs6ZmffruriEzHjOZzRM7vl8N8M0TVMAAADAIfI4XQAAAADiG4ESAAAAvUKgBAAAQK8QKAEAANArBEoAAAD0CoESAAAAvUKgBAAAQK8QKAEAANArBEoAAAD0CoESAAAAvUKgBAAAQK8QKAEAANArBEoAAAD0CoESAAAAvUKgBAAAQK8QKAEAANArBEoAAAD0CoESAAAAvUKgBAAAQK8QKAEAANArBEoAAAD0CoESAAAAveJzugAA6EumaSpsSiHTVCQieTySzzDkNSTDMJwuDwDiEoESQMIyTVM72sOqaQ2ppjWkLa0h1bSFFIp0fa7PIxWm+zQow6fCXb/y0ryETAA4AIZpmqbTRQBALNW3h7Vke0DL6gJqD1tvcR5J3eTILnZ/XprX0KQBfk0e6FdumtemagEg/hEoASSEiGlqXWOHFtUGtLEpKENSLN7cotcZnpWisny/RmanykPXEgD2QKAEEPcqm4N6vaJJDR2RmAXJvUWvm5Pq0dnDslTcL8WGuwBAfCJQAohbwYipd6tbVF4bsC1I7i16n6n5fp1clKkUD91KACBQAohLlc1BzatoUmNHpE+C5N4MSdmpHs2gWwkABEoA8ae8tk3zq1r6rCvZk+j9pw/J1NT8dAcrAQBnESgBxA3TNLVwa5sWbGl1upQupg3K0PEF6WwzBCApcVIOgLjh1jApSQu2tGrh1janywAARxAoAcSF8m3uDZNRC7a0qryWUAkg+RAoAbheZXNQ8ze3OF3GAZlf1aLK5qDTZQBAnyJQAnC1YMTUvIomxcvMREPSvIomBSNMTweQPAiUAFzt3eoWx7YGOhSmpMaOiN6rjo+OKgDEAoESgGtVNgdVXhuImzAZZUr6qDbA0DeApEGgBOBKEdPU63E01L03Q9LrFU2KsDMbgCRAoATgSusaO9QQR0PdezMlNXREtL6RLiWAxEegBOBKi3adzx3PDEmL2EYIQBIgUAJwnfr2sDY2BeO2OxllStrQFFR9e9jpUgDAVj6nCwCAvS3ZHrDtnO5ge0Dv/PbnWvbGy9pZs1np2Tkac/xp+sIN31b/gqKY38+QtHR7QKcOzoz5tQHALehQAnAV0zS1rM6eld3B9oCe+fr5euvpOepobdG4k89U/8LBWvTXP+jxS09XXeWGmN/TlLS0LiCTxTkAEhiBEoCr7GgPqz1sT/h657ePqmLZRxo68Sjd9soHuvT+3+jG59/QWbfeq5b67Xrpnm/Zct/2sKn69ogt1wYANyBQAnCVmtaQLdcNB4Na+MffSJLO+/bPlJbRr/OxaZffoMLR47Vh8X+0efUyW+5v1+sCADcgUAJwlZrWkC1vTBuX/leBpp3KGzJcRWMndnl8wvRzJElr3nsj5vf2GFJNG4ESQOIiUAJwlS2tIdkxOLzl05WSpMHjuoZJSRo89kjreWtXxfzeEVOqbmE/SgCJi0AJwDVM07Stk9dQs1mSlH1Y9yu5oyu8G7ZU2XL/mrYQC3MAJCwCJQDXCJtSyKa1Kx2tLZKkVH96t4+n+DOs57W12HL/UMTqVAJAIiJQAnCNkK0dvF3XNno6f8f+tGfv6wMA5xAoAbhGxMaddVJ3reruaGvt9vFgwDoiMTXdvg3Iw+wcBCBBESgBuIbHxneknMLBkqTGbdXdPr5zq/X1nEFDbKvByzsugATF2xsA1/D1OBzde4PGTJAkbV6zvNvHN3+8QpJUOOoI22qw8/UBgJMIlABcw2tIPpvelYaVHi1/v2ztqNqo6o+7hsqV81+TJI096Qxb7u/zWPtRAkAiIlACcA3DMFSY7rPl2r6UVB138dWSpL/e/+09VnMv+N2vVbN2lYaXHqPi8ZNtuX9huk8GHUoACcow2RgNgIu8WdWsRbUBWzY3D7YH9PS1X1LlykXKGlig4ZOPVcOWKlWuXKSMnDzd8NzfNXDoiJjf12NIU/PTddpg+xb8AICT6FACcJXCDJ8tYVKSUtL8uvap/9Np196mFH+6Vr/zd9Vv2aQp51ys//n9W7aEScnaf9KuzisAuAEdSgCuUhcI6ek1DU6XEXPXjctVnt/rdBkAYAs6lABcJS/NqzRvYs01TPMayk3j7RZA4uIdDoCrGIahSQP8SpRIaUgqHeBnQQ6AhEagBOA6kwf6++AgxL5hSiod6He6DACwFYESgOvkpnk1PCsl7ruUhqSSrBTlpjF3EkBiI1ACcKWy/PjvUpqSyvLTnS4DAGxHoATgSiOzU5WT6onbLqUhKSfVoxHZKU6XAgC2I1ACcCWPYejsYVlx26U0Jc0YliUPi3EAJAECJQDXKu6Xoqn58bfi25B0VL5fQ/rRnQSQHAiUAFzt5KJMZcfR0LchKTvVo5OKOGYRQPIgUAJwtRSPoRlxNPQdHepO8cRLBAaA3iNQAnC94n4pmj4kPjp+04dkqpihbgBJhkAJIC5MzU/XtEEZTpexT9MGZWgq2wQBSEI+pwsAgAN1fIEV1hZsaXW4kq5OGpSh4woIkwCSk2GaZrxMTQIASVJ5bZvmV7XIkBydWxm9//QhmXQmASQ1AiWAuFTZHNS8iiY1dkQcCZXR1dwzhmUxZxJA0iNQAohbwYipd6tbVF4b6LNuZfQ+R+X7dVJRJqu5AUAESgAJoLI5qNcrmtTQEbEtWEavm5Pq0dl0JQFgDwRKAAkhYppa3xjUoto2bWgKxixYRq9TkpWisvx0jchO4ThFANgLgRJAwqlvD2vp9oCW1gXUHrbe4jyGFNnvu50pj2F0Pi/Na6h0gF+lA/3KTfPaWjMAxDMCJYCEZZqm6tsjqmkNqaYtpOqWoGraQgpFuj63o61V+WmGDi/MU2G6T4UZPuWmeWTQjQSA/SJQAkgqpmkqYkoh01Q4Ink9UktTowbk5ur3v/+9LrnkEqdLBIC4w8bmAJKKYRjyGpJXhrRrFDstJ0d5eXnasGGDs8UBQJzi6EUAkFRSUkKgBIBDRKAEAFmBcv369U6XAQBxiUAJAKJDCQC9QaAEAFmBctOmTQqFQk6XAgBxh0AJALICZTgcVlVVldOlAEDcIVACgKxAKYlhbwA4BARKAJA0bNgwGYZBoASAQ0CgBABJfr9fRUVFrPQGgENAoASAXVjpDQCHhkAJALsQKAHg0BAoAWAXAiUAHBoCJQDsUlJSopqaGrW1tTldCgDEFQIlAOwS3Tpo48aNzhYCAHGGQAkAu4wYMUISe1ECwMEiUALALkVFRUpJSWHrIAA4SARKANjF6/Vq2LBhdCgB4CARKAFgN6z0BoCD53O6AABwk6uuukqhUMjpMgAgrhimaZpOFwEAbmGapoLBoFJTU50uBQDiBoESAAAAvcIcSgAAAPQKgRIAAAC9wqIcAACAg2CapsKmFDJNRSKSxyP5DENeQzIMw+nyHEGgBAAA6IFpmtrRHlZNa0g1rSFtaQ2ppi2kUKTrc30eqTDdp0EZPhXu+pWX5k2KkMmiHADYl2j7Ico0pST44QAku/r2sJZsD2hZXUDtYSsqeSR1kyO72P15aV5Dkwb4NXmgX7lpXpuqdR6BEgB2t3tgXLlSOuUUafNmKS3N0bIA2C9imlrX2KFFtQFtbArKkBSLkBS9zvCsFJXl+zUyO1WeBPtgypA3AOxu9zf5ujqpvl763e+ks86yHmtqsn7l5EhDh0o+3kaBRFDZHNTrFU1q6Igo+i4Qq45b9DoVTUFtbAoqJ9Wjs4dlqbhfSozu4Dw6lAAQtWOH1NAg7dxpdSV//GPrn6GQNGiQlJkpbdlihcymJulLX5LmzLGCJYC4FIyYere6ReW1gZh1JPcnep+p+X6dXJSpFE/8dysJlAAQCEi//7308svS+vXS9u1Wd9Lns772ySfSiy9K+flWeBwzRlq1ynrsxz+Wvv51p18BgENQ2RzUvIomNXZE+iRI7s2QlJ3q0YwE6FYSKAHgmWeka6+Vxo2TTjjh89B44olSUdHnz4u+XRqG1NgoXXWV5PdbQ+IA4kp5bZvmV7X0WVeyJ9H7Tx+Sqan56Q5W0jtM/gGAqiprSPuf/7QCZHeT5fde7Z2dbQXKioq+qxNAr5mmqYVb27RgS6v1Z6fr2fXP+VUtag+bOr4gPS63GSJQAkD//lJJiTR48OddyL15ujlY7Kyz7K0LQMztHibdJlrXCYUZDldy8AiUAPDFL0oDB1q/j8POAIADU77NvWEyasGWVqV5jbgb/mYOJQAcqvZ26a23pFNPteZSAnCtyuagXli70+kyDthlo/vH1UKdbsZwkodpmgpFTAXCEbUGIwqEIwpFTJGxgSQUDO7/OZGIFA5b2wiZprXN0IUXSh9+aH99AA5ZMGJqXkWT4mX8wZA0r6JJwUj85JGkGfLmLE4APQqFpGeflU47TRo1ygqXHo/1a/e/93vPo6yqsjY437GjT8sFcHDerW5xbGugQ2FKauyI6L3qFp0+pJ/T5RyQhA+Uh3IWZygiVbWEVN0SSrqzOIGk5PFIP/2ptWn53XdLKd0MM7W1Se+9Jy1dKq1bZ63ufv99qbDQ+gXAlSqbgyqvDThdxkEzJX1UG9CYnLS4GPpOyDmUnMUJ4KB94xvSX/8qXXGF1NoqbdxoBcz+/a3Htm+Xbr5Zys21vpaTI40YIc2aZc2h3P0McACuEDFNPbW6XjvjqDu5O0NS/1SPrjsi1/V5I+EC5d5ncdrx4qLXTcSzOIGk9dFH0i23SJ99Zu0xmZdnBceqKutXXp40bZoVOAsKrFXheXlSWprTlQPowdqd7XppfZPTZfTahSOyNap/qtNl7FPCBErO4gTQa62t0vLlVkjMy7OOWjRN6fvfl379a2vYG0Dc+ONnO1XRFIzL7mSUIWtk9OJR/Z0uZZ8SYg7l7mdxSn236330PotqA1q7syMhzuIEklpGhnTssV2/fu651ik6krXKe+/FOgBcp749rI1NB7B7g8uZkjY0BVXfHnb1Go6471ByFieAmNr9vO6ocFhqaJAGDHCkJAAH763NLfpoW5tt2aBp+1a9+9zj+vjf/9LOrdVKSfMrt2ioRh19kr54890xvZch6ejD0nXq4MyYXjeW4jZQ7n0Wp5tMG5QRt2dxAgAQ70zT1KMrdnTu7hJrFcs+0nM3XaJA004dNuJwFYwcq/bWZm1b/6kat1XrJx/VxPyeaV5DNx+Z59psEbdD3m4Nk1J8n8UJAEC829Eeti1MNtbW6LmbLlE42KHL5zyn8aedvcfjlSsX23Lf9rCp+vaI8vzuHPaOy5Ny4uUszvJaJvADANDXalpDtl37H4/9SIGmnTrzph90CZOSVDxhim33tvN19VbcBcrK5qDmb25xuowDMr+qRZXN8T8hGACAeFLTGrIl4LQ1NmjFv16Vv1+2jvry5TbcoWceQ6ppc2+gjKsh793P4oyHiZ/RszivGZfLlkIAAPSRLa2hfZ6Id6g2Lv1QoY52jTz6JHl9KVox/6/auOS/ioSCyi8ZrSO/cJ6yBhxmw52liClVt7i3SRVXgZKzOAEAwL6YpmlbJ2/b+o8lSVkD8vXk1edo0/KP9nj8jcd/rAt/+JiO/MJ5tty/pi0k0zRduTAnboa8o2dxxkuYjIqexcnQNwAA9gubUsiO9qSsIW9JWvz6i6pZu0oX/OBRfe/Nj3XnvEU68fIb1NHWqj997xva8ukqW+4filidSjeKi0AZMU29vmuoOx4Zkl6vaFIkPndoApJaKBTS+vXrFac7rAFJJ2Tj39VI2EqqkVBIZ9/6I0390mXKzB2g3KKhOvvWezVh+jkKBzv03txf2FaDna+vN+IiUK5r7FBDHA11782U1NAR0fpGupRAvHn11Vc1cuRIbd++3elSAByAiE3dSUlKy7Smrxkej6acc3GXx6eed6kkaf2i922rIWzj6+uNuAiUi3adzx3PDEmL2EYIiDslJSWSpA0bNjhcCYAD4bEx2eQWFUuSsgYcJl9qWtfHBw2VJLXssO8DqNelyc2lZX0uehZnvHYno3Y/ixNA/CBQAvHFZ+OClaLDj5QktTXt7HYaTOvOHZKk1Az7jki08/X1hutXeS/ZHrBlm6AFv/u1Kpb8VzWfrVZz/XaF2tuVNeAwlUw9XifP/B8VjBwb4ztaXcql2wOuPosTwJ5yc3OVk5NDoATihNeQfIYUsqETVTj6COUOHqb6zRWqXLFIQydO3ePx6FB30diJsb+5JJ/H2o/SjVzdoTRNU8vq7FnZ/c5vH9UnC99Uev9cjTrqJI098QvypaVpybwX9filp+uT9+fH/J6mpKV1ASb3A3GmpKRE69evd7oMAHsxTVPV1dX629/+pp/+9Ke6+OKLNXbsWH22+APbftaePPN/JEmvPXiXWurrOr++efUyLfjfX0uSjrlwpi33Lkz3uXLLIMnlHUo7z+L82sPPa/C4SUpJ8+/x9Q/+/Kxeve9OvXzvLZr9t6XyeGN7Zqbbz+IE0FVJSQkdSsBhwWBQn3zyiZYuXaply5Zp6dKlWrp0aeeCuezsbJWWlurMM8/UyMH5apM9h6Acdf7XtO6j97TiX3/VQ+cfp2ETj1JHW4sqln2kcLBDR335azpy+rkxv6/HkIoyU2J+3VhxdaC088zK4aXHdPv1Yy+apX//7teqq9yg2orPVDDi8Jjfu6Y1RKAE4khJSYleeeUVp8sAksbOnTu1bNmyPYLjqlWr1N7eLkkaPny4SktLdeONN6q0tFSlpaUaNmxYZ/du1Y6AXqtotqU2j8ejr973tErKTlD5K7/Tuo/+LcOQhhwxSUdfcKWmzPiKLfeNmFaH0q3cW5k+P4uzr1fIR7uSXl/sPwlEz+I8Ql1XhwFwp5KSEm3atEnhcFjeGI9aAMnMNE1t2rSpMzRGA2R0RCA1NVXjx49XaWmpZs6cqdLSUk2cOFE5OTn7vG5hhr3xxuPx6LivXKXjvnKVrffZm92vqzfcW5nsO4tzXxbP+5NqN36mgcNGKm/I8Jhf3+1ncQLoqqSkRMFgUJs3b9bQoUOdLgeIS+3t7Vq9evUewXHZsmVqaGiQJA0YMEClpaU6//zzNWnSJJWWlmrs2LFKSTn45k5emldpXsO2aXNOSPMayk1z79IX1wZKO8/i3N17c3+hres/Vkdbq2o3rNXWdR8rO79QX/3Jk/LYtJmVm8/iBNDV7lsHESiB/aurq9tjuHrp0qVas2aNQiHr5/ro0aM1adIk3X777Z1D1kVFRTH7uWgYhiYN8OujbW1xv+2gZO0SUzrA7+rc4NpAaedZnLv79D9va92H73X+uX/hYH3lR7/U4CMm2XbP6FmcXvd+XwDYzfDhwyVZgfLkk092thjARSKRiNavX99lyLqqqkqSlJ6eriOPPFLHHXecbrjhBk2aNElHHnmksrKybK9t8kC/PtyWGAeKmJJKB/r3+zwnuTZQ9tVZldc88ZIka5PSmrWr9dbTD+npa7+kM77xHZ16za223TdkmvLG/fk/QHJIT0/XoEGD2DoISa21tVUrV67co/O4fPlyNTdbi18KCwtVWlqqyy+/vHPIevTo0Y7NO85N82p4Vooq4vxwFEPS8KwU5aa5e/62awOlnWdxdic9q79KphynKx/7g3595Rf1r1//TKOOO1XF4yfbcr9wRJK7vzcA7Iatg5BMampq9giOy5Yt0yeffKJIJCKPx6OxY8eqtLRU5513nkpLSzVp0iQVFBQ4XXYXZfl+bWyK73ULpqSy/HSny9gv1wZKO8/i3BdvSoomnvElbV6zTB+/94ZtgdKtZ3EC6B6BEokoHA7r008/7TJkvXXrVklSVlaWJk6cqNNOO0233nqrJk2apAkTJig93f0BR5JGZqcqJ9WjnR2RuOxSGpL6p3o0Itu9+09GuTZQOnlWZUZOniTtsQN+rLn1LE4A3SspKdHbb7/tdBnAIWtqatLy5cv36DyuWLFCgUBAklRcXKzS0lJdd911nUPWJSUlti1Q7Qsew9DZw7L0wtqdTpdySExJM4ZlyRMHmcG1gdJrWGdW9sXCnL1tWLxQkmzZNkiSOtpaVTRovEaMGKERI0aopKSk8/cjRozQ4MGD2esOcJmSkhJVV1crEAjI73f35HgkN9M0VVVV1WXI+rPPPpMk+Xw+jR8/XpMmTdIll1zSOWSdl5fncOX2KO6Xoqn5fi2qtecoZ7sYkqbm+zWkn/u7k5KLA6VhGCpM96mqJfZbB21Y/B811dZo/OnnyOv7/D9BOBjUf196Tkte/7NS/OmaeMaXYn5vmab6RQL6xje+oQ0bNmj9+vV69913tXnz5s6npKSkaNiwYXuEzN1D5/42dAUQe9GtgyoqKnT44bE/QQsJIBLp8/lawWBQa9as6TJkvWPHDklSbm6uJk2apBkzZnQGx3HjxiktLbkO1zi5KFNrd3aoMU6Gvg1J2akenVSU6XQpB8ww7To9PQberGrWotpAzDc3X/TXP+gvP7xJmTkDVDRuojJy8tRaX6eaz9aoaftW+dL8uuiex20JlB5DmpqfrtMG7/lNEggEVFFRofXr1+/xa8OGDVq3bl3nKjrJeoPYu6sZ/fPQoUOVmpoa87qBZFdRUaHhw4fr73//u84880yny4FbrFwpXXONFAhIEydKDzwgFRbacqv6+vouxxGuXr1aHR0dkqQRI0Z07ukYHbIuLi529d6FfamyORhXQ9+Xje6v4jjpTkou7lBK1hFDdox4l5Qdr1OuulkbFi9UzdrVam3YIW9KinKLhmrC9HN0/Fev1cChI2y4c89ncfr9fh1++OHddj5M01RdXV1nwNw9cC5atKjzSDjJOg6quLi4S+CMhs78/HzeXIBDMGTIEPl8PrYOSlYbN0r/+7/SSy9Jp54qzZkjeb1Saqp08slSMCj98peS3y898oiUeeidJdM0tWHDhi5D1hUVFZKktLQ0HXnkkSorK9PVV1/deRxhdnZ2jF5sYirul6LpQzI1v6rF6VL2a/qQzLgKk5LLO5R1gZCeXtPgdBkxd924XOX5YzdHMhgMqrKystvAuWHDBtXVfb64KDMzs8e5m8OHD4+blXuAE0aOHKnzzz9fDz74oNOloK/dcIP05z9LX/2qdPXVVjcyOtc9OtR90UXSmjXW88aNk0xT2s8H+I6ODq1YsWKP4Lhs2TI1NjZKkvLz8zu7jtHO4+GHHy6fz9X9IFd7v6ZVC7a0Ol1Gj6YNytAJhRlOl3HQXP0dyVmcByYlJaUzFHZn586dnUFz98D5t7/9TRs3buwcLpGkQYMG9Rg4Bw0aFNer/YDeim4dFIqYCplmZ47wGYa8huj+J6rmZumdd6wQee+90t6LV6J9mRNOkBYulDZsOKBAGQqF9OMf/1g/+tGPZBiGxowZo9LSUn3xi1/sDJCFhYV8X8XY8QVW48SNofKkQRk6riA+Gzuu7lBK0lubWxLqLM6jD0vXqYPdM8k2Eomourq6S1cz+vuamprO56alpWn48OHdzt0sKSlhuAUJxzRN7WgPq6Y1pJrWkN5btkYpAwbJl9Z1lbfPY01nGZThU+GuX3lpXsJAIti6VfrKV6TsbOmvf+0aEqOfLN55Rzr/fOlHP5JuvFHq6LCGxHsQDodVUVGh2tpaTZgwQZm9GCbHwSuvbdP8qhYZkqMZI3r/6UMyNTUONjDviesDZX17WE+urne6jJi5/ohc1x+ftLvW1lZt3Lixx8DZ2vr5J7yBAwf2uFiouLg4foZoNm6UamutLkRJiXO77MMx9e1hLdke0LK6QOcIiUdS2DT3GxA9Uufc7zSvoUkD/Jo80B9Xf++xl+Zm6eabpbfeksrLu3Yoo2prpalTre7kP/7RpyXi0FQ2BzWvosmx1d/R1dwzhmXF3ZzJvbk+UErSHz/bmTBncV48qr/TpcSMaZratm1bl3mb0dBZWVmp6LeX1+vVsGHDegyceXl57ujkVFZKl10mLV8uhULSN78p/exn1mPLl0tz50rHHisdf7w0eLCztSKmIqapdY0dWlQb0MamYMy6FtHrDM9KUVm+XyOzU+Nik2LsJhyWfv5z6bvflVatknqYXiRJuuce6YknpLIyadMma4HO6af3Xa04aMGIqXerW1ReG+izbmX0Pkfl+3VSUaZSPPH/nhAXLSPO4nQnwzBUUFCggoICHXvssV0eb29v16ZNm7p0NcvLy/Xiiy9q587Pt2/Izs7udt7miBEjNGzYsL7ZMy0cll58Ufr3v6X775cuuEDK2G1idEeH9dgf/mB1If7yl30OZyF+VDYH9XpFkxo6Ioq+rcfqh0r0OhVNQW1sCion1aOzE6AbkTRM01p809Ehtbdbq7n35e67pbVrpXfflU47TRo6tG/qxCFL8RiaPqSfDs9J2+N9wI5gGb1u/wR8H4iLDmXENPXU6vq4P4vzuiNy6Uzspr6+vtth9PXr16uiokKhkLWpvWEYGjx4cI+LhQoKCmLT3dy501rJuXq1NbE+o5tVdqGQ9PDD0ve+J738sjRjRu/vC8c42ZmYmu/XyQnSmYhn4XB4/yeTbdwoXXGFlJNjjVLk5vb83LfesuZR3nCDdN99B7TSG+4RMU2tbwxqUW2bNtgwUlGSlaKy/HSNyE5JuDwQFx1KzuJMTLm5uSorK1NZWVmXx0KhkDZv3txlGH3NmjV6/fXXVVtb2/nc9PT0PULm3r8/4Inura3WkHdRkZTSzafGSETy+aSxY6X0dOv50a8zzzLu7D53Suq7SfnR+yyqDWjtzo6EmDsVD0zT1KZNm/Y4TWbp0qWaPXu2Zs2a1fOBEP/4h3TWWdbvL7jAGsbOzbVGNHYPotH3gbY265+jR0dvTKCMIx7D0Kj+qRrVP1X17WEt3R7Q0t3nUhvWftL7v87nz0vzGiod4Fdpgs+ljotAKXEWZ7Lx+XwaNmyYhg0bplNPPbXL483Nzd3uufmvf/1LGzZsUCAQkGTtGxg9v7ZH0Tf8piappkaaNKnnQOnxWPvMZWfvu0sBV3PD6k5TUmNHRC+s3Rn3qzvdpqOjQ6tXr+5yHGFDQ4MkKS8vT6Wlpfryl7+s0tJSpXT39z1q2jRp8WLpP/+RvvMdayTjn//cM0xKn4fGMWOs94lNm/b8OuJObppXpw7O1ClFGapvj1i7PbSFVN0SVE1bSKFuTl6J7vZQlJmiwnRrt4fcNI871gjYLG4CpcRZnPhcv379dOSRR+rII4/s8lgkElFNTY02bNigtra2/V8s+hf9pZekdeukY47Z9/M2bJCysj4/Xi0J3igShWmaWri1rXP/OaffR6L3n1/VovawqeML0pPiB08s1dXVdQbG6D9Xr17dOWVm1KhRKi0t1e233955HOHgwYMP/L9zZqZUWipNmGD93X/ySWnz5q6L8qLXGzXK+sC5YQPdyQRhGIby/F7l+b06QtZ8ftM0FTGlkGkqHJG8u/aj9STxfrRxFShTPIZmxNHQd3SomzlSfcvj8aioqEhFRUUH9i9cfLH04YfWWbw33CCdc073z4u+STQ1WRP0s7KsP/NDI27sHibdJlpXPJ6Q0RcikYjWr1/f5TjCyspKSdbxtRMnTtSxxx6r66+/XqWlpTryyCOVFf172ls+n7WxeXOztH5997s8BIPW6EZenrRli1Rf3/MWQ4hrxq7DDLwypMQdxT4ocRUoJc7ihA2uvNLqNs6da3UhcnK6f150nuQXvyjNm2cNgQ0fzvzJOFG+zb1hMmrBllaleY2kH/5ua2vTypUruxxH2NzcLEkqLCzUpEmTdOmll3aeKDN69Oj9L67preJi66zujz+2hsL3lpIiVVVJ27dbQ9/dLewDElRcrPLuDmdxIqbq6qxO5Zo11nDWvmzaJH35y9KSJdZw2EcfWQt1evD9739fLS0teywW4tz0vlXZHIybkQ1Jumx0/6T5MLp169Yucx0/+eQTRSIReTweHX744XucYz1p0iQVRqeb9LWKCmuBzoAB0jPPWF3KYFDq319qaZHuukt6/HFp2DBr38pzz3WmTsABcRso954L5SbRsziTdR5FXGpvl266yVrRuWZNz52F2lrpwgutrYUeeUQaONDqVOxjJfnMmTP1wQcf7PPc9L1Xp3NueuwEI6Z+s6Y+7uZeXzMuN6Gmy4TDYX366addhqyjx7v269evMzBGA+T48eOV4bYu389/Lt1xh7WFWHGx9Nhj0nnnWX9eudJ6L+lpHjaQwOI2UEa5YbWmlDhncSatujpp1ixp2zbrPF7/Xmc1R1d4L1hg/fC44w5rxedBzJ8Mh8Oqrq7udnV6d+eml5SU9HiyUMzmhSWB+VXNcbs7xOlD+jldyiFpamrSihUr9giOK1as6FwkV1xcvEdwnDRpkkaMGBEfH6ICAWt0wjCs+ZHDh3PAAaA4nEO5t6n56SpI93EWJ3qntdWa+zRunNTdqTzRz11r11o/PMaM+fzrBxgovV6viouLVVxcrJNOOqnL4y0tLZ3npu8eOt955x09++yzXc5N726T95KSkvg6N91mlc1BldcGnC7joJmSPqoNaExOmqvfU0zT1ObNm7vs7Rjdqsvn8+mII45QaWmpvvrVr3Z2IAcMGOBw5b3g90vHHed0FYDrJMRPneJ+KbpmXK6jJ14kylmcScvrlRobrS5kdwExFLKes2GDtam5DXO4MjMzNX78eI0fP77LY9Fz07s7WWjhwoWqqqrqcm56TycL5ebmJsV0jIhp6vWKJsdHLw6VIen1iibXnLAVDAa1Zs2aLkPWdXV1kqScnByVlpbq7LPP7uw8jhs3rm+OTQXguLgf8t7b3mfy2nkWJ2fyJohol/GMM6RFi6Tvf1+66KLutwU580xrWPwvf5FGjHDNlkG7n5ve3VGW3Z2b3l3g7LNz0/vA2p3teml9k9Nl9NqFI7I1qn/fDqk2NDR02dtx1apVnXOAR4wY0WXIeujQoUnxQQVA9xIuUEqcxYlD9O9/W5sWv/mmtTXQ449bi3M+/dSaLxkISH//uzR7tvSDH1idyjix+7npewfOfZ2bvnfojNm56X3gj5/tVEVTMC67k1GGpOFZKbp4VH9brm+apjZu3NhlyLqiokKSNZd3woQJewTHiRMnqn9/e+oBEL8SMlDujrM4cdA6Oqxf/XYtiKiulh54wFq4U1Agffe7CXXsYigUUlVVVY+LhfY+N72nuZsHdW66zerbw3pydb3TZcTM9Ufk9vp9JxAIaNWqVV2GrBsbGyVZ83InT568R+fx8MMPZz4ugAOS8IEyyjRNzuIEDkFTU5M2bNjQY+Bsb2/vfG5BQUGPgXPw4MH2bzy9y1ubW/TRtjbbu5OtO+v18PnHq6V+u/KHj9KtL/8n5vcwJB19WLpOHXzgYb22trbLkPWaNWsUDodlGIZGjx7dGRqjncdBgwbxHgfgkCVNoOwOZ3ECvRM9N72nuZvV1dWdz01JSdHw4cN7DJw5PZ1QdJBM09SjK3Z0jkjY6c93f1NL5r0o0zRtC5SSNUJy85F5Xd6XIpGIPvvssy5D1tH/7hkZGZo4cWJnaIweR+iWTjKAxJHUgRKAvdra2lRRUdFj4IwepSdJubm5PS4WGjp0qFJSDmzxW10gpKfXNNj0ij732X/f0zM3XKCjz79CH778vK2BUpIuH56mzZ+u7gyNS5cu1YoVK9TSYh1DW1RUtEdwLC0t1ciRI/usKwwguTE5BoBt0tPTNXbsWI3t5mhK0zRVV1e3R8CMhs6PPvpImzZtUiRizUnxeDwqLi7uMXAOHDiws3tX0xqy/XUFA2165ae367ARh2vaFd/Qhy8/b/s9Z1x6pZb942V5vV6NHTtWpaWluuCCCzr3djzssMNsrwEAekKHEoArBYNBbdq0qce5mzt27Oh8br9+/ToD5sSLrlXG2KOsPUVt8o/H7tV7c3+ha596RTmDhuiBGWW2dijNcFgZ2zfoxPwUjR8/Xv69T3ICAIfRoQTgSikpKRo5cqRGjhzZ7eMNDQ3dLhZq9PiVbhiyaxb0lk9XacHvfq2ycy9RSdnxqq/eZNOdPmd4vRowYqzKxuTYfi8AOBQESgBxKScnR5MnT9bkyZM7v2aaph5aXtft7g2xEIlE9PKPb1V6v/4681t323OTHtS0hWSaJgsGAbiSfWNCANDHwqZsC5OS9J8/Pq2qlYv1xZvvVmZOnn036kYocmD75wKAEwiUABJGyMYp4Q01m/XPX92nkrLjVXbuJbbdZ1/sfH0A0BsESgAJI2Jjd/LV++5UOBjUl77zoH032Y+wja8PAHqDOZQAEoaNC7v18YJ/yp/VX6/cd8ceXw/tOimooWaznrr2PEnSzJ+/oLSMfjGvwUsLAIBLESgBJAyfzQtWAk07tWHRwm4fCwbaOh+LhMO23N/u1wcAh4pACSBheA3J57FnYc59i2u7/Xp99Sbb96GUrNflIU8CcCkGUAAkDMMwVJiemJ+TC9N9bBkEwLUIlAASyqAMX8K9sXkMqSjzwM4yBwAnJNr7LoAkV5jhU6Itho6YStjOK4DEwDsUgIRSmNG3b2u5RUN7nF8ZS339ugDgYNChBJBQ8tK8SvMm1lzDNK+h3DTergG4F+9QABKKYRiaNMCvRImUhqTSAX4W5ABwNQIlgIQzeaBfiXJIoSmpdKDf6TIAYJ8IlAASTm6aV8OzUuK+S2lIKslKUW6a1+lSAGCfCJQAElJZfvx3KU1JZfnpTpcBAPtFoASQkEZmpyon1RO3XUpDUk6qRyOy2X8SgPsRKAEkJI9h6OxhWXHbpTQlzRiWJQ+LcQDEAQIlgIRV3C9FU/Pjb8W3IemofL+G9KM7CSA+ECgBJLSTizKVHUdD34ak7FSPTirKdLoUADhgBEoACS3FY2hGHA19R4e6UzzxEoEBgEAJIAkU90vR9CHx0fGbPiRTxQx1A4gzBEoASWFqfrqmDcpwuox9mjYoQ1PZJghAHPI5XQAA9JXjC6ywtmBLq8OVdHXSoAwdV0CYBBCfDNM042VqEQDERHltm+ZXtciQHJ1bGb3/9CGZdCYBxDUCJYCkVNkc1LyKJjV2RBwJldHV3DOGZTFnEkDcI1ACSFrBiKl3q1tUXhvos25l9D5H5ft1UlEmq7kBJAQCJYCkV9kc1OsVTWroiNgWLKPXzUn16Gy6kgASDIESACRFTFPrG4NaVNumDU3BmAXL6HVKslJUlp+uEdkpHKcIIOEQKAFgL/XtYS3dHtDSuoDaw9ZbpMeQIgfwbhkOBeX1Wd3HNK+h0gF+lQ70KzfNa2fJAOAoAiUA9MA0TdW3R1TTGlJNW0jVLUHVtIUUinR9rs8jFab79MEbr6mxar0eved7yk3zyKAbCSAJECgB4CCYpqmIKYVMU+GI5PVIPsOQx5AMw9Ddd9+tX/3qV9q2bRthEkDS4KQcADgIhmHI6zGU5vUoI8WjNK9HXo/RGR7Lysq0fft2VVZWOlwpAPQdAiUAxFBZWZkkafHixQ5XAgB9h0AJADFUVFSkgoICLVq0yOlSAKDPECgBIIYMw9CUKVMIlACSCoESAGKsrKxMixYtEmseASQLAiUAxFhZWZm2bdumzZs3O10KAPQJAiUAxBgLcwAkGwIlAMTYkCFDlJ+fzzxKAEmDQAkAMWYYRuc8SgBIBgRKALABK70BJBMCJQDYoKysTDU1Naqurna6FACwHYESAGwQXZhDlxJAMiBQAoANhg4dqgEDBrDSG0BSIFACgA1YmAMgmRAoAcAmLMwBkCwIlABgk7KyMlVXV6umpsbpUgDAVgRKALAJC3MAJAsCJQDYZPjw4crNzWVhDoCER6AEAJuwMAdAsiBQAoCNCJQAkgGBEgBsNGXKFFVVVWnbtm1OlwIAtiFQAoCNWJgDIBkQKAHARiNGjFBOTg4LcwAkNAIlANjIMAw2OAeQ8AiUAGAzFuYASHQESgCw2ZQpU7Rp0yZt377d6VIAwBYESgCwGQtzACQ6AiUA2GzkyJHKzs4mUAJIWARKALCZx+PRlClTWOkNIGERKAGgD7AwB0AiI1ACQB+YMmWKNm7cqLq6OqdLAYCYI1ACQB+ILsxh2BtAIiJQAkAfGD16tLKyshj2BpCQCJQA0Ac8Ho8mT55MhxJAQiJQAkAfYWEOgERFoASAPlJWVqb169ervr7e6VIAIKYIlADQR6ZMmaIpU6aopqbG6VIAIKYM0zRNp4sAgGRgmqYMw+j8JwAkCgIlAAAAeoUhbwAAAPQKgRIAAAC9QqAEAABArxAoAQAA0CsESgAAAPQKgRIAnFJfLz35pNNVAECvsW0QADhl6VJpyhRp+XJpwgSprU1qbJQaGiS/XyoosP4JAC7nc7oAAEg6kYjU3i7961+SYUiXXSaddJLk9UorV0rr1kk1NdKJJ0pz5kiTJjldMQDsEx1KAOgr69ZZv9avl5YskZ5/Xrr4Ysnnk377W6mwUBo9WjrqKCkQkF59VZoxQ/r1r52uHAD2iQ4lANgtELBC4a9+JW3aZHUo8/OlL31Juusuadgw6ZFHpGBQysiwhrnb26WhQ6Vnn3W6egDYLwIlANjt44+lb39bOuEE6Z57pHHjpOJiaeDAz5+Tlrbnv5OWJl10kTUkDgAux5A3ANht1SrpyCOlFSuk8eP3fCwSkTxsuAEgvvEuBgB2y82VSkqkAQO6Pra/MGmaVugEABcjUAKA3QoKpF/+UkpJOfh/d+lS6ZVXYl0RAMQUQ94A4Ca7dyQ9HmvboJ/9TKqrc7YuANgHOpQA0BfCYampac+vRcPj7p/rDcPaj9LrtX5fX9/9UDkAuAirvAGgL1RUWCu85879fCGOYey5ijscthbwfPihVF5u/Vq8WLr6aqm11dpSCABciCFvAOgLlZXWfpNvvy2dfLJ1zOLKlVaA9HqtDc4fecQa4vZ4pLw8afBg6bjjpJtusvatBACXIlACQF859VSr4zhokDX8HQhYHcrWVutM782bpYkTpZkzpeHDrQAaHe42TfakBOBaBEoA6CsffST97nfSxo1WqBwxQho1Stq5U3riCStYrljhdJUAcNCYQwkAfeWoo6SpU63uZHb2no+1tkrf/a71+1Do80U5ABAH6FACgFNM8/MV3k1N0tq1VuAEgDhDoAQAAECvsA8lAAAAeoVACQAAgF4hUAIAAKBXCJQAAADoFQIlAAAAeoVACQAuEYlEnC4BAA4JgRIAXKCurk7Lly93ugwAOCTsQwkALnDNNdeovLxcS5cudboUADhodCgBwAXKysq0atUqBQIBp0sBgINGoAQAFygrK1MoFNKKFSucLgUADhqBEgBcYOLEifJ6vVq0aJHTpQDAQSNQAoAL+P1+jR8/nkAJIC4RKAHAJcrKygiUAOISgRIAXKKsrEwrV65Ue3u706UAwEEhUAKAS5SVlSkYDGrlypVOlwIAB4VACQAuMWnSJBbmAIhLBEoAcIn09HQdccQRBEoAcYdACQAuMmXKFAIlgLhDoAQAFykrK9OKFSvU0dHhdCkAcMAIlADgImVlZero6NCqVaucLgUADhiBEgBcpLS0VB6Ph2FvAHGFQAkALpKRkaFx48YRKAHEFQIlALgMC3MAxBsCJQC4TFlZmZYvX65gMOh0KQBwQAiUAOAyZWVlam9vZ2EOgLhBoAQAlyktLZVhGFq8eLHTpQDAASFQAoDL9OvXT2PHjmUeJYC4QaAEABdiYQ6AeEKgBAAXKisr07JlyxQKhZwuBQD2i0AJAC5UVlamQCCg1atXO10KAOwXgRIAXGjy5MkszAEQNwiUAOBCWVlZGjNmDPMoAcQFAiUAuFRZWRmBEkBcIFACgEtNmTJFS5cuZWEOANcjUAKAS5WVlamtrU0ff/yx06UAwD4RKAHApSZPnixJLMwB4HoESgBwqf79+2v06NHMowTgegRKAHAxFuYAiAcESgBwsSlTpmjJkiUKh8NOlwIAPSJQAoCLlZWVqbW1VZ988onTpQBAjwiUAOBiU6ZMkSSGvQG4GoESAFwsJydHI0eOZKU3AFcjUAKAy7EwB4DbESgBwOWiC3MikYjTpQBAtwiUAOByZWVlam5u1qeffup0KQDQLQIlALjc3gtzTNNUKGIqEI6oNRhRIBxRKGLKNE0nywSQxHxOFwAA6JlpmjIzsjX9a1/XJ8rR7z5tUE1bSKFuRr99Hqkw3adBGT4V7vqVl+aVYRh9XziApGKYfKQFANepbw9ryfaAltUF1B623qYjoZA8vv33ATySonkzzWto0gC/Jg/0KzfNa1/BAJIagRIAXCJimlrX2KFFtQFtbArKkBSLN+jodYZnpags36+R2any0LUEEEMESgBwgcrmoF6vaFJDRyRmQXJv0evmpHp09rAsFfdLseEuAJIRgRIAHBSMmHq3ukXltQHbguTeoveZmu/XyUWZSvHQrQTQOwRKAHBIZXNQ8yqa1NgR6ZMguTdDUnaqRzPoVgLoJQIlADigvLZN86ta+qwr2ZPo/acPydTU/HQHKwEQzwiUANCHTNPUwq1tWrCl1elSupg2KEPHF6SzzRCAg8bG5gDQh9waJiVpwZZWLdza5nQZAOIQgRIA+kj5NveGyagFW1pVXkuoBHBwCJQA0Acqm4Oav7nF6TIOyPyqFlU2B50uA0AcIVACgM2CEVPzKpoULzMTDUnzKpoUjDDFHsCBIVACgM3erW5xbGugQ2FKauyI6L3q+OioAnAegRIAbFTZHFR5bSBuwmSUKemj2gBD3wAOCIESAGwSMU29HkdD3XszJL1e0aQIu8sB2A8CJQDYZF1jhxriaKh7b6akho6I1jfSpQSwbwRKALDJol3nc8czQ9IithECsB8ESgCwQX17WBubgnHbnYwyJW1oCqq+Pex0KQBczOd0AQCQiJZsD9hyTvdT156nDYsW9vj4lY//UYefcHpM72lIWro9oFMHZ8b0ugASB4ESAGLMNE0tq7N3ZfeE02coNaNrwOt/2KCY38uUtLQuoFOKMjjnG0C3CJQAEGM72sNqD9s72H3WLfcot2iorffYXXvYVH17RHl+b5/dE0D8YA4lAMRYTWvI6RJskaivC0DvESgBIMZqWkMJ9+bqMaSaNgIlgO4x5A0AMbalNaSIzff46JUX1LqzXoZhaOCwkRp/ylnKGTTEtvtFTKm6hf0oAXSPQAkAMWSaZp908t7+zcN7/Pnvj/xQp157m06/9jbb7lnTFpJpmizMAdAFgRIAYihsSiEb25MlU47TUV+6XMMmHaWsgQVq2FqtlfP/qrefeUTzf/0z+TP76YRLr7fl3qGI1an0kicB7MUwTQ5pBYBYCYQjenT5jj6/76f/eVvP3vgV+ftl665/rlSKP92W+9wyMU9p3kSbIQqgt3hXAIAYitg9ebIHY447VYOPKFWguVGbViyy7T5hh14fAHcjUAJADHkcfFcdOHSEJKlp+1bb7kFzEkB3eGsAgBjyObhgpa2xQZK6PUEnVpx8fQDci0AJADHkNSSfA++szfXbtXHJB5KkwWMn2nIPn8fajxIA9kagBIAYMgxDhen2bKCxaXm51n30b+29lrK+epN+d9tMdbS1atzJZ6p/QZEt9y9M97FlEIBusW0QAMTYoAyfqltiv7l57ca1+ssPb1LWwAINHDZSWQMO085t1dq8ZrlC7QEVjByr87//8P4vdAg8hlSUmWLLtQHEPwIlAMRYYYbPlpNyiieU6ZiLZqlyxSJtW/+pKpZ9qFR/hgaNmaAjv3Cujr3wStu2C4qYsq3zCiD+sQ8lAMRYXSCkp9c0OF1GzF03Lld5fq/TZQBwIeZQAkCM5aV5lZZgx8mkeQ3lpvEjA0D3eHcAgBgzDEOTBviVKJHSkFQ6wM+CHAA9IlACgA0mD/QrUeYTmTJVOtDvdBkAXIxACQA2yE3zanhWStx3KSPhkNb+5x3dfN1VWrVqldPlAHApAiUA2KQsP/67lB6vT+P6mXrrrbc0YcIEnXPOOfr3v//tdFkAXIZACQA2GZmdqpxUT9x2KQ1JOake3fq1i7Ru3TrNnTtXGzZs0LRp03TCCSfo1VdfVSRixwZJAOINgRIAbOIxDJ1e4FMkTndnMyXNGJYlj2EoNTVVV1xxhZYvX67XXntNHo9HX/rSlzRhwgQ9++yz6ujocLpcAA4iUAKATd5//3198dgp+u+Lz0hxFioNSUfl+zWk356n43g8Hs2YMUMLFizQ+++/rzFjxuiqq65SSUmJ5syZo8bGRmcKBuAoAiUAxFggENDs2bM1bdo0HXbYYbrvqgvUP80bN0PfhqTsVI9OKsrc5/OOP/54vfLKK1q9erX+3//7f7rrrrs0dOhQ3XXXXdq6dWvfFAvAFTgpBwBiaPHixbriiiu0du1a3Xvvvbr99tvl9XpV2RzUC2t3Ol3eAbtsdH8V9zu4s7urqqr085//XE888YSCwaBmzpyp22+/XaNHj7apSgBuQYcSAGIgGAzq3nvv1THHHKOUlBSVl5dr9uzZ8nqtowqL+6Vo+pB9d/zcYvqQzIMOk5I0ZMgQPfjgg6qsrNTdd9+tV199VYcffrguuugilZeX21ApALegQwkAvbR69WrNnDlTS5Ys0V133aXvfe97Sk1N7fa579e0asGW1j6u8MBNG5ShEwozYnKtQCCguXPnas6cOfrss8906qmnavbs2TrjjDM4dQdIMHQoAeAQhcNhPfTQQ5oyZYqam5u1cOFC3XvvvT2GSUk6viBd0wbFJrDF2kmDMnR8QXrMruf3+3X99dfr448/1p///Gc1NTXpzDPP1JQpU/SHP/xBoVAoZvcC4CwCJQAcgvXr1+vUU0/VHXfcoRtvvFGLFy/W0Ucfvd9/zzAMnVCY0Tn87XSfLnr/6UMydXxhhi2dQ6/XqwsvvFAffvih3nzzTRUUFOjSSy/V6NGj9Ytf/EKtre7t2AI4MAx5A8BBME1TTz31lG677Tbl5+frueee08knn3xI16psDmpeRZMaOyKOnKgTXc09Y1jWIc2Z7I2lS5fqgQce0J/+9Cfl5eXpf/7nf3TjjTdqwIABfVoHgNggUALAAaqqqtLVV1+tf/7zn7ruuus0Z84cZWVl9eqawYipd6tbVF4bkCH1SbCM3ueofL9OKspUise5PumGDRv00EMP6be//a0Mw9C1116rW2+9VUOHDnWsJgAHj0AJAPthmqZeeOEFffOb31RmZqaeeeYZnXnmmTG9R2VzUK9XNKmhI2JbsIxeNyfVo7Md6EruS21trX7xi1/oF7/4hXbu3KlLLrlEd955p4488kinSwNwAAiUALAP27Zt0w033KCXX35Zl112mR5//HHl5ubacq+IaWp9Y1CLatu0oSkYs2AZvU5JVorK8tM1IjtFHpeusm5ubtYzzzyjhx9+WJs2bdJZZ52lO++8UyeddBIrwwEXI1ACQA/+7//+T9dff71M09Svf/1rXXjhhX127/r2sJZuD2hpXUDtYett2mNIkQN4x979eWleQ6UD/Cod6FdumtfGimMrGAzqT3/6k+6//36tXLlSxxxzjGbPnq3zzjtPHg/rSQG3IVACwF7q6+t100036Xe/+53OO+88PfnkkyooKHCkFtM0Vd8eUU1rSDVtIVW3BFXTFlIo0vW5Po9UmO5TUWaKCtN9KszwKTfNE9edPdM09fe//13333+/3nvvPR1++OG64447dPnllystLc3p8gDsQqAEgN288cYbuvrqq9Xc3KzHHntMX/va11wXyEzTVMSUQqapcETyeiSfYchjyHW1xtIHH3ygBx54QK+88ooKCwt188036/rrr1f//v2dLg1IegRKAJA1d++OO+7QE088oS984Qt65plnVFxc7HRZ6MYnn3yiBx98UM8//7zS09N1ww036Fvf+pYGDRrkdGlA0iJQAkh6CxYs0JVXXqmamhrNmTNHX//61xO605coqqur9eijj+qJJ55Qe3u7Zs6cqdtvv11jxoxxujQg6TCzGUDSCgQCuv3223XyySdr0KBBWrZsmW644QbCZJwoKirSAw88oMrKSt1777167bXXNHbsWF1wwQX68MMPnS4PSCp0KAEkpfLycl1xxRVat26dfvzjH+vWW2+V1xs/q6DRVSAQ0P/+7//qwQcf1Nq1a3XKKafozjvv1JlnnsmHBMBmdCgBJJVgMKi7775bxx57rNLT07V48WLdcccdhMkE4Pf7de2112rNmjV66aWX1NraqrPOOkulpaV64YUXFAqFnC4RSFgESgBJI7qf4U9+8hN973vf0wcffKDx48c7XRZizOv16vzzz9cHH3ygt99+W0VFRbr88ss1atQoPf7442ppaXG6RCDhECgBJLxwOKwHHnhAZWVlam9v13//+1/98Ic/VEqKe44eROwZhqFTTjlFf//737Vs2TKdeOKJuuWWWzRs2DD98Ic/1Pbt2w/twtGZYuFw7IoF4hxzKAEktM8++0xXXnmlFi5cqNtuu00/+tGP5Pf7nS4LDtm4caMefvhh/eY3v5EkXXPNNbr11ls1fPjwg7tQQ4P02GNSdbV0xhnS+efHvFYgnhAoASSkSCSiJ554QnfccYcKCwv13HPPadq0aU6XBZfYvn27fvnLX+rxxx9XQ0ODPv30U5WUlOx78Y5pSoYh1dVJ3/629Mwz0oQJ0tat0g03SD/4gcSxkEhSBEoACaeyslJXXXWV5s+frxtuuEEPPPCA+vXr53RZcKGWlha98cYbOv9gOoyvvy595SvSLbdI110npaVJTU3SqFFSKCR9/LE0ZoyUmmpf4YDL8FEKQMIwTVNz587VhAkTtGbNGr3xxhv61a9+RZhEjzIzM3X++edrv72V6OM7dkgvvihlZVlhcuhQqaDACpOS1NEh/eIXkt8v/fznUjBo7wsAXIJACSAhbN26VV/+8pd15ZVX6rzzztPKlSt1xhlnOF0W4sR+96mMPv7mm9Krr0qzZkndHc2ZkSHde690883SffdJq1fHvFbAjQiUAOLeX/7yF40fP14LFy7Uyy+/rOeff145OTlOl4VE8cEHVhfy0kul66+3wuVNN30eMncXDkuHHSYdc4y0bZu0YUPf1ws4gEAJIG6Zpql3331XF110kU466SStXLlSX/7yl50uC4lm+HArTP75z9J3viO98440aJAUiXR9bnRRzosvSocfLg0ZYv2Z5QpIcARKAHHLMAydfPLJeuutt/TSSy/psMMOc7okJKLCQumaa6TcXKvjOGmS9fW9V3RHIlbXculS6b33pNNPl8rKrMc4+hEJjkAJwF0OspNjmqZOPfVUzmqGPaLfj8GgFQp9PuvP3XUno9+DTz0lZWdL555rfa275wIJhkAJwB3WrbP+Gf2hfIDBkiAJWxmG1N4uzZ8vbd8uXXSR9fXu9ps0DKmlRVq+3AqU0X1P+R5FEiBQAnDW1q3SeedJ/+//SV/+svWDW+KHMNxj40bpd7/bcwh7b9EPQJmZ1vey1/t5N5PvZSQBn9MFAEhira3SHXdIlZXW0XWPP25tEF1YaJ1AEolw8gict3Kl1XX8y1+sbYH2Fj1Bp7lZuuce6Y9/lGprpbw86f33pYkT+75moI8RKAH0vWhQTE+XHnjA6upkZUmTJ0s33ig9/bT19bQ0pytFMosGxYoKq9tYWNj98yIRqyP5i19Iv/2t1aG8+mrpo4+s72sgCXD0IoC+9ac/Wduu3HuvlJ/f9fErrpDeftvqXN50k1RVZa2s5RxuOOWf/7S2DcrPl15+WRo37vPHwmErTAYCUmmpVFIivfCC1Z0EkghjSQD6ziOPWD+Yx42zFi3sLhy2/vnww9Yef7fcIn3hC9bRds8/b52RDDjhjDOkxYutzcrnzv38e1WywqQkPfustWhnxgzCJJISHUoAfWPHDmsoMCvL2iB6wICuz4l2e1aulD7+WPrxj63j7ebOtfYAZHEDnNbaas2jDAal116TamqkqVOtOcCHHy795jdWl3I/839DoZD+9a9/6dFHH9Xs2bPZ+gpxjw4lgL6Rm2uFyS1bev5BG+32TJggnX229UPb77c6PvywhRtEF+V4vdYCsttvl449VkpNlb7+dStMSvtdTObz+ZSamqpt27bp9NNP19FHH60///nPCu/e/QTiCIESQN+59lprPuScOXsOG3bH45GKiqRPP5X+8x/rawyowC08HmnmTKmhQfrwQ+kf//h8j8oD/D49/fTTtXjxYr3xxhvKzs7WV77yFY0dO1ZPPvmkAoGAfbUDNiBQAugbhmHt43fVVdJDD0kLFlhf7+4UkUjEWuF9663S5s3WMGJ9PaeOwH1SU60h7zFjPv/aQXTTDcPQGWecoTfffFMffvihSktLdcMNN2j48OG677771NDQEPuaARswhxJA31q2zFqYk5f3eajcl1tusVbN3nuvNaQIJLjPPvtMc+bM0XPPPaeUlBRdf/31uuWWWzR48GCnSwN6RKAE0LeCQStQfvyx9MEH1h6U3S1giH4tGLS6P0ccYW051K+fM3UDfaympkaPPfaYfvWrX6m1tVWXX3657rjjDo3bfdsiwCUY8gbQt1JSpOpqa4HOww9bv+9uAUP0aykp0vjx1lnf0UU7QBIoLCzUT3/6U23atEn33Xef/vnPf+qII47Qeeedp4ULFzpdHrAHAiWAvmOa0mmnWWcjS9Yw9jnnWCu/e/L1r0t/+5v0gx9YJ+sASSY7O1u33Xab1q9fr9/+9rf69NNPdcIJJ2jatGmaN2+eIswrhgsQKAH0HcOQfv97a1Xs3/4mPfec9MknVrDs6Oi6OnbnTmu4+1//sobJgSSWmpqqWbNmadWqVXr11VcViUR0zjnnaOLEiZo7d646OjqcLhFJjDmUAGKuurpaBQUF8vY0RB09I7m+3tpC6P77raD5la9Yj5eXWytnpf1uEA0ks3//+9+6//77NW/ePA0ZMkS33nqrrr32WvVjrjH6GO/SAGKmtbVV3/rWtzR27Fjt2LFDPX5ejW6rkpsrfe1r0imnSNdcY53jXVws/fKXUmOj9RzCJNCjE088Ua+99ppWrFih008/XXfeeaeGDh2q733ve9q2bZvT5SGJ0KEEEBMffPCBZs6c2bmA4KabbpLnQMPg8uXS7NnSihXW5tDf/a40cKC9BQMJqLKyUo888oieeuophcNhzZo1S7fddptGjhzpdGkxZ5qmwqYUMs3OgQyfYchriGMsHUCgBNAr7e3tuvfee/Wzn/1MU6dO1dy5czV27NhDuZB1TnJubuyLBJLMjh079Ktf/UqPPfaY6urqdOGFF2r27NmaMmWK06UdEtM0taM9rJrWkGpaQ9rSGlJNW0ihbtYj+TxSYbpPgzJ8Ktz1Ky/NS8i0GYESwCFbtmyZrrjiCq1Zs0Z33323Zs+eLZ/P53RZAHZpa2vTc889pzlz5mj9+vWaPn26Zs+erdNPPz0uAlZ9e1hLtge0rC6g9rAVVzySDmRd++7PS/MamjTAr8kD/cpNY/sxOxAoARy0UCik+++/X/fcc4/Gjh2r559/XqWlpU6XBaAHoVBIL730ku6//34tWbJEU6ZM0Z133qkLLrjAdR8CI6apdY0dWlQb0MamoAxJsQgq0esMz0pRWb5fI7NT5YmDUB0vCJQADsonn3yiK664QuXl5Zo9e7buvvtupaWlOV0WgANgmqbefPNN3X///Zo/f75GjBih22+/XVdeeaXSXbDPa2VzUK9XNKmhIxKzILm36HVzUj06e1iWivul2HCX5EOgBHBAIpGIHn/8cX37299WcXGx5s6dq+OOO87psgAcokWLFumBBx7QX/7yFw0cOFA33XSTvvGNbyjXgXnMwYipd6tbVF4bsC1I7i16n6n5fp1clKkUD93K3iBQAtivjRs3atasWXrnnXd000036b777lNGRobTZQGIgXXr1umhhx7Ss88+K6/Xq+uuu0633HKLiouL++T+lc1BzatoUmNHpE+C5N4MSdmpHs2gW9krBEoAPTJNU88884xuueUW5eXl6dlnn9Vpp53mdFkAbLBt2zY99thj+uUvf6nm5mZddtlluvPOO3XEEUfYds/y2jbNr2rps65kT6L3nz4kU1PznR/6j0cESgDdqq6u1rXXXqu//e1vuuqqq/Twww+rf//+TpcFwGZNTU36zW9+o4cfflhVVVU655xzdOedd+rEE0+M2T1M09TCrW1asKU1ZteMlWmDMnR8QXpcrIJ3E46gALAH0zT1xz/+URMmTNDixYv12muv6ZlnniFMAkkiKytLt9xyi9atW6fnnntO69at07Rp03TCCSfor3/9qyKRA9m0Z9/cGiYlacGWVi3c2uZ0GXGHQAmg0/bt23XxxRfrkksu0Re+8AWtXLlSM2bMcLosAA5ITU3VzJkztWLFCr322mvyeDw677zzNGHCBD377LPq6Og4pOuWb3NvmIxasKVV5bWEyoNBoAQgSXrttdc0YcIEvfnmm/rjH/+oP/3pTxowYIDTZQFwmMfj0YwZM7RgwQK9//77Gj16tK666iqNGDFCDz30kJqamg74WpXNQc3f3GJjtbEzv6pFlc1Bp8uIGwRKIMnt3LlTs2bN0rnnnqupU6dq5cqVuvjii50uC4ALHX/88Xr11Ve1atUqnXHGGfrOd76joUOH6rvf/a62bt26z383GDE1r6JJ8TIz0ZA0r6JJwQhLTQ4Ei3KAJPbmm29q1qxZamho0KOPPqpZs2YxER3AAauqqtKjjz6qJ598UsFgUFdeeaVuv/12jRo1qstz51c1a1FtwNHV3AfLkLVP5elD+jldiuvRoQRizDRNhSKmAuGIWoMRBcIRhSKm3PTZraWlRd/85jc1ffp0jRo1SitWrNBVV11FmARwUIYMGaI5c+Zo06ZN+sEPfqD/+7//05gxY3TRRRepvLy883mVzUGVx1mYlKythD6qDTD0fQDoUAK9YJqmdrSHVdMaUk1rSFtaQ6ppCynUzSJIn0cqTPdpUIZPhbt+5aV5+zzELVy4UDNnztTmzZt1//3368Ybb5THw2dLAL3X1tam559/Xg8++KDWrVun0047TXfOnq31g6c6tnF5bxmS+qd6dN0RuZz9vQ8ESuAQ1LeHtWR7QMvqAmoPW3+FPJIOZDON3Z+X5jU0aYBfkwf6lZvmtalaS3t7u+6++249+OCDOvroozV37lyNGTPG1nsCSE7hcFgvv/yy7r//frVkDtDMR19wuqReu3BEtkb1T3W6DNciUAIHKGKaWtfYoUW1AW1sCsbsZIfodYZnpags36+R2akx/xS8ZMkSXXHFFfrkk090zz336I477pDP54vpPQBgb6Zp6tcfbVSDJ0Mer70fmu1kyHqPvngU+/H2hJ8owAGobA7q9YomNXREOlcoxuqTWPQ6FU1BbWwKKifVo7NjdKZsKBTSfffdp3vvvVfjx49XeXm5Jk6c2OvrAsCBaOiIqDElK+4XbJiSNjQFVd8etn00KV7RoQT2IRgx9W51i8prA3121mz0PlPz/Tq5KFMpnkPrVq5Zs0YzZ87UokWL9J3vfEc/+MEPlJrKcA2AvvPW5hZ9tK0tpu+dm1cv09r/vqOqlUtUuXKRGmtr5EtN048+qIrhXboyJB19WLpOHZxp633iFR1KoAeVzUHNq2hSY4c147GvPnlF77OoNqC1Ozs04yC7lZFIRI8++qjuuusuDR8+XAsXLtQxxxxjT7EA0APTNLWsLvYru9/6zUNa/c7fY3zV/TMlLa0L6JSiDHbE6AaBEuhGeW2b5le19FlXsjumpMaOiF5Yu1PTh2Rqan76fv+d9evXa9asWXrvvfd088036yc/+YkyMjLsLxYA9rKjPdy5aDGWhk6cqsLR4zVk/GQNGV+qn35hfMzv0ZP2sKn69ojy/Ax7741ACezGNE0t3Pr5ObNOzweJ3n9+VYvaw6aOL0jv9pOxaZp6+umndeutt2rgwIF6++23dcopp/RprQCwu5rWkC3XPfnKm2y57oGqaQ0RKLsR7/NkgZjaPUy6zYItrVq4ta3L1zdv3qyzzjpL119/vS699FKtWLGCMAnAcTWtoYQLGR5DqmmzJyjHOzqUwC7l29wbJqMWbGlVmtfQ1Px0maap3//+9/rmN7+p9PR0vf766zrrrLOcLhEAJElbWkMHtDdvPImYUnULp+Z0J9E+PACHpLI5qPmbW5wu44DMr2rRiqpaXXjhhbr88sv1xS9+UStXriRMAnAN0zQTtpNX0xZy1VG6bkGHEkkvGDE1r6LJ0QU4B8U09fsVm/X+B//Viy++qIsuusjpigBgD2FT3R5BmwhCEatT6WWh9x4IlEh671a3xNcZs4ah7MOK9NTbi3XumMOcrgYAuggleAcvZJryikS5O4a8kdQqm4Mqr439Pml2MzwerW7xqLKZuTwA3CeSoN3JqHCCv75DQaBE0oqYpl7fNdQdjwxJr1c0KZLgnQAA8ceT4OnCm+Cv71DwnwRJa11jhxriaah7L6asc3LXN9KlBOAuvgQ/SSbRX9+hIFAiaS3adT53PDMkLartujclADjJa0i+BE0YPo+1HyX2lKD/u4F9q28Pa2NTMG67k1GmpA1NQdW3h50uBQA6GYahwvTEXPdbmO7jLO9uJOb/bWA/lmwPxHyboI62Vq394B19/N4bqlq1VPVbNikSjmhAcYkmnD5DJ17+daVl9IvhHS2GpKXbAzp1cGbMrw0Ah2pQhk/VLbHf3PzjBf/UW08/vMfXwsEO/eqKMzv/fNq1t2rstDNifGerM1mUmRLz6yYCAiWSjmmaWlYX+5Xdy/7xkl7+0a2SpIKRYzXm+NMUaG7SpuUfaf4T92vZP17Wdb95Vf3y8mN6X1PS0rqATinK4FMzANcozPDZclJOS32dKlcu2uNrpmnu8bWW+job7mztP5mondfe4r8Kks6O9rDaw7Ef7PampOqYi2bpxMuu18ChIzu/3lhbo7nfulTVH6/QvDnf01d/+mTM790eNlXfHlGe3xvzawPAoSjMsCdilJ17icrOvcSWax8Iu15XvGMOJZJOTas9x4FNmXGxvvSdB/YIk5KUnV+oc2ffL0la9dbrCgU7bLm/Xa8LAA5FXppXaQl2nEya11BuGtGpO/xXQdKpaQ31+Tf+oDHjJUmhjna1NuyI+fU9hhL23FwA8ckwDE0a4I/73TSiDEmlA/xMLeoBgRJJZ0tr7CeJ78+OzRWSJK8vRRn9c2N+/YgpVbewHyUAd5k80B/3u2lEmZJKB/qdLsO1CJRIKqZpOtLJW/iHpyRJY44/Tb7UNFvuUdMWksmpOQBcJDfNq+FZKXHfpTQklWSlKDeNeeo9IVAiqYRNKdTH7cmP//0vlb/ygry+FH3hG9+27T6hiNWpBAA3KcuP/y6lKaksP93pMlyNQImkEurjDt629Z/qxe99Q6Zp6os3361BYybYer++fn0AsD8js1OVk+qJ2y6lISkn1aMR2ew/uS8ESiSVSB92J3durdaz37xYbY0NOvHyG3TCpdfbfs9wX08OBYD98BiGzh6WFbddSlPSjGFZ8rAYZ58IlEgqnj76jm+pr9MzN1yohpoqlZ17ic665Z4+ua+Xv9EAXKi4X4qm5sffim9D0lH5fg3pR3dyf/jxg6Ti64NPmO0tzXr2f76q2o1rNf60s3X+9x/ps20m+uL1AcChOLkoU9lxNPRtSMpO9eikIo61PRAESiQVryH5bPyuD3W06/lbvqbNq5dq9HGn6qv3PSWPt29WBfo81n6UAOBGKR5DM+Jo6Ds61J3CG+sBIVAiqRiGYds5rJFwWH/8zvVaX/5vDZ98rC6f85x8Kam23Ks7hek+NtwF4GrF/VI0fUh8dPymD8lUMUPdB4wDKZF0BmX4VN0S+83N//On32jV269LkjJzBujVn93Z7fPOuvkeZeYOiOm9PYZUlMkbHwD3m5qfrvawqQVbWp0upUfTBmVoKtsEHRQCJZJOYYbPlpNy2hp3dv4+Giy7M/36O2MeKCOmbOu8AkCsHV9ghTU3hsqTBmXouALC5MEyTI7WQJKpC4T09JoGp8uIuevG5SrPzykOAOJHeW2b5le1yJAcnVsZvf/0IZl0Jg8RLQ0knbw0r9K8htrDifNZKs1rKDeNKdEA4svU/HQVpPs0r6JJjR0RR0JldDX3jGFZzJnsBX4CIekYhqFJA+JvP7SeGJJKB/hZkAMgLhX3S9E143JVlu+XpD57b47eZ2q+X9eMyyVM9hKBEklp8sD4P1s2ypRUOtDvdBkAcMhSPIamD+mny0b3V/9UK5rYFSyj1+2f6tFlo/vr9CH92BooBphDiaT1x892qqIpGNfB0pA0PCtFF4/q73QpABATEdPU+sagFtW2aUNTMGbzK6PXKclKUVl+ukZkp3CcYgwxhxJJqyzfr41NQafL6BVTUhkTyAEkEI9haFT/VI3qn6r69rCWbg9oaV2gc967x7B2ttj/dT5/XprXUOkAv0oH+pWbxuJFO9ChRNKKmKaeWl2vnQ5NBO8tQ9aQzXVH5PIpG0BCM01T9e0R1bSGVNMWUnVLUDVtIYW62QPO57G2USvKTFFhuk+FGT7lpnmYZ24zAiWSWmVzUC+s3bn/J7rU5aP7awgTyQEkIdM0FTGlkGkqHJG8HslnGPIYIjw6gEU5SGrF/VI0NT/+Vnwbko7K9xMmASQtwzDk9RhK83qUkeJRmtcjr8cgTDqEQImkd3JRprJTPXETKqN7pp1UFB/n4QIAEh+BEkkvxWNoxrCsuJlHaUqaMSyLbS4AAK5BoARkDX1PHxIfHb/pQzLZgBcA4CoESmCXqfnpmjYow+ky9mnaoAzOmQUAuA77UAK7Ob7ACmsLtrQ6XElXJw3K0HEFhEkAgPuwbRDQjfLaNs2vaonZCQ2HKnr/6UMy6UwCAFyLQAn0oLI5qHkVTWp0aOPz6GruGcOymDMJAHA1AiWwD8GIqXerW1ReG+izbmX0Pkfl+3VSUSaruQEArkegBA5AZXNQr1c0qaEjYluwjF43J9Wjs+lKAgDiCIESOEAR09T6xqAW1bZpQ1MwZsEyep2SrBSV5adrRHYKZ3MDAOIKgRI4BPXtYS3dHtDSuoDaw9ZfIY8hRQ7gb9Puz0vzGiod4FfpQL9y07w2VgwAgH0IlEAvmKap+vaIalpDqmkLqbolqJq2kEKRrs/1eaTCdJ+KMlNUmO5TYYZPuWkezp0FAMQ9AiUQY6ZpKmJKIdNUOCJ5PZLPMOQxRHgEACQkAiUAAAB6haMXAQAA0CsESgAAAPQKgRIAAAC9QqAEAABArxAoAQAA0CsESgAAAPQKgRIAAAC9QqAEAABArxAoAQAA0CsESgAAAPQKgRIAAAC9QqAEAABArxAoAQAA0CsESgAAAPQKgRIAAAC9QqAEAABArxAoAQAA0CsESgAAAPQKgRIAAAC9QqAEAABArxAoAQAA0CsESgAAAPTK/wftcaJ+WRk5qwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = dataset[num]\n",
    "data\n",
    "\n",
    "g = nx.Graph()\n",
    "g.add_nodes_from(range(data.num_nodes))\n",
    "edges = data.edge_index.t().tolist()\n",
    "# edge_attrs = {tuple(edge): attr.item() for edge, attr in zip(edges, data.edge_attr)}\n",
    "g.add_edges_from(edges)\n",
    "print(len(edges))\n",
    "\n",
    "# Draw the graph with edge attributes\n",
    "pos = nx.spring_layout(g)  # positions for all nodes\n",
    "nx.draw(g, pos, with_labels=True, node_color='skyblue', node_size=1500, edge_color='k', linewidths=1, font_size=15)\n",
    "nx.draw_networkx_edge_labels(g, pos, font_color='red', font_size=12)  # Add edge labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_num_nodes: 3\n",
      "max_num_nodes: 165\n",
      "mean_num_nodes: 15.006369426751592\n",
      "min_num_edges: 2\n",
      "max_num_edges: 208\n",
      "mean_num_edges: 18.29299363057325\n",
      "mean nodes degree: 1.2190152801358236\n"
     ]
    }
   ],
   "source": [
    "def graph_stat(dataset, verilog_files):\n",
    "    \"\"\"\n",
    "    TODO: calculate the statistics of the ENZYMES dataset.\n",
    "    \n",
    "    Outputs:\n",
    "        min_num_nodes: min number of nodes\n",
    "        max_num_nodes: max number of nodes\n",
    "        mean_num_nodes: average number of nodes\n",
    "        min_num_edges: min number of edges\n",
    "        max_num_edges: max number of edges\n",
    "        mean_num_edges: average number of edges\n",
    "    \"\"\"\n",
    "    # for ind,data in enumerate(dataset):\n",
    "        # print(verilog_files[ind])\n",
    "        # print(data)\n",
    "        # print(len(data.x[1]))\n",
    "        \n",
    "    nodes_edges = [(data.num_nodes, data.num_edges) for data in dataset]\n",
    "    num_nodes, num_edges = list(list(zip(*nodes_edges))[0]), list(list(zip(*nodes_edges))[1])\n",
    "    min_num_nodes = min(num_nodes)\n",
    "    max_num_nodes = max(num_nodes)\n",
    "    mean_num_nodes = np.mean(num_nodes)\n",
    "    min_num_edges = min(num_edges)\n",
    "    max_num_edges = max(num_edges)\n",
    "    mean_num_edges = np.mean(num_edges)\n",
    "    mean_degree = (mean_num_edges)/mean_num_nodes\n",
    "    \n",
    "    print(f\"min_num_nodes: {min_num_nodes}\")\n",
    "    print(f\"max_num_nodes: {max_num_nodes}\")\n",
    "    print(f\"mean_num_nodes: {mean_num_nodes}\")\n",
    "    print(f\"min_num_edges: {min_num_edges}\")\n",
    "    print(f\"max_num_edges: {max_num_edges}\")\n",
    "    print(f\"mean_num_edges: {mean_num_edges}\")\n",
    "    print(f\"mean nodes degree: {mean_degree}\")\n",
    "\n",
    "graph_stat(dataset, verilog_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    if isinstance(batch[0], Data):\n",
    "        return batch\n",
    "    else:\n",
    "        return default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import random_split\n",
    "\n",
    "# # Define the sizes of training, validation, and test sets\n",
    "# train_size = int(0.7 * len(dataset))  # 70% of the data for training\n",
    "# val_size = int(0.15 * len(dataset))   # 15% of the data for validation\n",
    "# test_size = len(dataset) - train_size - val_size  # Remaining data for testing\n",
    "\n",
    "# # Split the dataset into training, validation, and test sets\n",
    "# train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# # Create DataLoader for each set\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "\n",
    "# Define the size of the training set (e.g., 70% of the data)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "\n",
    "# Calculate the size of the testing set\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoader for each set\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=custom_collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=custom_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[8, 20], edge_index=[2, 7], y=[1, 16], batch=[8])\n"
     ]
    }
   ],
   "source": [
    "print(train_loader.dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data(x=[16, 20], edge_index=[2, 19], y=[1, 16], batch=[16]), Data(x=[8, 20], edge_index=[2, 7], y=[1, 16], batch=[8]), Data(x=[25, 20], edge_index=[2, 26], y=[1, 16], batch=[25]), Data(x=[9, 20], edge_index=[2, 8], y=[1, 16], batch=[9]), Data(x=[29, 20], edge_index=[2, 50], y=[1, 16], batch=[29]), Data(x=[5, 20], edge_index=[2, 4], y=[1, 16], batch=[5]), Data(x=[7, 20], edge_index=[2, 6], y=[1, 16], batch=[7]), Data(x=[31, 20], edge_index=[2, 36], y=[1, 16], batch=[31]), Data(x=[13, 20], edge_index=[2, 15], y=[1, 16], batch=[13]), Data(x=[4, 20], edge_index=[2, 3], y=[1, 16], batch=[4]), Data(x=[10, 20], edge_index=[2, 9], y=[1, 16], batch=[10]), Data(x=[8, 20], edge_index=[2, 7], y=[1, 16], batch=[8]), Data(x=[22, 20], edge_index=[2, 21], y=[1, 16], batch=[22]), Data(x=[27, 20], edge_index=[2, 29], y=[1, 16], batch=[27]), Data(x=[3, 20], edge_index=[2, 2], y=[1, 16], batch=[3]), Data(x=[5, 20], edge_index=[2, 4], y=[1, 16], batch=[5])]\n"
     ]
    }
   ],
   "source": [
    "loader_iter = iter(train_loader)\n",
    "batch = next(loader_iter)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConv(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNConv, self).__init__()\n",
    "        self.theta = nn.Parameter(torch.FloatTensor(in_channels, out_channels))\n",
    "        # Initialize the parameters.\n",
    "        stdv = 1. / math.sqrt(out_channels)\n",
    "        self.theta.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "            1. Generate the adjacency matrix with self-loop \\hat{A} using edge_index.\n",
    "            2. Calculate the diagonal degree matrix \\hat{D}.\n",
    "            3. Calculate the output X' with torch.mm using the equation above.\n",
    "        \"\"\"\n",
    "\n",
    "        num_nodes = x.shape[0]\n",
    "        A = torch.sparse_coo_tensor(edge_index, torch.ones(edge_index.shape[1]), (num_nodes, num_nodes))\n",
    "        A = A.to_dense()\n",
    "        A_hat = A + torch.eye(num_nodes)\n",
    "        \n",
    "        A_sum = torch.sum(A_hat, dim=1)\n",
    "        D = torch.pow(A_sum, -0.5)\n",
    "        D[D == float('inf')] = 0.0\n",
    "        D_hat_sqrt = torch.diag(D)\n",
    "        \n",
    "        first = torch.mm(torch.mm(D_hat_sqrt, A_hat), D_hat_sqrt)\n",
    "        second = torch.mm(x, self.theta)\n",
    "        \n",
    "        ret = torch.mm(first, second)\n",
    "        \n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (gcn1): GCNConv()\n",
       "  (a1): ReLU()\n",
       "  (gcn2): GCNConv()\n",
       "  (a2): ReLU()\n",
       "  (gcn3): GCNConv()\n",
       "  (a3): ReLU()\n",
       "  (gcn4): GCNConv()\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (linear): Linear(in_features=128, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from torch_geometric.nn import GCNConv\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "            1. Define the first convolution layer using `GCNConv()`. Set `out_channels` to 64;\n",
    "            2. Define the first activation layer using `nn.ReLU()`;\n",
    "            3. Define the second convolution layer using `GCNConv()`. Set `out_channels` to 64;\n",
    "            4. Define the second activation layer using `nn.ReLU()`;\n",
    "            5. Define the third convolution layer using `GCNConv()`. Set `out_channels` to 64;\n",
    "            6. Define the dropout layer using `nn.Dropout()`;\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        num_node_features = 20\n",
    "        num_output_classes = 16\n",
    "        \n",
    "        # num_channels = 32\n",
    "        \n",
    "        self.gcn1 = GCNConv(in_channels=num_node_features, out_channels=128)\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.gcn2 = GCNConv(in_channels= 128, out_channels=128)\n",
    "        self.a2 = nn.ReLU()\n",
    "        self.gcn3 = GCNConv(in_channels=128, out_channels=128)\n",
    "        self.a3 = nn.ReLU()\n",
    "        self.gcn4 = GCNConv(in_channels=128, out_channels=128)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.linear = nn.Linear(in_features=128, out_features=num_output_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        \"\"\"\n",
    "            x: [num_nodes, 4], node features\n",
    "            edge_index: [2, num_edges], edges\n",
    "            edge_attrib : [num_edges, 1], edge attributes\n",
    "            batch: [num_nodes], batch assignment vector which maps each node to its \n",
    "                   respective graph in the batch\n",
    "\n",
    "        Outputs:\n",
    "            probs: probabilities of shape (batch_size, 16)\n",
    "        \"\"\"\n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = self.a1(x)\n",
    "        x = self.gcn2(x, edge_index)\n",
    "        x = self.a2(x)\n",
    "        x = self.gcn3(x, edge_index)\n",
    "        x = self.a3(x)\n",
    "        x = self.gcn4(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        probs = torch.nn.functional.softmax(x, dim=-1)\n",
    "        \n",
    "        return probs\n",
    "        \n",
    "        \n",
    "        \n",
    "GCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 002, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 003, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 004, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 005, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 006, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 007, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 008, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 009, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 010, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 011, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 012, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 013, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 014, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 015, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 016, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 017, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 018, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 019, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 020, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 021, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 022, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 023, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 024, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 025, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 026, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 027, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 028, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 029, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 030, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 031, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 032, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 033, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 034, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 035, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 036, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 037, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 038, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 039, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 040, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 041, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 042, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 043, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 044, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 045, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 046, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 047, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 048, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 049, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 050, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 051, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 052, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 053, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 054, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 055, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 056, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 057, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 058, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 059, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 060, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 061, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 062, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 063, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 064, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 065, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 066, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 067, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 068, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 069, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 070, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 071, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 072, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 073, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 074, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 075, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 076, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 077, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 078, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 079, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 080, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 081, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 082, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 083, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 084, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 085, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 086, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 087, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 088, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 089, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 090, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 091, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 092, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 093, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 094, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 095, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 096, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 097, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 098, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 099, Train Acc: 0.0913, Test Acc: 0.0913\n",
      "Epoch: 100, Train Acc: 0.0913, Test Acc: 0.0913\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [29], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Your training code here\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m):\n\u001b[1;32m---> 56\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     train_acc \u001b[38;5;241m=\u001b[39m test(train_loader)\n\u001b[0;32m     58\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m test(train_loader)\n",
      "Cell \u001b[1;32mIn [29], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_data \u001b[38;5;129;01min\u001b[39;00m train_loader:  \u001b[38;5;66;03m# Iterate in batches over the training dataset.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m batch_data:\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;66;03m# print(data.x, data.edge_index, data.batch, data.y)\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[43mgcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;66;03m# pred = out.argmax(dim=1)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;66;03m# pred_out = torch.tensor(pred, dtype=torch.float16)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;66;03m# print(out)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;66;03m# print(data.y)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m         out_labels\u001b[38;5;241m.\u001b[39mappend((out, data\u001b[38;5;241m.\u001b[39my))\n",
      "File \u001b[1;32mc:\\Users\\Mai\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Mai\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [25], line 42\u001b[0m, in \u001b[0;36mGCN.forward\u001b[1;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, batch):\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m        x: [num_nodes, 4], node features\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m        edge_index: [2, num_edges], edges\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m        probs: probabilities of shape (batch_size, 16)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma1(x)\n\u001b[0;32m     44\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgcn2(x, edge_index)\n",
      "File \u001b[1;32mc:\\Users\\Mai\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Mai\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [24], line 19\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     17\u001b[0m num_nodes \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     18\u001b[0m A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse_coo_tensor(edge_index, torch\u001b[38;5;241m.\u001b[39mones(edge_index\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), (num_nodes, num_nodes))\n\u001b[1;32m---> 19\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m A_hat \u001b[38;5;241m=\u001b[39m A \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(num_nodes)\n\u001b[0;32m     22\u001b[0m A_sum \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(A_hat, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "gcn = GCN()\n",
    "\n",
    "# print(gcn.parameters())\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(gcn.parameters(), lr=0.01)\n",
    "# loss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "out_y= []\n",
    "\n",
    "out_labels = []\n",
    "def train(train_loader):\n",
    "    gcn.train()\n",
    "    # print(gcn.parameters())\n",
    "    for batch_data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        for data in batch_data:\n",
    "            # print(data.x, data.edge_index, data.batch, data.y)\n",
    "            out = gcn(data.x, data.edge_index, data.batch)\n",
    "            # pred = out.argmax(dim=1)\n",
    "            # pred_out = torch.tensor(pred, dtype=torch.float16)\n",
    "            # print(out)\n",
    "            # print(data.y)\n",
    "            out_labels.append((out, data.y))\n",
    "            loss = criterion(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "testing_labels = []\n",
    "\n",
    "def test(loader):\n",
    "    gcn.eval()\n",
    "    correct = 0\n",
    "    for batch_data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        for data in batch_data:\n",
    "            out = gcn(data.x, data.edge_index, data.batch)  \n",
    "            pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "            testing_labels.append(pred)\n",
    "            y_label = (data.y.tolist())\n",
    "            y_label = y_label[0].index(1.0)\n",
    "            pred_label = (pred.tolist())[0]\n",
    "            # print(pred_label)\n",
    "            # print(y_label)\n",
    "            if y_label == pred_label:\n",
    "                correct += 1            \n",
    "            # correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Your training code here\n",
    "for epoch in range(200):\n",
    "    train(train_loader)\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(train_loader)\n",
    "    \n",
    "    print(f'Epoch: {epoch + 1:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the duration\n",
    "duration = end_time - start_time\n",
    "print(\"Training duration:\", duration, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1958762886597938"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gcn.state_dict(), 'gcn_model4.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([17])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[0,0,1], [0,0,1], [1,0,1], [3,3,1]], dtype=torch.float)\n",
    "y = torch.tensor([2], dtype=torch.long)\n",
    "edge_index = torch.tensor([[0, 1, 2],\n",
    "                           [3, 3, 3]], dtype=torch.long)\n",
    "gcn.eval()\n",
    "batch = torch.tensor([0, 0, 0, 0], dtype=torch.long)\n",
    "data_trial = Data(x=x, edge_index=edge_index, y=y, batch = batch)\n",
    "\n",
    "out = gcn(data_trial.x, data_trial.edge_index, data_trial.batch)\n",
    "pred = out.argmax(dim=1)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcn = GCN()\n",
    "# gcn.load_state_dict(torch.load('gcn_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [213], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m one_hot_list \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlong)  \u001b[38;5;66;03m# Example one-hot encoded representation of class 2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Get the index of the non-zero element\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mone_hot_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "one_hot_list = torch.tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0], dtype = torch.long)  # Example one-hot encoded representation of class 2\n",
    "\n",
    "# Get the index of the non-zero element\n",
    "index = one_hot_list.index(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode of Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 321 verilog files \n",
    "* only 3 features             [type, operation_type, num_of_connections]\n",
    "* no edge attribute\n",
    "* 18 classes \n",
    "* 200 epochs \n",
    "* learning rate = 0.01\n",
    "* Dropoout = 0.4\n",
    "* Adam Optimizer\n",
    "* train 70, test 30 (on whole dataset, not each class)\n",
    "* time of training = seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train acc:  0.2902\n",
    "* Test Acc: 0.1959\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested Modifications for upcoming experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Clean dataset (by removing unnecessay, uninformative or wrong code files)\n",
    "2) remove reduntant parsing (different files but same parsing)\n",
    "3) include more informative features\n",
    "4) improve encoding format\n",
    "5) try using less classes (most important ones, so that less classes but more balanced dataset)\n",
    "6) adding more files\n",
    "7) adjusting hyperparameters such as learning rate, dropout, ...etc\n",
    "8) splitting train, val, test\n",
    "9) using equal percentages of each class (adjusting splitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode of Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested Modifications for upcoming experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr = 0.01\n",
    "\n",
    "all 20 features \n",
    "\n",
    "dropout 0.4\n",
    "\n",
    "train = 0.9 test = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
