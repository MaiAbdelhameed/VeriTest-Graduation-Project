{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\mai\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (2022.2.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "!pip install torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "!pip install torch_geometric -q\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data import random_split\n",
    "import math\n",
    "from torch_geometric.utils import to_dense_adj, add_self_loops\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "DATA_PATH = \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['done\\\\adder11.txt', 'done\\\\adder12.txt', 'done\\\\adder13.txt', 'done\\\\adder14.txt', 'done\\\\adder15.txt', 'done\\\\adder16.txt', 'done\\\\adder17.txt', 'done\\\\adder18.txt', 'done\\\\adder19.txt', 'done\\\\adder2.txt', 'done\\\\adder20.txt', 'done\\\\adder5.txt', 'done\\\\adder6.txt', 'done\\\\adder8.txt', 'done\\\\ALU10.txt', 'done\\\\ALU13.txt', 'done\\\\ALU14.txt', 'done\\\\ALU15.txt', 'done\\\\ALU2.txt', 'done\\\\ALU6.txt', 'done\\\\ALU7.txt', 'done\\\\ALU8.txt', 'done\\\\ALU9.txt', 'done\\\\and1.txt', 'done\\\\and10.txt', 'done\\\\and12.txt', 'done\\\\and13.txt', 'done\\\\and14.txt', 'done\\\\and15.txt', 'done\\\\and16.txt', 'done\\\\and17.txt', 'done\\\\and18.txt', 'done\\\\and19.txt', 'done\\\\and2.txt', 'done\\\\and20.txt', 'done\\\\and21.txt', 'done\\\\and23.txt', 'done\\\\and25.txt', 'done\\\\and26.txt', 'done\\\\and27.txt', 'done\\\\and28.txt', 'done\\\\and29.txt', 'done\\\\and3.txt', 'done\\\\and30.txt', 'done\\\\and6.txt', 'done\\\\and7.txt', 'done\\\\and8.txt', 'done\\\\and9.txt', 'done\\\\comparator1.txt', 'done\\\\comparator13.txt', 'done\\\\comparator14.txt', 'done\\\\comparator15.txt', 'done\\\\comparator16.txt', 'done\\\\comparator17.txt', 'done\\\\comparator18.txt', 'done\\\\comparator19.txt', 'done\\\\comparator2.txt', 'done\\\\comparator20.txt', 'done\\\\comparator21.txt', 'done\\\\comparator22.txt', 'done\\\\comparator23.txt', 'done\\\\comparator6.txt', 'done\\\\comparator7.txt', 'done\\\\comparator8.txt', 'done\\\\comparator9.txt', 'done\\\\decoder1.txt', 'done\\\\decoder11.txt', 'done\\\\decoder12.txt', 'done\\\\decoder13.txt', 'done\\\\decoder14.txt', 'done\\\\decoder15.txt', 'done\\\\decoder16.txt', 'done\\\\decoder17.txt', 'done\\\\decoder18.txt', 'done\\\\decoder19.txt', 'done\\\\decoder2.txt', 'done\\\\decoder20.txt', 'done\\\\decoder21.txt', 'done\\\\decoder22.txt', 'done\\\\decoder23.txt', 'done\\\\decoder24.txt', 'done\\\\decoder25.txt', 'done\\\\decoder26.txt', 'done\\\\decoder27.txt', 'done\\\\decoder28.txt', 'done\\\\decoder29.txt', 'done\\\\decoder3.txt', 'done\\\\decoder30.txt', 'done\\\\decoder31.txt', 'done\\\\decoder32.txt', 'done\\\\decoder4.txt', 'done\\\\encoder1.txt', 'done\\\\encoder10.txt', 'done\\\\encoder11.txt', 'done\\\\encoder12.txt', 'done\\\\encoder13.txt', 'done\\\\encoder14.txt', 'done\\\\encoder15.txt', 'done\\\\encoder16.txt', 'done\\\\encoder17.txt', 'done\\\\encoder18.txt', 'done\\\\encoder19.txt', 'done\\\\encoder2.txt', 'done\\\\encoder20.txt', 'done\\\\encoder21.txt', 'done\\\\encoder24.txt', 'done\\\\encoder25.txt', 'done\\\\encoder3.txt', 'done\\\\encoder4.txt', 'done\\\\encoder5.txt', 'done\\\\encoder6.txt', 'done\\\\encoder7.txt', 'done\\\\encoder8.txt', 'done\\\\encoder9.txt', 'done\\\\mult1.txt', 'done\\\\mult10.txt', 'done\\\\mult11.txt', 'done\\\\mult12.txt', 'done\\\\mult13.txt', 'done\\\\mult14.txt', 'done\\\\mult15.txt', 'done\\\\mult16.txt', 'done\\\\mult17.txt', 'done\\\\mult18.txt', 'done\\\\mult19.txt', 'done\\\\mult2.txt', 'done\\\\mult3.txt', 'done\\\\mult30.txt', 'done\\\\mult31.txt', 'done\\\\mult32.txt', 'done\\\\mult33.txt', 'done\\\\mult34.txt', 'done\\\\mult35.txt', 'done\\\\mult4.txt', 'done\\\\mult5.txt', 'done\\\\mult6.txt', 'done\\\\mult8.txt', 'done\\\\mult9.txt', 'done\\\\mux1.txt', 'done\\\\mux10.txt', 'done\\\\mux11.txt', 'done\\\\mux12.txt', 'done\\\\mux13.txt', 'done\\\\mux14.txt', 'done\\\\mux15.txt', 'done\\\\mux16.txt', 'done\\\\mux17.txt', 'done\\\\mux18.txt', 'done\\\\mux19.txt', 'done\\\\mux2.txt', 'done\\\\mux20.txt', 'done\\\\mux21.txt', 'done\\\\mux22.txt', 'done\\\\mux23.txt', 'done\\\\mux24.txt', 'done\\\\mux25.txt', 'done\\\\mux26.txt', 'done\\\\mux3.txt', 'done\\\\mux4.txt', 'done\\\\mux5.txt', 'done\\\\mux6.txt', 'done\\\\mux7.txt', 'done\\\\mux8.txt', 'done\\\\mux9.txt', 'done\\\\nand1.txt', 'done\\\\nand10.txt', 'done\\\\nand11.txt', 'done\\\\nand12.txt', 'done\\\\nand14.txt', 'done\\\\nand15.txt', 'done\\\\nand16.txt', 'done\\\\nand17.txt', 'done\\\\nand18.txt', 'done\\\\nand19.txt', 'done\\\\nand2.txt', 'done\\\\nand20.txt', 'done\\\\nand21.txt', 'done\\\\nand22.txt', 'done\\\\nand3.txt', 'done\\\\nand4.txt', 'done\\\\nand6.txt', 'done\\\\nand7.txt', 'done\\\\nand8.txt', 'done\\\\nand9.txt', 'done\\\\nor1.txt', 'done\\\\nor10.txt', 'done\\\\nor11.txt', 'done\\\\nor12.txt', 'done\\\\nor13.txt', 'done\\\\nor14.txt', 'done\\\\nor15.txt', 'done\\\\nor16.txt', 'done\\\\nor17.txt', 'done\\\\nor2.txt', 'done\\\\nor3.txt', 'done\\\\nor4.txt', 'done\\\\nor6.txt', 'done\\\\nor7.txt', 'done\\\\nor8.txt', 'done\\\\nor9.txt', 'done\\\\not1.txt', 'done\\\\not10.txt', 'done\\\\not11.txt', 'done\\\\not12.txt', 'done\\\\not13.txt', 'done\\\\not14.txt', 'done\\\\not2.txt', 'done\\\\not3.txt', 'done\\\\not6.txt', 'done\\\\not7.txt', 'done\\\\not9.txt', 'done\\\\or1.txt', 'done\\\\or10.txt', 'done\\\\or11.txt', 'done\\\\or12.txt', 'done\\\\or13.txt', 'done\\\\or14.txt', 'done\\\\or15.txt', 'done\\\\or16.txt', 'done\\\\or17.txt', 'done\\\\or18.txt', 'done\\\\or19.txt', 'done\\\\or2.txt', 'done\\\\or20.txt', 'done\\\\or21.txt', 'done\\\\or22.txt', 'done\\\\or23.txt', 'done\\\\or24.txt', 'done\\\\or25.txt', 'done\\\\or26.txt', 'done\\\\or28.txt', 'done\\\\or4.txt', 'done\\\\or7.txt', 'done\\\\or8.txt', 'done\\\\or9.txt', 'done\\\\pe1.txt', 'done\\\\pe14.txt', 'done\\\\pe15.txt', 'done\\\\pe16.txt', 'done\\\\pe17.txt', 'done\\\\pe18.txt', 'done\\\\pe19.txt', 'done\\\\pe2.txt', 'done\\\\pe20.txt', 'done\\\\pe21.txt', 'done\\\\pe22.txt', 'done\\\\pe3.txt', 'done\\\\pe4.txt', 'done\\\\pe5.txt', 'done\\\\pe6.txt', 'done\\\\pe7.txt', 'done\\\\sub1.txt', 'done\\\\sub10.txt', 'done\\\\sub11.txt', 'done\\\\sub12.txt', 'done\\\\sub2.txt', 'done\\\\sub5.txt', 'done\\\\sub7.txt', 'done\\\\sub8.txt', 'done\\\\sub9.txt', 'done\\\\xnor1.txt', 'done\\\\xnor10.txt', 'done\\\\xnor11.txt', 'done\\\\xnor12.txt', 'done\\\\xnor13.txt', 'done\\\\xnor14.txt', 'done\\\\xnor15.txt', 'done\\\\xnor16.txt', 'done\\\\xnor17.txt', 'done\\\\xnor18.txt', 'done\\\\xnor19.txt', 'done\\\\xnor2.txt', 'done\\\\xnor20.txt', 'done\\\\xnor21.txt', 'done\\\\xnor22.txt', 'done\\\\xnor23.txt', 'done\\\\xnor24.txt', 'done\\\\xnor25.txt', 'done\\\\xnor4.txt', 'done\\\\xnor6.txt', 'done\\\\xnor7.txt', 'done\\\\xnor8.txt', 'done\\\\xnor9.txt', 'done\\\\xor1.txt', 'done\\\\xor10.txt', 'done\\\\xor12.txt', 'done\\\\xor13.txt', 'done\\\\xor14.txt', 'done\\\\xor15.txt', 'done\\\\xor16.txt', 'done\\\\xor17.txt', 'done\\\\xor18.txt', 'done\\\\xor19.txt', 'done\\\\xor2.txt', 'done\\\\xor20.txt', 'done\\\\xor21.txt', 'done\\\\xor22.txt', 'done\\\\xor23.txt', 'done\\\\xor24.txt', 'done\\\\xor25.txt', 'done\\\\xor26.txt', 'done\\\\xor3.txt', 'done\\\\xor6.txt', 'done\\\\xor7.txt', 'done\\\\xor8.txt', 'done\\\\xor9.txt']\n"
     ]
    }
   ],
   "source": [
    "def get_file_names(folder_path):\n",
    "    file_names_with_path = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if os.path.isfile(os.path.join(folder_path, filename)):\n",
    "            file_names_with_path.append(os.path.join(folder_path, filename))\n",
    "    return file_names_with_path\n",
    "\n",
    "# Example usage:\n",
    "folder_path = 'done'\n",
    "verilog_files = get_file_names(folder_path)\n",
    "print(verilog_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# # Shuffle the dataset in-place\n",
    "# random.shuffle(verilog_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracting_attributes(verilog_file):\n",
    "    try:\n",
    "        if os.path.isfile(verilog_file):\n",
    "            with open(verilog_file, \"r\") as file:\n",
    "                loaded_data = json.load(file)\n",
    "                nodes = loaded_data[0]\n",
    "                edges = loaded_data[1]\n",
    "                # edge_atr = loaded_data[2]\n",
    "                label = loaded_data[3]\n",
    "                \n",
    "                x = torch.tensor(nodes, dtype=torch.float)\n",
    "                edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "                # edge_atr = torch.tensor(edge_atr, dtype=torch.long)\n",
    "                y = torch.tensor(label, dtype=torch.float)\n",
    "                num_nodes = x.size(0)\n",
    "                # print(num_nodes)\n",
    "                \n",
    "                # Create batch assignment vector (assuming one graph per file)\n",
    "                batch = torch.zeros(num_nodes, dtype=torch.long)\n",
    "                # data = Data(x=x, edge_index=edge_index, edge_attr=edge_atr ,y = y, batch = batch)\n",
    "                data = Data(x=x, edge_index=edge_index, y = y, batch = batch)\n",
    "                return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return e\n",
    "\n",
    "# temp=extracting_attributes(\"./done/adder6.txt\")\n",
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 306 Verilog files.\n",
      "306\n"
     ]
    }
   ],
   "source": [
    "class VerilogDataset(Dataset):  # Using Dataset from torch_geometric\n",
    "    def __init__(self, verilog_files):\n",
    "        print(f\"Loaded {len(verilog_files)} Verilog files.\")\n",
    "        self.verilog_files = verilog_files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.verilog_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        verilog_file = self.verilog_files[idx]\n",
    "        data = extracting_attributes(verilog_file)\n",
    "        return data\n",
    "\n",
    "dataset = VerilogDataset(verilog_files)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[165, 17], edge_index=[2, 208], y=[1, 16], batch=[165])\n",
      "done\\adder11.txt\n",
      "done\\adder11.txt\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])\n",
    "print(verilog_files[0])\n",
    "print(dataset.verilog_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data objects are unique.\n"
     ]
    }
   ],
   "source": [
    "def are_all_data_objects_unique(dataset):\n",
    "    data_objects = []\n",
    "    for data in dataset:\n",
    "        if data in data_objects:\n",
    "            return False\n",
    "        data_objects.append(data)\n",
    "    return True\n",
    "\n",
    "# Example usage:\n",
    "is_unique = are_all_data_objects_unique(dataset)\n",
    "if is_unique:\n",
    "    print(\"All data objects are unique.\")\n",
    "else:\n",
    "    print(\"Duplicate data objects found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done\\\\comparator20.txt'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = random.randint(0, len(verilog_files))\n",
    "verilog_files[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = dataset[num]\n",
    "data\n",
    "\n",
    "g = nx.Graph()\n",
    "g.add_nodes_from(range(data.num_nodes))\n",
    "edges = data.edge_index.t().tolist()\n",
    "# edge_attrs = {tuple(edge): attr.item() for edge, attr in zip(edges, data.edge_attr)}\n",
    "g.add_edges_from(edges)\n",
    "print(len(edges))\n",
    "\n",
    "# Draw the graph with edge attributes\n",
    "pos = nx.spring_layout(g)  # positions for all nodes\n",
    "nx.draw(g, pos, with_labels=True, node_color='skyblue', node_size=1500, edge_color='k', linewidths=1, font_size=15)\n",
    "nx.draw_networkx_edge_labels(g, pos, font_color='red', font_size=12)  # Add edge labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_num_nodes: 3\n",
      "max_num_nodes: 165\n",
      "mean_num_nodes: 14.683006535947712\n",
      "min_num_edges: 2\n",
      "max_num_edges: 208\n",
      "mean_num_edges: 17.915032679738562\n",
      "mean nodes degree: 1.2201201869574896\n"
     ]
    }
   ],
   "source": [
    "def graph_stat(dataset):\n",
    "    \"\"\"\n",
    "    TODO: calculate the statistics of the ENZYMES dataset.\n",
    "    \n",
    "    Outputs:\n",
    "        min_num_nodes: min number of nodes\n",
    "        max_num_nodes: max number of nodes\n",
    "        mean_num_nodes: average number of nodes\n",
    "        min_num_edges: min number of edges\n",
    "        max_num_edges: max number of edges\n",
    "        mean_num_edges: average number of edges\n",
    "    \"\"\"\n",
    "    # for ind,data in enumerate(dataset):\n",
    "        # print(verilog_files[ind])\n",
    "        # print(data)\n",
    "        # print(len(data.x[1]))\n",
    "        \n",
    "    nodes_edges = [(data.num_nodes, data.num_edges) for data in dataset]\n",
    "    num_nodes, num_edges = list(list(zip(*nodes_edges))[0]), list(list(zip(*nodes_edges))[1])\n",
    "    min_num_nodes = min(num_nodes)\n",
    "    max_num_nodes = max(num_nodes)\n",
    "    mean_num_nodes = np.mean(num_nodes)\n",
    "    min_num_edges = min(num_edges)\n",
    "    max_num_edges = max(num_edges)\n",
    "    mean_num_edges = np.mean(num_edges)\n",
    "    mean_degree = (mean_num_edges)/mean_num_nodes\n",
    "    \n",
    "    print(f\"min_num_nodes: {min_num_nodes}\")\n",
    "    print(f\"max_num_nodes: {max_num_nodes}\")\n",
    "    print(f\"mean_num_nodes: {mean_num_nodes}\")\n",
    "    print(f\"min_num_edges: {min_num_edges}\")\n",
    "    print(f\"max_num_edges: {max_num_edges}\")\n",
    "    print(f\"mean_num_edges: {mean_num_edges}\")\n",
    "    print(f\"mean nodes degree: {mean_degree}\")\n",
    "\n",
    "graph_stat(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    if isinstance(batch[0], Data):\n",
    "        return batch\n",
    "    else:\n",
    "        return default_collate(batch)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import random_split\n",
    "\n",
    "# # Define the sizes of training, validation, and test sets\n",
    "# train_size = int(0.7 * len(dataset))  # 70% of the data for training\n",
    "# val_size = int(0.15 * len(dataset))   # 15% of the data for validation\n",
    "# test_size = len(dataset) - train_size - val_size  # Remaining data for testing\n",
    "\n",
    "# # Split the dataset into training, validation, and test sets\n",
    "# train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# # Create DataLoader for each set\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "\n",
    "# Define the size of the training set (e.g., 70% of the data)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "\n",
    "# Calculate the size of the testing set\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoader for each set\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=custom_collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=custom_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[29, 17], edge_index=[2, 50], y=[1, 16], batch=[29])\n"
     ]
    }
   ],
   "source": [
    "# len(train_loader.dataset)\n",
    "print(train_loader.dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_iter = iter(train_loader)\n",
    "batch = next(loader_iter)\n",
    "# print(batch)\n",
    "# print(batch.num_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConv(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNConv, self).__init__()\n",
    "        self.theta = nn.Parameter(torch.FloatTensor(in_channels, out_channels))\n",
    "        # Initialize the parameters.\n",
    "        stdv = 1. / math.sqrt(out_channels)\n",
    "        self.theta.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "            1. Generate the adjacency matrix with self-loop \\hat{A} using edge_index.\n",
    "            2. Calculate the diagonal degree matrix \\hat{D}.\n",
    "            3. Calculate the output X' with torch.mm using the equation above.\n",
    "        \"\"\"\n",
    "\n",
    "        num_nodes = x.shape[0]\n",
    "        A = torch.sparse_coo_tensor(edge_index, torch.ones(edge_index.shape[1]), (num_nodes, num_nodes))\n",
    "        A = A.to_dense()\n",
    "        A_hat = A + torch.eye(num_nodes)\n",
    "        \n",
    "        A_sum = torch.sum(A_hat, dim=1)\n",
    "        D = torch.pow(A_sum, -0.5)\n",
    "        D[D == float('inf')] = 0.0\n",
    "        D_hat_sqrt = torch.diag(D)\n",
    "        \n",
    "        first = torch.mm(torch.mm(D_hat_sqrt, A_hat), D_hat_sqrt)\n",
    "        second = torch.mm(x, self.theta)\n",
    "        \n",
    "        ret = torch.mm(first, second)\n",
    "        \n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (gcn1): GCNConv()\n",
       "  (a1): ReLU()\n",
       "  (gcn2): GCNConv()\n",
       "  (a2): ReLU()\n",
       "  (gcn3): GCNConv()\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (linear): Linear(in_features=128, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from torch_geometric.nn import GCNConv\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "            1. Define the first convolution layer using `GCNConv()`. Set `out_channels` to 64;\n",
    "            2. Define the first activation layer using `nn.ReLU()`;\n",
    "            3. Define the second convolution layer using `GCNConv()`. Set `out_channels` to 64;\n",
    "            4. Define the second activation layer using `nn.ReLU()`;\n",
    "            5. Define the third convolution layer using `GCNConv()`. Set `out_channels` to 64;\n",
    "            6. Define the dropout layer using `nn.Dropout()`;\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        num_node_features = 17\n",
    "        num_output_classes = 16\n",
    "        \n",
    "        # num_channels = 32\n",
    "        \n",
    "        self.gcn1 = GCNConv(in_channels=num_node_features, out_channels=128)\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.gcn2 = GCNConv(in_channels= 128, out_channels=128)\n",
    "        self.a2 = nn.ReLU()\n",
    "        self.gcn3 = GCNConv(in_channels=128, out_channels=128)\n",
    "        # self.a3 = nn.ReLU()\n",
    "        # self.gcn4 = GCNConv(in_channels=128, out_channels=128)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.linear = nn.Linear(in_features=128, out_features=num_output_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "    \n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = self.a1(x)\n",
    "        x = self.gcn2(x, edge_index)\n",
    "        x = self.a2(x)\n",
    "        x = self.gcn3(x, edge_index)\n",
    "        # x = self.a3(x)\n",
    "        # x = self.gcn4(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        probs = torch.nn.functional.softmax(x, dim=-1)\n",
    "        \n",
    "        return probs\n",
    "        \n",
    "        \n",
    "        \n",
    "GCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.1916, Test Acc: 0.0652\n",
      "Epoch: 002, Train Acc: 0.2336, Test Acc: 0.1196\n",
      "Epoch: 003, Train Acc: 0.2944, Test Acc: 0.1848\n",
      "Epoch: 004, Train Acc: 0.4112, Test Acc: 0.2717\n",
      "Epoch: 005, Train Acc: 0.4065, Test Acc: 0.2391\n",
      "Epoch: 006, Train Acc: 0.3879, Test Acc: 0.2391\n",
      "Epoch: 007, Train Acc: 0.4299, Test Acc: 0.2717\n",
      "Epoch: 008, Train Acc: 0.4346, Test Acc: 0.2609\n",
      "Epoch: 009, Train Acc: 0.4393, Test Acc: 0.3152\n",
      "Epoch: 010, Train Acc: 0.4439, Test Acc: 0.2826\n",
      "Epoch: 011, Train Acc: 0.4626, Test Acc: 0.2826\n",
      "Epoch: 012, Train Acc: 0.4813, Test Acc: 0.2826\n",
      "Epoch: 013, Train Acc: 0.4813, Test Acc: 0.3152\n",
      "Epoch: 014, Train Acc: 0.4907, Test Acc: 0.3152\n",
      "Epoch: 015, Train Acc: 0.4766, Test Acc: 0.3261\n",
      "Epoch: 016, Train Acc: 0.5000, Test Acc: 0.2935\n",
      "Epoch: 017, Train Acc: 0.5093, Test Acc: 0.3370\n",
      "Epoch: 018, Train Acc: 0.5093, Test Acc: 0.3370\n",
      "Epoch: 019, Train Acc: 0.5047, Test Acc: 0.3261\n",
      "Epoch: 020, Train Acc: 0.5047, Test Acc: 0.3370\n",
      "Epoch: 021, Train Acc: 0.5187, Test Acc: 0.3478\n",
      "Epoch: 022, Train Acc: 0.4953, Test Acc: 0.2826\n",
      "Epoch: 023, Train Acc: 0.4953, Test Acc: 0.2935\n",
      "Epoch: 024, Train Acc: 0.4953, Test Acc: 0.2935\n",
      "Epoch: 025, Train Acc: 0.5000, Test Acc: 0.3152\n",
      "Epoch: 026, Train Acc: 0.4813, Test Acc: 0.2826\n",
      "Epoch: 027, Train Acc: 0.4953, Test Acc: 0.3261\n",
      "Epoch: 028, Train Acc: 0.4953, Test Acc: 0.2717\n",
      "Epoch: 029, Train Acc: 0.4953, Test Acc: 0.2717\n",
      "Epoch: 030, Train Acc: 0.5000, Test Acc: 0.2826\n",
      "Epoch: 031, Train Acc: 0.4907, Test Acc: 0.2935\n",
      "Epoch: 032, Train Acc: 0.5000, Test Acc: 0.3261\n",
      "Epoch: 033, Train Acc: 0.4860, Test Acc: 0.2826\n",
      "Epoch: 034, Train Acc: 0.5047, Test Acc: 0.2935\n",
      "Epoch: 035, Train Acc: 0.4953, Test Acc: 0.2935\n",
      "Epoch: 036, Train Acc: 0.5000, Test Acc: 0.2826\n",
      "Epoch: 037, Train Acc: 0.4953, Test Acc: 0.2826\n",
      "Epoch: 038, Train Acc: 0.5000, Test Acc: 0.2609\n",
      "Epoch: 039, Train Acc: 0.5047, Test Acc: 0.2826\n",
      "Epoch: 040, Train Acc: 0.5280, Test Acc: 0.3152\n",
      "Epoch: 041, Train Acc: 0.5093, Test Acc: 0.3261\n",
      "Epoch: 042, Train Acc: 0.5187, Test Acc: 0.3261\n",
      "Epoch: 043, Train Acc: 0.5140, Test Acc: 0.2935\n",
      "Epoch: 044, Train Acc: 0.5093, Test Acc: 0.2935\n",
      "Epoch: 045, Train Acc: 0.5187, Test Acc: 0.3370\n",
      "Epoch: 046, Train Acc: 0.5234, Test Acc: 0.3370\n",
      "Epoch: 047, Train Acc: 0.5140, Test Acc: 0.3043\n",
      "Epoch: 048, Train Acc: 0.5000, Test Acc: 0.3152\n",
      "Epoch: 049, Train Acc: 0.5140, Test Acc: 0.3043\n",
      "Epoch: 050, Train Acc: 0.5047, Test Acc: 0.3152\n",
      "Epoch: 051, Train Acc: 0.5047, Test Acc: 0.2935\n",
      "Epoch: 052, Train Acc: 0.5280, Test Acc: 0.2609\n",
      "Epoch: 053, Train Acc: 0.5234, Test Acc: 0.3587\n",
      "Epoch: 054, Train Acc: 0.5514, Test Acc: 0.3478\n",
      "Epoch: 055, Train Acc: 0.5561, Test Acc: 0.3152\n",
      "Epoch: 056, Train Acc: 0.5561, Test Acc: 0.3913\n",
      "Epoch: 057, Train Acc: 0.5701, Test Acc: 0.4130\n",
      "Epoch: 058, Train Acc: 0.5654, Test Acc: 0.3696\n",
      "Epoch: 059, Train Acc: 0.5561, Test Acc: 0.3152\n",
      "Epoch: 060, Train Acc: 0.5794, Test Acc: 0.3804\n",
      "Epoch: 061, Train Acc: 0.5654, Test Acc: 0.3587\n",
      "Epoch: 062, Train Acc: 0.5327, Test Acc: 0.3587\n",
      "Epoch: 063, Train Acc: 0.5514, Test Acc: 0.3261\n",
      "Epoch: 064, Train Acc: 0.5421, Test Acc: 0.3587\n",
      "Epoch: 065, Train Acc: 0.5421, Test Acc: 0.3696\n",
      "Epoch: 066, Train Acc: 0.5514, Test Acc: 0.3587\n",
      "Epoch: 067, Train Acc: 0.5421, Test Acc: 0.3478\n",
      "Epoch: 068, Train Acc: 0.5374, Test Acc: 0.3152\n",
      "Epoch: 069, Train Acc: 0.5421, Test Acc: 0.3587\n",
      "Epoch: 070, Train Acc: 0.5280, Test Acc: 0.3478\n",
      "Epoch: 071, Train Acc: 0.5421, Test Acc: 0.3478\n",
      "Epoch: 072, Train Acc: 0.5701, Test Acc: 0.4022\n",
      "Epoch: 073, Train Acc: 0.5701, Test Acc: 0.4022\n",
      "Epoch: 074, Train Acc: 0.5000, Test Acc: 0.4022\n",
      "Epoch: 075, Train Acc: 0.5000, Test Acc: 0.4239\n",
      "Epoch: 076, Train Acc: 0.5234, Test Acc: 0.4348\n",
      "Epoch: 077, Train Acc: 0.5234, Test Acc: 0.4565\n",
      "Epoch: 078, Train Acc: 0.5187, Test Acc: 0.4239\n",
      "Epoch: 079, Train Acc: 0.5047, Test Acc: 0.4457\n",
      "Epoch: 080, Train Acc: 0.4907, Test Acc: 0.4891\n",
      "Epoch: 081, Train Acc: 0.5140, Test Acc: 0.4348\n",
      "Epoch: 082, Train Acc: 0.5234, Test Acc: 0.4130\n",
      "Epoch: 083, Train Acc: 0.5327, Test Acc: 0.4457\n",
      "Epoch: 084, Train Acc: 0.5234, Test Acc: 0.4130\n",
      "Epoch: 085, Train Acc: 0.5280, Test Acc: 0.4348\n",
      "Epoch: 086, Train Acc: 0.5421, Test Acc: 0.4239\n",
      "Epoch: 087, Train Acc: 0.5561, Test Acc: 0.4674\n",
      "Epoch: 088, Train Acc: 0.5514, Test Acc: 0.4674\n",
      "Epoch: 089, Train Acc: 0.5234, Test Acc: 0.4239\n",
      "Epoch: 090, Train Acc: 0.5514, Test Acc: 0.4891\n",
      "Epoch: 091, Train Acc: 0.5514, Test Acc: 0.4674\n",
      "Epoch: 092, Train Acc: 0.5654, Test Acc: 0.4674\n",
      "Epoch: 093, Train Acc: 0.5187, Test Acc: 0.3696\n",
      "Epoch: 094, Train Acc: 0.5841, Test Acc: 0.4348\n",
      "Epoch: 095, Train Acc: 0.5467, Test Acc: 0.4457\n",
      "Epoch: 096, Train Acc: 0.5748, Test Acc: 0.4348\n",
      "Epoch: 097, Train Acc: 0.5935, Test Acc: 0.4783\n",
      "Epoch: 098, Train Acc: 0.5888, Test Acc: 0.5217\n",
      "Epoch: 099, Train Acc: 0.5794, Test Acc: 0.4891\n",
      "Epoch: 100, Train Acc: 0.5888, Test Acc: 0.5109\n",
      "Training duration: 262.17353439331055 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gcn = GCN()\n",
    "gcn = gcn.to(device)\n",
    "# print(gcn.parameters())\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(gcn.parameters(), lr=0.001)\n",
    "# loss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "out_labels = []\n",
    "\n",
    "# training_running_loss = 0.0\n",
    "\n",
    "def train(train_loader):\n",
    "    \n",
    "    gcn.train()\n",
    "    # print(gcn.parameters())\n",
    "    for batch_data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        for data in batch_data:\n",
    "            data = data.to(device)\n",
    "            #forward pass\n",
    "            out = gcn(data.x, data.edge_index, data.batch)\n",
    "            # calculate the loss\n",
    "            loss = criterion(out, data.y)\n",
    "            # zero the gradients of the weights so that the gradients are not accumulated\n",
    "            optimizer.zero_grad()\n",
    "            # calculate the gradients using backpropagation\n",
    "            loss.backward()\n",
    "            # update the weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # calculate the loss\n",
    "            # training_running_loss += loss.detach().item()\n",
    "            \n",
    "            out_labels.append((out, data.y))\n",
    "        \n",
    "        \n",
    "\n",
    "testing_labels = []\n",
    "def test(loader):\n",
    "    gcn.eval()\n",
    "    correct = 0\n",
    "    for batch_data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        for data in batch_data:\n",
    "            out = gcn(data.x, data.edge_index, data.batch)  \n",
    "            pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "            testing_labels.append(pred)\n",
    "            y_label = (data.y.tolist())\n",
    "            y_label = y_label[0].index(1.0)\n",
    "            pred_label = (pred.tolist())[0]\n",
    "            # print(pred_label)\n",
    "            # print(y_label)\n",
    "            if y_label == pred_label:\n",
    "                correct += 1            \n",
    "            # correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "num_epochs = 100\n",
    "# Your training code here\n",
    "for epoch in range(num_epochs):\n",
    "    train(train_loader)\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch + 1:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the duration\n",
    "duration = end_time - start_time\n",
    "print(\"Training duration:\", duration, \"seconds\")\n",
    "# with open(\"out_labels.txt\", \"w\") as output:\n",
    "#         output.write(str(out_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5108695652173914"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gcn.state_dict(), 'gcn_model58-51-0001-100.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\\comparator16.txt\n",
      "tensor([6])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "num = random.randint(0, len(verilog_files))\n",
    "print(verilog_files[num])\n",
    "data_trial = dataset[num]\n",
    "\n",
    "\n",
    "out = gcn(data_trial.x, data_trial.edge_index, data_trial.batch)\n",
    "pred = out.argmax(dim=1)\n",
    "print(pred)\n",
    "print((data_trial.y.tolist())[0].index(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[0.1118, 0.1097, 0.1018, 0.1003, 0.1178, 0.1129, 0.1081, 0.1210, 0.1167]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1059, 0.1114, 0.1021, 0.0979, 0.1187, 0.1096, 0.1097, 0.1217, 0.1228]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1078, 0.1124, 0.1022, 0.1001, 0.1166, 0.1129, 0.1110, 0.1191, 0.1179]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1095, 0.1032, 0.0960, 0.0981, 0.1257, 0.1091, 0.1091, 0.1260, 0.1233]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1096, 0.1091, 0.1006, 0.1017, 0.1147, 0.1134, 0.1094, 0.1264, 0.1150]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1065, 0.1128, 0.0992, 0.1019, 0.1142, 0.1175, 0.1083, 0.1225, 0.1171]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1139, 0.1077, 0.0977, 0.0989, 0.1158, 0.1183, 0.1071, 0.1264, 0.1142]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1071, 0.1127, 0.0988, 0.0998, 0.1145, 0.1159, 0.1104, 0.1251, 0.1158]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1081, 0.1133, 0.1001, 0.0981, 0.1155, 0.1141, 0.1137, 0.1236, 0.1135]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1088, 0.1155, 0.0976, 0.0986, 0.1130, 0.1117, 0.1142, 0.1264, 0.1141]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1208, 0.1097, 0.0887, 0.0928, 0.1110, 0.1075, 0.1250, 0.1413, 0.1031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1085, 0.1138, 0.0930, 0.0979, 0.1097, 0.1154, 0.1200, 0.1291, 0.1126]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1081, 0.1128, 0.0957, 0.0979, 0.1128, 0.1196, 0.1140, 0.1266, 0.1124]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1090, 0.1068, 0.0943, 0.0958, 0.1132, 0.1194, 0.1234, 0.1300, 0.1082]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1004, 0.1046, 0.0898, 0.0919, 0.1132, 0.1343, 0.1389, 0.1294, 0.0975]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1079, 0.1126, 0.0969, 0.1008, 0.1130, 0.1213, 0.1146, 0.1225, 0.1105]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1040, 0.1074, 0.0939, 0.0977, 0.1184, 0.1195, 0.1201, 0.1306, 0.1084]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1021, 0.1103, 0.1021, 0.1021, 0.1165, 0.1199, 0.1178, 0.1211, 0.1080]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1002, 0.0999, 0.0859, 0.1045, 0.1209, 0.1353, 0.1212, 0.1336, 0.0984]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1004, 0.1164, 0.0946, 0.0977, 0.1220, 0.1182, 0.1215, 0.1242, 0.1049]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1010, 0.1056, 0.0961, 0.0998, 0.1263, 0.1173, 0.1179, 0.1289, 0.1071]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.1034, 0.1058, 0.0977, 0.1001, 0.1193, 0.1232, 0.1170, 0.1245, 0.1091]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1033, 0.1066, 0.0917, 0.0978, 0.1267, 0.1307, 0.1195, 0.1241, 0.0995]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0995, 0.1101, 0.1022, 0.1006, 0.1219, 0.1193, 0.1169, 0.1203, 0.1091]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0970, 0.0955, 0.0993, 0.1000, 0.1293, 0.1240, 0.1209, 0.1316, 0.1024]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0919, 0.1066, 0.1006, 0.1029, 0.1235, 0.1216, 0.1224, 0.1208, 0.1096]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0944, 0.1025, 0.0988, 0.1020, 0.1265, 0.1249, 0.1308, 0.1184, 0.1018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0939, 0.1065, 0.1001, 0.1006, 0.1239, 0.1316, 0.1233, 0.1226, 0.0977]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1071, 0.1068, 0.0978, 0.1007, 0.1220, 0.1242, 0.1130, 0.1208, 0.1075]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1054, 0.1044, 0.1000, 0.1063, 0.1206, 0.1223, 0.1200, 0.1145, 0.1065]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0974, 0.1064, 0.1047, 0.1030, 0.1266, 0.1324, 0.1208, 0.1124, 0.0964]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0944, 0.1041, 0.1022, 0.0993, 0.1326, 0.1246, 0.1262, 0.1162, 0.1004]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0994, 0.1075, 0.1058, 0.1002, 0.1237, 0.1211, 0.1149, 0.1195, 0.1079]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0977, 0.0997, 0.1061, 0.0960, 0.1364, 0.1253, 0.1237, 0.1167, 0.0984]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0930, 0.1051, 0.1022, 0.0985, 0.1289, 0.1288, 0.1202, 0.1214, 0.1020]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0978, 0.1062, 0.1025, 0.0984, 0.1281, 0.1220, 0.1145, 0.1218, 0.1087]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0997, 0.1020, 0.1038, 0.1034, 0.1270, 0.1244, 0.1114, 0.1260, 0.1022]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0759, 0.0706, 0.1188, 0.1135, 0.1482, 0.1511, 0.1388, 0.1186, 0.0643]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0805, 0.0973, 0.1074, 0.0960, 0.1498, 0.1348, 0.1199, 0.1220, 0.0925]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0894, 0.0933, 0.1086, 0.1078, 0.1390, 0.1399, 0.1188, 0.1172, 0.0860]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0858, 0.1033, 0.1062, 0.1049, 0.1399, 0.1306, 0.1281, 0.1101, 0.0910]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0884, 0.0970, 0.1113, 0.1019, 0.1403, 0.1238, 0.1221, 0.1135, 0.1018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0979, 0.1051, 0.1036, 0.1089, 0.1342, 0.1239, 0.1208, 0.1134, 0.0922]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0926, 0.1024, 0.1066, 0.0980, 0.1387, 0.1230, 0.1176, 0.1191, 0.1021]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0728, 0.0866, 0.1092, 0.1093, 0.1527, 0.1318, 0.1412, 0.1135, 0.0829]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0647, 0.0729, 0.1220, 0.1259, 0.1680, 0.1497, 0.1247, 0.1015, 0.0706]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0875, 0.0965, 0.1112, 0.1158, 0.1427, 0.1351, 0.1272, 0.1067, 0.0772]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0951, 0.1059, 0.1139, 0.1059, 0.1449, 0.1223, 0.1218, 0.1043, 0.0860]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0815, 0.0841, 0.1227, 0.1163, 0.1655, 0.1343, 0.1398, 0.0931, 0.0628]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0928, 0.0950, 0.1144, 0.1094, 0.1429, 0.1284, 0.1221, 0.1065, 0.0884]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0831, 0.0934, 0.1097, 0.1119, 0.1585, 0.1274, 0.1259, 0.1127, 0.0774]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0792, 0.0763, 0.1274, 0.1077, 0.1611, 0.1331, 0.1588, 0.0936, 0.0628]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0915, 0.0899, 0.1135, 0.1170, 0.1493, 0.1277, 0.1354, 0.1039, 0.0718]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0563, 0.0535, 0.1198, 0.1389, 0.2035, 0.1588, 0.1424, 0.0878, 0.0389]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0815, 0.0586, 0.1195, 0.1449, 0.1896, 0.1302, 0.1423, 0.0831, 0.0502]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0813, 0.0809, 0.1272, 0.1156, 0.1574, 0.1325, 0.1383, 0.0939, 0.0729]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0705, 0.0663, 0.1214, 0.1423, 0.1719, 0.1237, 0.1695, 0.0827, 0.0517]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0589, 0.0549, 0.1517, 0.1126, 0.2043, 0.1377, 0.1818, 0.0606, 0.0376]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0811, 0.0663, 0.1082, 0.1254, 0.1625, 0.1573, 0.1661, 0.0928, 0.0404]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0783, 0.0715, 0.1137, 0.1247, 0.1709, 0.1421, 0.1617, 0.0913, 0.0457]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0697, 0.0553, 0.1361, 0.1254, 0.1759, 0.1472, 0.1726, 0.0755, 0.0423]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0853, 0.0426, 0.1335, 0.1308, 0.1678, 0.1615, 0.1717, 0.0825, 0.0242]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0614, 0.0519, 0.1104, 0.1750, 0.1683, 0.1925, 0.1534, 0.0631, 0.0240]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1032, 0.0836, 0.1148, 0.1244, 0.1465, 0.1387, 0.1373, 0.0882, 0.0632]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0904, 0.0638, 0.1120, 0.1380, 0.1465, 0.1600, 0.1571, 0.0868, 0.0454]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0745, 0.0717, 0.1204, 0.1380, 0.1804, 0.1574, 0.1557, 0.0687, 0.0331]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1000, 0.0819, 0.1204, 0.1079, 0.1708, 0.1505, 0.1268, 0.0843, 0.0574]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0896, 0.0675, 0.0923, 0.1379, 0.1691, 0.1610, 0.1472, 0.0805, 0.0549]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0941, 0.0767, 0.1136, 0.1291, 0.1560, 0.1427, 0.1536, 0.0851, 0.0491]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1035, 0.0598, 0.1109, 0.1437, 0.1532, 0.1655, 0.1315, 0.0876, 0.0443]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1138, 0.0710, 0.1010, 0.1349, 0.1380, 0.1734, 0.1204, 0.0932, 0.0543]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0723, 0.0677, 0.1047, 0.1543, 0.1820, 0.1725, 0.1473, 0.0662, 0.0329]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0920, 0.0721, 0.1033, 0.1391, 0.1913, 0.1488, 0.1276, 0.0799, 0.0460]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0911, 0.0236, 0.0775, 0.1725, 0.2374, 0.1754, 0.1570, 0.0548, 0.0108]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0948, 0.0616, 0.1025, 0.1620, 0.1551, 0.1587, 0.1203, 0.0937, 0.0513]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1131, 0.0589, 0.0982, 0.1332, 0.1599, 0.1827, 0.1146, 0.0979, 0.0415]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1069, 0.0462, 0.0937, 0.1657, 0.1639, 0.2076, 0.1072, 0.0775, 0.0313]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1009, 0.0497, 0.1074, 0.1371, 0.1863, 0.1817, 0.1217, 0.0840, 0.0311]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0682, 0.0411, 0.1219, 0.1727, 0.2034, 0.1782, 0.1250, 0.0639, 0.0257]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0885, 0.0495, 0.0845, 0.1705, 0.1931, 0.1843, 0.1153, 0.0839, 0.0305]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.1038, 0.0746, 0.1087, 0.1283, 0.1511, 0.1504, 0.1203, 0.0989, 0.0639]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0852, 0.0559, 0.0919, 0.1503, 0.1910, 0.1766, 0.1086, 0.0968, 0.0437]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1053, 0.0359, 0.0689, 0.2009, 0.2021, 0.2345, 0.0873, 0.0494, 0.0155]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0795, 0.0441, 0.0872, 0.1911, 0.1805, 0.1851, 0.1112, 0.0889, 0.0324]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0901, 0.0695, 0.0852, 0.1489, 0.1709, 0.1846, 0.0929, 0.1001, 0.0578]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0856, 0.0244, 0.0965, 0.1702, 0.2351, 0.2120, 0.0942, 0.0644, 0.0176]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0761, 0.0217, 0.0599, 0.3122, 0.2130, 0.1706, 0.0799, 0.0586, 0.0080]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0545, 0.0231, 0.0607, 0.2487, 0.2486, 0.2047, 0.0734, 0.0669, 0.0194]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0612, 0.0321, 0.0870, 0.1591, 0.2246, 0.2194, 0.0769, 0.1135, 0.0261]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0670, 0.0212, 0.0717, 0.2029, 0.2131, 0.2993, 0.0538, 0.0570, 0.0140]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0848, 0.0477, 0.0873, 0.1673, 0.1955, 0.1916, 0.0871, 0.0989, 0.0398]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0552, 0.0231, 0.0744, 0.1699, 0.3081, 0.2381, 0.0571, 0.0576, 0.0164]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0667, 0.0203, 0.0638, 0.2149, 0.2519, 0.2103, 0.0959, 0.0605, 0.0157]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0118, 0.0008, 0.0140, 0.2004, 0.5902, 0.1593, 0.0165, 0.0063, 0.0007]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0784, 0.0326, 0.0771, 0.1881, 0.2077, 0.2432, 0.0651, 0.0824, 0.0254]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0925, 0.0382, 0.0890, 0.1561, 0.1929, 0.1952, 0.1025, 0.0890, 0.0445]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0711, 0.0280, 0.0647, 0.1724, 0.2174, 0.2565, 0.0845, 0.0768, 0.0286]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0726, 0.0411, 0.0830, 0.1665, 0.2173, 0.2369, 0.0792, 0.0775, 0.0258]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0625, 0.0222, 0.0515, 0.1902, 0.2606, 0.2716, 0.0626, 0.0612, 0.0177]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0996, 0.0570, 0.0846, 0.1522, 0.1587, 0.1976, 0.0883, 0.1083, 0.0536]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0592, 0.0163, 0.0654, 0.2129, 0.2247, 0.2653, 0.0615, 0.0796, 0.0150]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0523, 0.0157, 0.0510, 0.2885, 0.1464, 0.3217, 0.0478, 0.0639, 0.0128]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0633, 0.0196, 0.0512, 0.2280, 0.1892, 0.3098, 0.0608, 0.0628, 0.0154]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0618, 0.0345, 0.0518, 0.2087, 0.2015, 0.2658, 0.0664, 0.0833, 0.0263]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0723, 0.0394, 0.0723, 0.1980, 0.1643, 0.2491, 0.0818, 0.0826, 0.0402]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0521, 0.0138, 0.0384, 0.2750, 0.1628, 0.3084, 0.0752, 0.0610, 0.0133]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0601, 0.0225, 0.0484, 0.2307, 0.1562, 0.3211, 0.0638, 0.0738, 0.0234]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0773, 0.0448, 0.0561, 0.2191, 0.1630, 0.2269, 0.0956, 0.0860, 0.0311]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0772, 0.0329, 0.0621, 0.2126, 0.1566, 0.2672, 0.0750, 0.0887, 0.0278]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0386, 0.0144, 0.0476, 0.2886, 0.1676, 0.3017, 0.0686, 0.0598, 0.0131]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0658, 0.0307, 0.0504, 0.2885, 0.1422, 0.2786, 0.0624, 0.0619, 0.0195]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0740, 0.0269, 0.0589, 0.2084, 0.1286, 0.2891, 0.0651, 0.1186, 0.0304]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0413, 0.0104, 0.0237, 0.2941, 0.0720, 0.4639, 0.0421, 0.0444, 0.0082]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0376, 0.0122, 0.0444, 0.3157, 0.1440, 0.3306, 0.0552, 0.0511, 0.0093]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0567, 0.0206, 0.0489, 0.2647, 0.1004, 0.3248, 0.0866, 0.0805, 0.0168]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0167, 0.0035, 0.0113, 0.3528, 0.0509, 0.4943, 0.0338, 0.0349, 0.0018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0424, 0.0180, 0.0320, 0.3218, 0.0776, 0.3445, 0.0602, 0.0920, 0.0115]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0423, 0.0183, 0.0389, 0.2447, 0.0965, 0.4033, 0.0743, 0.0709, 0.0107]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0227, 0.0031, 0.0160, 0.4263, 0.0451, 0.3910, 0.0464, 0.0463, 0.0031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0633, 0.0197, 0.0352, 0.2251, 0.0817, 0.4386, 0.0404, 0.0780, 0.0181]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.2967e-03, 3.0514e-04, 2.0014e-03, 1.5553e-01, 7.2512e-03, 8.1690e-01,\n",
       "           9.0341e-03, 6.6130e-03, 6.8204e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0160, 0.0048, 0.0108, 0.2517, 0.0270, 0.6313, 0.0183, 0.0374, 0.0027]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0218, 0.0034, 0.0113, 0.2594, 0.0311, 0.6152, 0.0244, 0.0303, 0.0031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0421, 0.0123, 0.0342, 0.2747, 0.0854, 0.4173, 0.0630, 0.0620, 0.0091]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0105, 0.0009, 0.0044, 0.3423, 0.0098, 0.5994, 0.0120, 0.0200, 0.0006]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0441, 0.0102, 0.0225, 0.2536, 0.0616, 0.4867, 0.0705, 0.0429, 0.0079]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0467, 0.0168, 0.0254, 0.2354, 0.0877, 0.4852, 0.0450, 0.0477, 0.0102]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0857, 0.0320, 0.0451, 0.2063, 0.0737, 0.3835, 0.0722, 0.0753, 0.0263]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0107, 0.0011, 0.0042, 0.1618, 0.0138, 0.7829, 0.0092, 0.0152, 0.0011]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0242, 0.0096, 0.0235, 0.1577, 0.0781, 0.6078, 0.0467, 0.0437, 0.0086]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0210, 0.0051, 0.0193, 0.0960, 0.0370, 0.7492, 0.0304, 0.0382, 0.0038]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0413, 0.0133, 0.0331, 0.1980, 0.0813, 0.5237, 0.0415, 0.0568, 0.0111]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0428, 0.0267, 0.0480, 0.1580, 0.1125, 0.4335, 0.0817, 0.0763, 0.0206]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0555, 0.0151, 0.0317, 0.1643, 0.0679, 0.5386, 0.0625, 0.0497, 0.0146]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0107, 0.0018, 0.0122, 0.1424, 0.0372, 0.7502, 0.0222, 0.0223, 0.0010]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0197, 0.0044, 0.0104, 0.1213, 0.0348, 0.7547, 0.0367, 0.0160, 0.0019]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0420, 0.0072, 0.0246, 0.1530, 0.0494, 0.6289, 0.0403, 0.0496, 0.0049]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0195, 0.0047, 0.0170, 0.1810, 0.0489, 0.6487, 0.0382, 0.0388, 0.0031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0715, 0.0339, 0.0470, 0.1921, 0.0884, 0.3864, 0.0743, 0.0822, 0.0241]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0259, 0.0101, 0.0224, 0.1371, 0.0530, 0.6529, 0.0502, 0.0430, 0.0054]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0673, 0.0236, 0.0417, 0.1817, 0.0845, 0.4283, 0.0647, 0.0840, 0.0242]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0288, 0.0098, 0.0206, 0.1397, 0.0657, 0.6240, 0.0501, 0.0550, 0.0063]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0168, 0.0033, 0.0104, 0.0998, 0.0304, 0.7608, 0.0308, 0.0446, 0.0031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0494, 0.0166, 0.0277, 0.1261, 0.0675, 0.6007, 0.0445, 0.0546, 0.0129]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0538, 0.0188, 0.0332, 0.1528, 0.0581, 0.5535, 0.0438, 0.0731, 0.0128]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0126, 0.0072, 0.0149, 0.1236, 0.0663, 0.6905, 0.0314, 0.0505, 0.0030]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0772, 0.0320, 0.0585, 0.1501, 0.1274, 0.3228, 0.0883, 0.1123, 0.0314]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0253, 0.0074, 0.0192, 0.1550, 0.0760, 0.6231, 0.0337, 0.0557, 0.0046]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0584, 0.0169, 0.0469, 0.1486, 0.0997, 0.4695, 0.0648, 0.0787, 0.0165]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0343, 0.0166, 0.0389, 0.1245, 0.0596, 0.5945, 0.0518, 0.0719, 0.0079]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0442, 0.0201, 0.0515, 0.1662, 0.1167, 0.4086, 0.0670, 0.1088, 0.0168]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0284, 0.0092, 0.0192, 0.1370, 0.0848, 0.6219, 0.0372, 0.0553, 0.0069]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.0060e-03, 4.8164e-05, 8.4278e-04, 3.1442e-02, 7.7538e-03, 9.4764e-01,\n",
       "           2.2061e-03, 9.0409e-03, 2.1262e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0292, 0.0057, 0.0174, 0.1454, 0.0467, 0.6747, 0.0343, 0.0433, 0.0033]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0292, 0.0074, 0.0287, 0.1566, 0.0963, 0.5007, 0.0693, 0.1013, 0.0106]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[3.8636e-04, 1.3970e-05, 2.9851e-04, 2.2131e-02, 5.7988e-03, 9.6613e-01,\n",
       "           1.6749e-03, 3.5520e-03, 1.3233e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0585, 0.0106, 0.0396, 0.2032, 0.0987, 0.4234, 0.0688, 0.0832, 0.0141]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0557, 0.0348, 0.0509, 0.1239, 0.1347, 0.3851, 0.0909, 0.0996, 0.0243]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0310, 0.0089, 0.0298, 0.1151, 0.0745, 0.5905, 0.0539, 0.0883, 0.0080]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0495, 0.0136, 0.0358, 0.1523, 0.0870, 0.5029, 0.0676, 0.0800, 0.0114]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0515, 0.0223, 0.0399, 0.1866, 0.1234, 0.3783, 0.0640, 0.1147, 0.0192]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0326, 0.0062, 0.0224, 0.1481, 0.0588, 0.6024, 0.0428, 0.0809, 0.0059]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0253, 0.0081, 0.0215, 0.1295, 0.0799, 0.5898, 0.0733, 0.0671, 0.0055]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[2.3440e-03, 3.1362e-04, 2.3222e-03, 4.9673e-02, 2.1704e-02, 9.0007e-01,\n",
       "           1.4016e-02, 9.3979e-03, 1.5432e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0295, 0.0074, 0.0268, 0.1803, 0.0807, 0.5572, 0.0526, 0.0592, 0.0063]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0349, 0.0148, 0.0383, 0.1368, 0.1252, 0.4874, 0.0633, 0.0867, 0.0127]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0164, 0.0012, 0.0075, 0.1054, 0.0504, 0.6958, 0.0151, 0.1064, 0.0019]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0215, 0.0070, 0.0232, 0.1430, 0.0970, 0.6010, 0.0468, 0.0557, 0.0047]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0252, 0.0138, 0.0354, 0.1752, 0.1157, 0.4686, 0.0717, 0.0833, 0.0112]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0256, 0.0094, 0.0228, 0.1536, 0.0922, 0.5211, 0.0784, 0.0859, 0.0110]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0114, 0.0046, 0.0171, 0.1237, 0.0899, 0.6408, 0.0432, 0.0641, 0.0052]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0665, 0.0367, 0.0558, 0.1542, 0.0992, 0.3254, 0.0823, 0.1403, 0.0397]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0083, 0.0021, 0.0080, 0.1071, 0.0438, 0.7587, 0.0298, 0.0407, 0.0015]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0395, 0.0159, 0.0461, 0.1422, 0.1251, 0.4356, 0.0660, 0.1136, 0.0159]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0246, 0.0059, 0.0250, 0.0913, 0.0848, 0.6198, 0.0596, 0.0843, 0.0046]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0528, 0.0212, 0.0483, 0.1493, 0.1153, 0.3800, 0.0746, 0.1331, 0.0254]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0244, 0.0054, 0.0199, 0.1647, 0.0671, 0.6103, 0.0545, 0.0493, 0.0044]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0622, 0.0226, 0.0542, 0.1412, 0.1273, 0.3620, 0.0961, 0.1132, 0.0212]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[4.8658e-03, 6.2723e-04, 3.5370e-03, 9.5234e-02, 3.5559e-02, 8.3107e-01,\n",
       "           1.1991e-02, 1.6639e-02, 4.7539e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0176, 0.0030, 0.0097, 0.1679, 0.0614, 0.6604, 0.0213, 0.0564, 0.0023]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0219, 0.0037, 0.0203, 0.1361, 0.0520, 0.6250, 0.0318, 0.1050, 0.0041]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0197, 0.0033, 0.0191, 0.1333, 0.0829, 0.6528, 0.0316, 0.0531, 0.0042]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0469, 0.0105, 0.0333, 0.1662, 0.0899, 0.4705, 0.0736, 0.1010, 0.0082]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0140, 0.0021, 0.0155, 0.1017, 0.0554, 0.7225, 0.0248, 0.0626, 0.0016]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0150, 0.0022, 0.0115, 0.1441, 0.0762, 0.6216, 0.0376, 0.0897, 0.0021]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0363, 0.0088, 0.0223, 0.1311, 0.1092, 0.5040, 0.0627, 0.1125, 0.0133]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0465, 0.0184, 0.0443, 0.1663, 0.1383, 0.3702, 0.0779, 0.1204, 0.0177]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0198, 0.0035, 0.0188, 0.1095, 0.1197, 0.6210, 0.0520, 0.0519, 0.0037]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0275, 0.0026, 0.0152, 0.1316, 0.0583, 0.6620, 0.0383, 0.0619, 0.0026]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0424, 0.0118, 0.0372, 0.1449, 0.1157, 0.4818, 0.0536, 0.1027, 0.0098]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0551, 0.0252, 0.0532, 0.1472, 0.1241, 0.3636, 0.0815, 0.1267, 0.0233]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0511, 0.0178, 0.0482, 0.1235, 0.1455, 0.3787, 0.0712, 0.1371, 0.0268]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0335, 0.0067, 0.0197, 0.1409, 0.1470, 0.4866, 0.0495, 0.1062, 0.0097]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0636, 0.0287, 0.0618, 0.1507, 0.1459, 0.2998, 0.0880, 0.1295, 0.0320]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0170, 0.0022, 0.0111, 0.1742, 0.0790, 0.5901, 0.0387, 0.0858, 0.0019]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0124, 0.0018, 0.0163, 0.1550, 0.1507, 0.5502, 0.0426, 0.0688, 0.0021]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0253, 0.0055, 0.0217, 0.1537, 0.1099, 0.5226, 0.0548, 0.0968, 0.0097]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0456, 0.0119, 0.0347, 0.1358, 0.0990, 0.5300, 0.0655, 0.0685, 0.0089]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0367, 0.0082, 0.0244, 0.1455, 0.1383, 0.4489, 0.0522, 0.1375, 0.0083]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0348, 0.0111, 0.0306, 0.1464, 0.1314, 0.4605, 0.0559, 0.1187, 0.0106]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0597, 0.0170, 0.0427, 0.1495, 0.1268, 0.3506, 0.0848, 0.1519, 0.0169]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0480, 0.0198, 0.0360, 0.1729, 0.1620, 0.3070, 0.1043, 0.1299, 0.0200]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0328, 0.0186, 0.0388, 0.1644, 0.1581, 0.3993, 0.0652, 0.1079, 0.0150]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0194, 0.0013, 0.0097, 0.1074, 0.0689, 0.6829, 0.0350, 0.0735, 0.0020]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0287, 0.0056, 0.0344, 0.1447, 0.1068, 0.4834, 0.0751, 0.1156, 0.0057]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0539, 0.0133, 0.0376, 0.1903, 0.1276, 0.3420, 0.0782, 0.1395, 0.0176]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0709, 0.0380, 0.0698, 0.1660, 0.1431, 0.2367, 0.1171, 0.1203, 0.0382]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0786, 0.0480, 0.0693, 0.1329, 0.1525, 0.2305, 0.1060, 0.1247, 0.0574]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.1453e-04, 3.5857e-06, 1.4002e-04, 2.9182e-02, 1.0359e-02, 9.5206e-01,\n",
       "           1.7240e-03, 6.2075e-03, 4.9101e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0522, 0.0157, 0.0428, 0.2002, 0.1234, 0.3605, 0.0936, 0.0924, 0.0192]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0642, 0.0127, 0.0373, 0.1861, 0.1541, 0.3089, 0.0868, 0.1338, 0.0162]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0422, 0.0078, 0.0226, 0.1987, 0.1281, 0.4440, 0.0717, 0.0790, 0.0060]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0871, 0.0454, 0.0665, 0.1398, 0.1503, 0.2213, 0.1040, 0.1320, 0.0535]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0452, 0.0169, 0.0530, 0.1954, 0.1850, 0.2625, 0.1010, 0.1187, 0.0222]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0648, 0.0239, 0.0601, 0.1556, 0.1555, 0.2735, 0.1081, 0.1325, 0.0261]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0184, 0.0016, 0.0078, 0.2803, 0.1084, 0.4645, 0.0512, 0.0663, 0.0015]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0307, 0.0084, 0.0315, 0.2177, 0.1370, 0.3637, 0.0933, 0.1112, 0.0065]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0484, 0.0202, 0.0409, 0.2243, 0.1178, 0.3321, 0.0908, 0.1061, 0.0193]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0749, 0.0443, 0.0776, 0.1501, 0.1372, 0.2306, 0.1131, 0.1237, 0.0485]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0449, 0.0150, 0.0365, 0.2476, 0.1387, 0.3220, 0.0778, 0.1009, 0.0165]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0594, 0.0181, 0.0502, 0.2369, 0.1422, 0.2327, 0.1003, 0.1389, 0.0214]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.8595e-03, 2.9371e-04, 3.2481e-03, 4.9506e-01, 7.7968e-02, 3.8345e-01,\n",
       "           1.4730e-02, 2.3208e-02, 1.8038e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0600, 0.0186, 0.0454, 0.2229, 0.1327, 0.2922, 0.1099, 0.1021, 0.0161]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0331, 0.0019, 0.0139, 0.3394, 0.0541, 0.4479, 0.0442, 0.0636, 0.0020]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0696, 0.0310, 0.0660, 0.1993, 0.1384, 0.2412, 0.1159, 0.1047, 0.0340]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0268, 0.0033, 0.0176, 0.2968, 0.0719, 0.4533, 0.0566, 0.0708, 0.0031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0868, 0.0319, 0.0816, 0.1807, 0.1281, 0.2245, 0.1037, 0.1210, 0.0418]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0652, 0.0319, 0.0671, 0.1893, 0.1471, 0.2572, 0.1081, 0.1043, 0.0299]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0473, 0.0076, 0.0395, 0.2757, 0.0817, 0.3803, 0.0890, 0.0714, 0.0074]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0609, 0.0134, 0.0432, 0.2169, 0.1124, 0.3579, 0.0850, 0.0923, 0.0180]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0824, 0.0327, 0.0672, 0.1671, 0.1294, 0.2695, 0.1142, 0.1042, 0.0334]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0761, 0.0481, 0.0783, 0.1547, 0.1374, 0.2297, 0.1329, 0.0999, 0.0429]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0734, 0.0231, 0.0655, 0.1663, 0.1173, 0.3025, 0.1101, 0.1151, 0.0268]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[8.8159e-03, 6.0923e-04, 8.4433e-03, 1.9427e-01, 4.0449e-02, 6.8429e-01,\n",
       "           4.1066e-02, 2.1164e-02, 8.9709e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0433, 0.0089, 0.0438, 0.2315, 0.0828, 0.4048, 0.0983, 0.0774, 0.0091]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0800, 0.0199, 0.0583, 0.2072, 0.1138, 0.3215, 0.1040, 0.0750, 0.0203]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0461, 0.0119, 0.0484, 0.2744, 0.1351, 0.3063, 0.0940, 0.0714, 0.0125]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0819, 0.0305, 0.0624, 0.2216, 0.1206, 0.2381, 0.1098, 0.0977, 0.0374]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0342, 0.0040, 0.0319, 0.2765, 0.0608, 0.4518, 0.0702, 0.0668, 0.0038]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0768, 0.0491, 0.0870, 0.1850, 0.1341, 0.2134, 0.1164, 0.0955, 0.0428]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.6946e-03, 3.6741e-05, 3.2339e-03, 3.5913e-01, 2.7354e-02, 5.4899e-01,\n",
       "           4.6323e-02, 1.1186e-02, 4.7200e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0487, 0.0136, 0.0673, 0.2761, 0.1132, 0.2925, 0.0964, 0.0783, 0.0139]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0451, 0.0122, 0.0546, 0.3136, 0.1221, 0.2881, 0.0880, 0.0660, 0.0103]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0710, 0.0205, 0.0566, 0.2243, 0.1320, 0.2992, 0.0890, 0.0832, 0.0241]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0141, 0.0008, 0.0094, 0.3070, 0.0438, 0.5808, 0.0197, 0.0227, 0.0017]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0432, 0.0132, 0.0467, 0.2279, 0.1138, 0.3841, 0.0817, 0.0746, 0.0148]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0402, 0.0096, 0.0451, 0.2318, 0.0735, 0.4340, 0.0905, 0.0643, 0.0110]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0186, 0.0025, 0.0135, 0.2251, 0.0594, 0.6136, 0.0337, 0.0308, 0.0028]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0593, 0.0283, 0.0546, 0.1926, 0.1407, 0.3131, 0.0909, 0.0883, 0.0321]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0506, 0.0145, 0.0570, 0.2065, 0.1396, 0.3212, 0.1200, 0.0748, 0.0159]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0386, 0.0023, 0.0212, 0.2556, 0.0576, 0.5332, 0.0522, 0.0368, 0.0024]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0614, 0.0143, 0.0427, 0.1893, 0.0848, 0.4213, 0.0808, 0.0920, 0.0133]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0554, 0.0174, 0.0620, 0.1878, 0.1382, 0.3451, 0.0982, 0.0784, 0.0175]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0467, 0.0136, 0.0500, 0.1865, 0.1194, 0.3949, 0.0948, 0.0776, 0.0165]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0975, 0.0496, 0.0829, 0.1439, 0.1242, 0.2422, 0.1104, 0.1035, 0.0458]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0830, 0.0409, 0.0779, 0.1494, 0.1242, 0.2694, 0.1024, 0.1057, 0.0470]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0277, 0.0059, 0.0556, 0.1602, 0.1238, 0.4471, 0.0946, 0.0782, 0.0068]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.2805e-03, 4.9053e-05, 1.5539e-03, 3.5752e-02, 6.6068e-03, 9.4597e-01,\n",
       "           5.9896e-03, 2.7571e-03, 4.1143e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0423, 0.0145, 0.0526, 0.1376, 0.1227, 0.4660, 0.0754, 0.0700, 0.0189]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0446, 0.0082, 0.0374, 0.1851, 0.1199, 0.4737, 0.0659, 0.0592, 0.0060]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.5401e-05, 1.6089e-08, 1.3805e-05, 3.7343e-03, 2.3489e-04, 9.9582e-01,\n",
       "           5.4741e-05, 1.1343e-04, 3.3377e-08]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0210, 0.0032, 0.0147, 0.1537, 0.0501, 0.6810, 0.0256, 0.0475, 0.0033]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0156, 0.0019, 0.0111, 0.0893, 0.0431, 0.7749, 0.0261, 0.0356, 0.0026]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0562, 0.0268, 0.0656, 0.1456, 0.1446, 0.3571, 0.0876, 0.0858, 0.0309]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0601, 0.0100, 0.0345, 0.1661, 0.1036, 0.5010, 0.0591, 0.0544, 0.0112]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0090, 0.0012, 0.0051, 0.1076, 0.0189, 0.8299, 0.0101, 0.0170, 0.0011]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0194, 0.0026, 0.0179, 0.1235, 0.0532, 0.6945, 0.0415, 0.0444, 0.0032]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0177, 0.0015, 0.0104, 0.1403, 0.0381, 0.7257, 0.0307, 0.0331, 0.0025]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.6210e-03, 1.5184e-05, 5.4552e-04, 3.3802e-02, 2.6953e-03, 9.5394e-01,\n",
       "           1.9098e-03, 4.4471e-03, 2.6128e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0175, 0.0008, 0.0059, 0.1360, 0.0221, 0.7778, 0.0181, 0.0208, 0.0009]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0507, 0.0149, 0.0498, 0.1736, 0.1394, 0.4221, 0.0671, 0.0643, 0.0181]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0197, 0.0016, 0.0145, 0.0822, 0.0375, 0.7911, 0.0210, 0.0301, 0.0023]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0077, 0.0013, 0.0109, 0.1134, 0.0667, 0.7431, 0.0247, 0.0311, 0.0012]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[5.3927e-03, 1.6984e-04, 1.2831e-03, 3.9222e-02, 8.3252e-03, 9.3051e-01,\n",
       "           4.3729e-03, 1.0525e-02, 1.9836e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0190, 0.0011, 0.0119, 0.1156, 0.0352, 0.7718, 0.0158, 0.0283, 0.0014]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0430, 0.0139, 0.0354, 0.1266, 0.0713, 0.5775, 0.0608, 0.0574, 0.0141]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0184, 0.0029, 0.0136, 0.0632, 0.0542, 0.8005, 0.0204, 0.0243, 0.0024]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[9.5568e-03, 8.3943e-04, 5.7512e-03, 9.8759e-02, 2.9747e-02, 8.2081e-01,\n",
       "           1.2525e-02, 2.1329e-02, 6.8718e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.0504e-02, 5.4642e-04, 6.0157e-03, 6.3735e-02, 3.3636e-02, 8.4922e-01,\n",
       "           1.7857e-02, 1.7855e-02, 6.3194e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.3072e-02, 6.4665e-04, 6.2002e-03, 6.9584e-02, 2.1103e-02, 8.6498e-01,\n",
       "           1.1038e-02, 1.2744e-02, 6.3274e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0313, 0.0060, 0.0381, 0.1064, 0.0715, 0.6431, 0.0416, 0.0547, 0.0074]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0211, 0.0018, 0.0109, 0.1260, 0.0304, 0.7684, 0.0169, 0.0226, 0.0018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0191, 0.0037, 0.0148, 0.1202, 0.0791, 0.6488, 0.0467, 0.0620, 0.0056]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[5.0436e-03, 1.5003e-04, 2.6697e-03, 3.4019e-02, 2.0853e-02, 9.2157e-01,\n",
       "           6.9617e-03, 8.5433e-03, 1.8611e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.0902e-03, 3.4768e-05, 1.0194e-03, 3.4278e-02, 1.3362e-02, 9.4171e-01,\n",
       "           3.7113e-03, 4.7631e-03, 3.0669e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.1986e-05, 4.3504e-08, 2.3622e-05, 3.4064e-03, 7.6640e-04, 9.9550e-01,\n",
       "           1.7253e-04, 1.1876e-04, 1.3296e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[6.4232e-03, 3.8399e-04, 3.3108e-03, 6.1325e-02, 1.5853e-02, 8.9078e-01,\n",
       "           9.5876e-03, 1.1919e-02, 4.1320e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[4.6553e-03, 6.6659e-04, 9.6380e-03, 6.1867e-02, 3.3770e-02, 8.4947e-01,\n",
       "           2.0845e-02, 1.8174e-02, 9.1897e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[4.9640e-03, 4.3088e-04, 1.0027e-02, 6.3524e-02, 5.1438e-02, 8.2166e-01,\n",
       "           2.4959e-02, 2.2176e-02, 8.2189e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0098, 0.0025, 0.0105, 0.0913, 0.0529, 0.7947, 0.0188, 0.0177, 0.0016]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0373, 0.0071, 0.0288, 0.1358, 0.0795, 0.6047, 0.0402, 0.0592, 0.0075]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.6003e-03, 8.0909e-05, 2.4186e-03, 3.1774e-02, 1.8325e-02, 9.3202e-01,\n",
       "           6.1285e-03, 6.5577e-03, 9.1599e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[1.7956e-03, 7.0113e-05, 9.3268e-04, 3.4926e-02, 7.8277e-03, 9.4695e-01,\n",
       "           2.0287e-03, 5.3526e-03, 1.1869e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0288, 0.0077, 0.0299, 0.1553, 0.0914, 0.5716, 0.0571, 0.0500, 0.0083]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.5164e-03, 1.0616e-04, 1.1056e-03, 3.1736e-02, 1.6240e-02, 9.3937e-01,\n",
       "           4.2070e-03, 4.6406e-03, 7.8487e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[8.7266e-04, 2.0282e-05, 1.6437e-03, 3.0768e-02, 1.1347e-02, 9.4873e-01,\n",
       "           4.0269e-03, 2.5603e-03, 3.2302e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.1991e-03, 1.1119e-04, 3.1791e-03, 6.0622e-02, 2.5335e-02, 8.8993e-01,\n",
       "           8.4732e-03, 8.8673e-03, 2.7930e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0181, 0.0022, 0.0175, 0.1138, 0.0664, 0.7212, 0.0310, 0.0266, 0.0031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.8840e-03, 4.0429e-05, 1.2859e-03, 7.3859e-02, 7.9795e-03, 9.0702e-01,\n",
       "           3.5822e-03, 4.3059e-03, 4.0768e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0186, 0.0026, 0.0305, 0.1179, 0.0889, 0.6776, 0.0280, 0.0323, 0.0037]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[8.8308e-05, 1.3776e-07, 2.4991e-05, 7.2382e-03, 1.3879e-03, 9.9067e-01,\n",
       "           1.4896e-04, 4.4366e-04, 8.7022e-08]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0183, 0.0009, 0.0122, 0.0770, 0.0421, 0.7833, 0.0259, 0.0382, 0.0019]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.6675e-03, 8.4220e-05, 7.7132e-04, 3.1897e-02, 1.0839e-02, 9.4757e-01,\n",
       "           4.0726e-03, 2.0509e-03, 4.4120e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[3.7397e-03, 1.2030e-04, 2.2087e-03, 6.9303e-02, 1.7918e-02, 8.9554e-01,\n",
       "           5.5687e-03, 5.4395e-03, 1.5967e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0222, 0.0071, 0.0197, 0.1035, 0.0820, 0.6874, 0.0399, 0.0335, 0.0046]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0205, 0.0015, 0.0095, 0.1430, 0.0651, 0.7158, 0.0189, 0.0239, 0.0018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.0100e-04, 8.2423e-07, 7.2047e-05, 8.7077e-03, 5.0910e-03, 9.8521e-01,\n",
       "           4.3402e-04, 3.8308e-04, 4.9143e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0244, 0.0012, 0.0144, 0.1215, 0.0627, 0.7194, 0.0287, 0.0258, 0.0019]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0274, 0.0053, 0.0214, 0.1306, 0.0667, 0.6492, 0.0355, 0.0555, 0.0084]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[2.6988e-03, 2.6830e-04, 1.8813e-03, 6.3423e-02, 1.7775e-02, 9.0330e-01,\n",
       "           5.1145e-03, 5.2169e-03, 3.1926e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0161, 0.0017, 0.0094, 0.0995, 0.0446, 0.7787, 0.0195, 0.0283, 0.0023]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0265, 0.0019, 0.0141, 0.1449, 0.0770, 0.6670, 0.0312, 0.0332, 0.0043]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[5.7467e-03, 2.7168e-04, 5.9011e-03, 8.7144e-02, 4.3795e-02, 8.3207e-01,\n",
       "           1.0871e-02, 1.3817e-02, 3.8490e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.6484e-03, 8.2820e-05, 4.1505e-03, 1.8410e-01, 4.1590e-02, 7.4223e-01,\n",
       "           1.2327e-02, 1.2688e-02, 1.8509e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0300, 0.0058, 0.0203, 0.1219, 0.0947, 0.6365, 0.0440, 0.0401, 0.0068]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[4.3343e-03, 8.8411e-05, 1.6207e-03, 5.3760e-02, 2.7186e-02, 9.0170e-01,\n",
       "           5.8585e-03, 5.3147e-03, 1.3518e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0313, 0.0057, 0.0287, 0.1937, 0.1252, 0.5054, 0.0616, 0.0418, 0.0064]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.5503e-02, 7.5912e-04, 7.2919e-03, 8.6872e-02, 4.8623e-02, 7.8929e-01,\n",
       "           1.5896e-02, 3.4348e-02, 1.4177e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0366, 0.0098, 0.0433, 0.1356, 0.1517, 0.4391, 0.0708, 0.0992, 0.0140]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[6.9314e-05, 3.2684e-07, 5.6569e-05, 3.6625e-02, 6.2398e-03, 9.5645e-01,\n",
       "           3.6664e-04, 1.9371e-04, 3.7855e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0435, 0.0065, 0.0347, 0.1206, 0.2306, 0.4406, 0.0508, 0.0612, 0.0116]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0393, 0.0039, 0.0235, 0.1901, 0.1304, 0.4956, 0.0543, 0.0556, 0.0073]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[5.2883e-03, 2.8170e-04, 6.7409e-03, 2.0027e-01, 1.0574e-01, 6.4250e-01,\n",
       "           2.5106e-02, 1.3657e-02, 4.2640e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[8.2839e-03, 2.2496e-04, 4.4602e-03, 1.0420e-01, 4.4727e-02, 8.1230e-01,\n",
       "           1.1257e-02, 1.4117e-02, 4.2058e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0733, 0.0190, 0.0479, 0.1520, 0.1618, 0.3595, 0.0867, 0.0724, 0.0275]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0283, 0.0032, 0.0190, 0.1887, 0.1119, 0.5880, 0.0318, 0.0262, 0.0029]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0420, 0.0091, 0.0236, 0.1686, 0.1173, 0.5100, 0.0648, 0.0557, 0.0089]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0252, 0.0026, 0.0259, 0.1727, 0.1024, 0.5590, 0.0745, 0.0346, 0.0031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0466, 0.0104, 0.0367, 0.2061, 0.1645, 0.3832, 0.0860, 0.0564, 0.0101]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0443, 0.0093, 0.0478, 0.1579, 0.1276, 0.4470, 0.0900, 0.0664, 0.0097]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0425, 0.0031, 0.0261, 0.2306, 0.0980, 0.4857, 0.0614, 0.0488, 0.0038]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0445, 0.0072, 0.0407, 0.2223, 0.1621, 0.3318, 0.0782, 0.1047, 0.0086]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0771, 0.0274, 0.0657, 0.1491, 0.1533, 0.3012, 0.0947, 0.0953, 0.0362]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0776, 0.0279, 0.0787, 0.1858, 0.1413, 0.2464, 0.1086, 0.1023, 0.0315]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0509, 0.0091, 0.0531, 0.1765, 0.1395, 0.3923, 0.0875, 0.0769, 0.0142]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0114, 0.0006, 0.0097, 0.2349, 0.1075, 0.5592, 0.0485, 0.0271, 0.0011]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0436, 0.0071, 0.0377, 0.2308, 0.1444, 0.3979, 0.0956, 0.0367, 0.0062]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0507, 0.0053, 0.0369, 0.1972, 0.1083, 0.4525, 0.0755, 0.0652, 0.0083]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0919, 0.0408, 0.0713, 0.1508, 0.1539, 0.2216, 0.1091, 0.1176, 0.0429]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0665, 0.0271, 0.0587, 0.1986, 0.1371, 0.3116, 0.0977, 0.0811, 0.0216]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0670, 0.0220, 0.0767, 0.1751, 0.1783, 0.2588, 0.1072, 0.0898, 0.0250]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0604, 0.0115, 0.0582, 0.2140, 0.1417, 0.3156, 0.1188, 0.0697, 0.0102]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0659, 0.0157, 0.0457, 0.2366, 0.1362, 0.2948, 0.1155, 0.0731, 0.0166]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0803, 0.0485, 0.1008, 0.1224, 0.1703, 0.1968, 0.1213, 0.1029, 0.0567]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0890, 0.0396, 0.0845, 0.1618, 0.1473, 0.2190, 0.1115, 0.1018, 0.0455]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0746, 0.0104, 0.0593, 0.1876, 0.1449, 0.3171, 0.0949, 0.0966, 0.0147]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0746, 0.0277, 0.0685, 0.2157, 0.1480, 0.2261, 0.1136, 0.0981, 0.0278]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0646, 0.0226, 0.0603, 0.2214, 0.1589, 0.2228, 0.1217, 0.1015, 0.0261]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0786, 0.0245, 0.0732, 0.1795, 0.1320, 0.2721, 0.1119, 0.0997, 0.0285]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0650, 0.0133, 0.0720, 0.1894, 0.1435, 0.2973, 0.1290, 0.0761, 0.0145]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0964, 0.0352, 0.0840, 0.1629, 0.1350, 0.2207, 0.1017, 0.1167, 0.0474]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0764, 0.0229, 0.0644, 0.1655, 0.1450, 0.2854, 0.1061, 0.1056, 0.0287]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0373, 0.0034, 0.0349, 0.2296, 0.1143, 0.4141, 0.0997, 0.0611, 0.0057]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0554, 0.0113, 0.0588, 0.1689, 0.1335, 0.3548, 0.1162, 0.0892, 0.0118]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0244, 0.0027, 0.0348, 0.2348, 0.1532, 0.4080, 0.0973, 0.0419, 0.0029]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0459, 0.0108, 0.0497, 0.2229, 0.1487, 0.3053, 0.1107, 0.0903, 0.0156]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0610, 0.0258, 0.0752, 0.1888, 0.1569, 0.2336, 0.1069, 0.1231, 0.0286]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0610, 0.0107, 0.0558, 0.2186, 0.0932, 0.3460, 0.1013, 0.1006, 0.0128]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0822, 0.0457, 0.0946, 0.1396, 0.1650, 0.1629, 0.1216, 0.1237, 0.0646]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0600, 0.0127, 0.0644, 0.1967, 0.1635, 0.2622, 0.1201, 0.1022, 0.0183]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0474, 0.0129, 0.0653, 0.1751, 0.1582, 0.3020, 0.1173, 0.1042, 0.0175]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0125, 0.0007, 0.0146, 0.1895, 0.1341, 0.5538, 0.0505, 0.0435, 0.0008]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0862, 0.0509, 0.0893, 0.1384, 0.1519, 0.2062, 0.1164, 0.1084, 0.0523]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0739, 0.0286, 0.0728, 0.1880, 0.1669, 0.2312, 0.1230, 0.0900, 0.0255]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0635, 0.0287, 0.0832, 0.1634, 0.1728, 0.2328, 0.1411, 0.0849, 0.0296]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0640, 0.0384, 0.0777, 0.1670, 0.1888, 0.2056, 0.1257, 0.0930, 0.0397]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0439, 0.0150, 0.0640, 0.2379, 0.1636, 0.2340, 0.1582, 0.0686, 0.0147]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0719, 0.0320, 0.0793, 0.1705, 0.1449, 0.2370, 0.1216, 0.1045, 0.0382]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0652, 0.0232, 0.0715, 0.2035, 0.1507, 0.2406, 0.1297, 0.0914, 0.0242]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0450, 0.0152, 0.0763, 0.1846, 0.1853, 0.2156, 0.1445, 0.1162, 0.0173]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0616, 0.0178, 0.0596, 0.1941, 0.1677, 0.2767, 0.1165, 0.0906, 0.0154]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0520, 0.0122, 0.0614, 0.2046, 0.1908, 0.2576, 0.1176, 0.0863, 0.0175]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0430, 0.0081, 0.0690, 0.1884, 0.2250, 0.2692, 0.1072, 0.0812, 0.0088]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0849, 0.0473, 0.0910, 0.1595, 0.1687, 0.1652, 0.1311, 0.1040, 0.0484]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0079, 0.0005, 0.0150, 0.2699, 0.1815, 0.3820, 0.0781, 0.0646, 0.0007]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0849, 0.0500, 0.0824, 0.1680, 0.1675, 0.1863, 0.1162, 0.0990, 0.0455]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0262, 0.0023, 0.0258, 0.3760, 0.1281, 0.3271, 0.0690, 0.0427, 0.0028]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0761, 0.0322, 0.0946, 0.1528, 0.1708, 0.2173, 0.1220, 0.0976, 0.0367]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0690, 0.0447, 0.0864, 0.1760, 0.1789, 0.1810, 0.1362, 0.0904, 0.0373]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0368, 0.0069, 0.0427, 0.1944, 0.1866, 0.3589, 0.1088, 0.0553, 0.0096]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[8.9578e-03, 8.0168e-04, 1.1752e-02, 4.9535e-01, 1.2197e-01, 2.5994e-01,\n",
       "           7.7337e-02, 2.3489e-02, 3.9841e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.6647e-04, 6.2516e-07, 3.0290e-04, 3.7969e-01, 1.4865e-02, 5.8800e-01,\n",
       "           1.5902e-02, 9.6785e-04, 2.4811e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0509, 0.0161, 0.0721, 0.2170, 0.1919, 0.2017, 0.1306, 0.0996, 0.0202]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0322, 0.0033, 0.0349, 0.2617, 0.1657, 0.3582, 0.0905, 0.0493, 0.0042]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0504, 0.0094, 0.0541, 0.1946, 0.1593, 0.3265, 0.1301, 0.0647, 0.0108]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0720, 0.0243, 0.0803, 0.1663, 0.1842, 0.2192, 0.1280, 0.0972, 0.0285]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0673, 0.0285, 0.0808, 0.1600, 0.1804, 0.2134, 0.1237, 0.1113, 0.0347]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0440, 0.0136, 0.0595, 0.2061, 0.1603, 0.2939, 0.1353, 0.0759, 0.0115]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0104, 0.0004, 0.0191, 0.3209, 0.1864, 0.3894, 0.0483, 0.0245, 0.0005]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0450, 0.0108, 0.0488, 0.1771, 0.1614, 0.3827, 0.1025, 0.0611, 0.0106]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0698, 0.0285, 0.0755, 0.1608, 0.1428, 0.2701, 0.1251, 0.1002, 0.0272]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0414, 0.0083, 0.0554, 0.2321, 0.1420, 0.3078, 0.1094, 0.0915, 0.0122]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[6.7043e-03, 1.7912e-04, 1.3032e-02, 2.0665e-01, 6.4837e-02, 6.4179e-01,\n",
       "           4.0856e-02, 2.5534e-02, 4.1998e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0790, 0.0308, 0.0728, 0.1573, 0.1576, 0.2390, 0.1377, 0.0946, 0.0311]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0661, 0.0251, 0.0676, 0.1628, 0.1868, 0.2164, 0.1375, 0.1013, 0.0363]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0373, 0.0071, 0.0490, 0.1457, 0.2005, 0.3697, 0.1259, 0.0553, 0.0095]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0447, 0.0156, 0.0608, 0.1592, 0.2322, 0.2672, 0.1305, 0.0744, 0.0153]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0242, 0.0027, 0.0296, 0.1502, 0.1555, 0.5047, 0.0962, 0.0335, 0.0035]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0448, 0.0101, 0.0473, 0.1444, 0.1494, 0.4241, 0.1013, 0.0687, 0.0101]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0708, 0.0265, 0.0662, 0.1461, 0.1560, 0.2827, 0.1279, 0.0977, 0.0259]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0400, 0.0098, 0.0446, 0.1249, 0.1936, 0.3700, 0.1153, 0.0893, 0.0125]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0663, 0.0337, 0.0728, 0.1479, 0.1706, 0.2390, 0.1318, 0.0991, 0.0390]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0328, 0.0031, 0.0281, 0.1410, 0.1440, 0.4715, 0.1179, 0.0568, 0.0047]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0410, 0.0081, 0.0381, 0.1244, 0.1686, 0.4012, 0.1119, 0.0964, 0.0103]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0596, 0.0274, 0.0579, 0.1618, 0.1759, 0.2736, 0.1306, 0.0900, 0.0232]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0513, 0.0202, 0.0674, 0.1373, 0.1914, 0.2853, 0.1213, 0.0998, 0.0260]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0359, 0.0118, 0.0591, 0.1351, 0.1721, 0.3249, 0.1422, 0.1031, 0.0157]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0732, 0.0254, 0.0765, 0.1239, 0.1662, 0.2792, 0.1396, 0.0847, 0.0314]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[2.4173e-03, 4.7859e-05, 2.2589e-03, 5.8806e-02, 7.6475e-02, 8.2252e-01,\n",
       "           2.8194e-02, 9.2211e-03, 5.8832e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0324, 0.0041, 0.0411, 0.1300, 0.1556, 0.4719, 0.1210, 0.0382, 0.0056]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.2923e-03, 1.0087e-05, 1.7392e-03, 3.8844e-02, 4.3297e-02, 8.6686e-01,\n",
       "           4.5495e-02, 2.4534e-03, 1.1604e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0496, 0.0064, 0.0430, 0.1363, 0.1574, 0.4018, 0.1289, 0.0680, 0.0088]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0351, 0.0051, 0.0450, 0.1220, 0.1745, 0.4161, 0.1382, 0.0532, 0.0107]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0689, 0.0354, 0.0763, 0.1468, 0.1620, 0.2199, 0.1570, 0.0973, 0.0364]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0486, 0.0082, 0.0501, 0.1208, 0.1654, 0.4033, 0.1221, 0.0707, 0.0108]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0831, 0.0483, 0.0849, 0.1145, 0.1578, 0.1929, 0.1327, 0.1277, 0.0581]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0571, 0.0115, 0.0431, 0.1587, 0.1381, 0.3788, 0.1235, 0.0774, 0.0118]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0499, 0.0136, 0.0545, 0.1545, 0.1386, 0.3715, 0.1246, 0.0787, 0.0140]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0515, 0.0124, 0.0584, 0.1361, 0.1679, 0.3472, 0.1417, 0.0691, 0.0157]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0760, 0.0335, 0.0785, 0.1366, 0.1624, 0.2361, 0.1395, 0.0960, 0.0413]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0478, 0.0084, 0.0410, 0.1700, 0.1682, 0.3381, 0.1517, 0.0632, 0.0116]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0578, 0.0150, 0.0592, 0.1339, 0.1514, 0.3810, 0.1106, 0.0726, 0.0185]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0579, 0.0163, 0.0547, 0.1367, 0.1766, 0.3329, 0.1201, 0.0844, 0.0203]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.7019e-03, 7.3369e-05, 2.8247e-03, 1.8651e-01, 7.0547e-02, 6.5508e-01,\n",
       "           6.9104e-02, 1.2043e-02, 1.1487e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0510, 0.0100, 0.0543, 0.1647, 0.1641, 0.2987, 0.1536, 0.0856, 0.0181]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0762, 0.0327, 0.0823, 0.1284, 0.1551, 0.2403, 0.1378, 0.1102, 0.0369]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0609, 0.0175, 0.0595, 0.1556, 0.1440, 0.3533, 0.1034, 0.0771, 0.0287]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0162, 0.0019, 0.0167, 0.1163, 0.1641, 0.5525, 0.0859, 0.0434, 0.0032]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0204, 0.0036, 0.0229, 0.1429, 0.1519, 0.5497, 0.0699, 0.0339, 0.0048]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0190, 0.0023, 0.0195, 0.1234, 0.0969, 0.6251, 0.0775, 0.0343, 0.0021]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0758, 0.0372, 0.0837, 0.1402, 0.1459, 0.2551, 0.1106, 0.1078, 0.0438]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[1.0897e-02, 5.6326e-04, 1.8740e-02, 1.3102e-01, 1.1400e-01, 6.6019e-01,\n",
       "           4.3292e-02, 1.9389e-02, 1.9030e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0595, 0.0117, 0.0670, 0.1201, 0.1552, 0.3589, 0.1298, 0.0810, 0.0168]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0610, 0.0188, 0.0614, 0.1353, 0.1318, 0.3362, 0.1176, 0.1122, 0.0258]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0335, 0.0043, 0.0397, 0.0916, 0.0782, 0.6359, 0.0719, 0.0403, 0.0047]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[7.3242e-03, 1.9575e-04, 9.5126e-03, 5.2268e-02, 4.6091e-02, 8.5048e-01,\n",
       "           1.9341e-02, 1.4496e-02, 2.9088e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[7.2930e-03, 6.9166e-04, 1.2036e-02, 1.0643e-01, 6.4548e-02, 7.2875e-01,\n",
       "           5.1762e-02, 2.7681e-02, 8.0644e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0576, 0.0144, 0.0659, 0.1609, 0.1333, 0.3467, 0.1140, 0.0876, 0.0195]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0298, 0.0039, 0.0452, 0.1570, 0.1234, 0.4695, 0.0916, 0.0718, 0.0078]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0548, 0.0161, 0.0566, 0.1510, 0.1307, 0.3665, 0.0949, 0.1125, 0.0169]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0555, 0.0146, 0.0670, 0.1592, 0.1261, 0.3364, 0.1024, 0.1163, 0.0225]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0262, 0.0029, 0.0307, 0.1368, 0.1043, 0.5494, 0.0875, 0.0573, 0.0047]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[4.7947e-03, 2.3045e-04, 8.5734e-03, 1.2327e-01, 4.1779e-02, 7.8245e-01,\n",
       "           2.3946e-02, 1.4582e-02, 3.7029e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0469, 0.0054, 0.0383, 0.1585, 0.1356, 0.4288, 0.1174, 0.0606, 0.0085]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.8013e-03, 3.5813e-05, 3.0361e-03, 7.1114e-02, 2.2653e-02, 8.6818e-01,\n",
       "           1.9187e-02, 1.1917e-02, 7.0728e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0502, 0.0058, 0.0372, 0.1526, 0.1166, 0.4760, 0.0702, 0.0832, 0.0082]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[4.4857e-06, 5.3940e-10, 1.1012e-05, 6.9655e-03, 2.8741e-04, 9.9229e-01,\n",
       "           1.4475e-04, 2.9511e-04, 1.7880e-08]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0331, 0.0044, 0.0224, 0.1716, 0.0854, 0.5555, 0.0602, 0.0633, 0.0040]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0202, 0.0008, 0.0222, 0.0996, 0.0595, 0.7217, 0.0463, 0.0283, 0.0013]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0262, 0.0054, 0.0393, 0.1438, 0.1309, 0.5098, 0.0700, 0.0645, 0.0101]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0421, 0.0114, 0.0581, 0.1280, 0.1358, 0.4413, 0.0959, 0.0684, 0.0189]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0254, 0.0023, 0.0425, 0.1189, 0.1306, 0.5462, 0.0756, 0.0531, 0.0055]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0391, 0.0033, 0.0356, 0.1350, 0.1200, 0.5457, 0.0658, 0.0496, 0.0060]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0585, 0.0184, 0.0809, 0.1603, 0.1689, 0.2837, 0.1081, 0.0959, 0.0254]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0329, 0.0040, 0.0431, 0.1216, 0.1137, 0.5498, 0.0666, 0.0612, 0.0072]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0350, 0.0061, 0.0535, 0.1564, 0.1489, 0.4309, 0.0952, 0.0658, 0.0082]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0637, 0.0138, 0.0781, 0.1214, 0.1307, 0.3635, 0.1172, 0.0908, 0.0208]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0802, 0.0396, 0.0897, 0.1306, 0.1677, 0.2224, 0.1176, 0.1074, 0.0448]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0548, 0.0048, 0.0483, 0.1683, 0.1280, 0.4301, 0.0909, 0.0666, 0.0082]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0569, 0.0099, 0.0681, 0.1704, 0.1336, 0.3562, 0.0927, 0.0962, 0.0161]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0287, 0.0022, 0.0250, 0.1376, 0.0695, 0.6450, 0.0526, 0.0367, 0.0027]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.2015e-02, 4.5406e-04, 1.5500e-02, 1.4146e-01, 1.1208e-01, 6.5504e-01,\n",
       "           4.2723e-02, 1.9327e-02, 1.4021e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0713, 0.0275, 0.0874, 0.1502, 0.1585, 0.2274, 0.1345, 0.1082, 0.0351]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[8.2820e-05, 1.1329e-08, 1.0387e-04, 2.2055e-02, 3.5955e-03, 9.7025e-01,\n",
       "           3.8165e-03, 9.6099e-05, 5.3351e-08]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0768, 0.0159, 0.0622, 0.1489, 0.1397, 0.3203, 0.1130, 0.0979, 0.0253]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0871, 0.0366, 0.0820, 0.1404, 0.1557, 0.2358, 0.1113, 0.1049, 0.0462]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0551, 0.0038, 0.0483, 0.1364, 0.1232, 0.4956, 0.0674, 0.0631, 0.0071]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0280, 0.0014, 0.0401, 0.1013, 0.1198, 0.6062, 0.0639, 0.0362, 0.0031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0722, 0.0131, 0.0534, 0.1789, 0.1357, 0.3513, 0.0994, 0.0796, 0.0165]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0928, 0.0349, 0.0927, 0.1365, 0.1434, 0.2305, 0.1181, 0.1054, 0.0458]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0792, 0.0224, 0.0721, 0.1606, 0.1516, 0.2858, 0.1071, 0.0927, 0.0284]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0908, 0.0308, 0.0795, 0.1626, 0.1487, 0.2455, 0.1035, 0.0975, 0.0412]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0786, 0.0235, 0.0785, 0.1535, 0.1396, 0.2746, 0.1312, 0.0927, 0.0278]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0794, 0.0248, 0.0799, 0.1347, 0.1688, 0.2491, 0.1258, 0.1006, 0.0369]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1011, 0.0585, 0.0964, 0.1261, 0.1353, 0.1884, 0.1143, 0.1154, 0.0644]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0739, 0.0284, 0.0833, 0.1446, 0.1619, 0.2403, 0.1266, 0.1011, 0.0399]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0567, 0.0101, 0.0549, 0.1738, 0.1442, 0.3448, 0.1011, 0.0961, 0.0182]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0718, 0.0182, 0.0735, 0.1780, 0.1539, 0.2903, 0.1069, 0.0835, 0.0238]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0945, 0.0273, 0.0798, 0.1458, 0.1533, 0.2334, 0.1235, 0.1061, 0.0362]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0982, 0.0596, 0.0991, 0.1260, 0.1363, 0.1673, 0.1206, 0.1203, 0.0728]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0926, 0.0355, 0.0962, 0.1342, 0.1663, 0.1942, 0.1288, 0.1067, 0.0454]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0963, 0.0588, 0.0989, 0.1282, 0.1377, 0.1780, 0.1241, 0.1088, 0.0692]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0906, 0.0392, 0.0843, 0.1411, 0.1484, 0.2221, 0.1215, 0.1027, 0.0501]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[2.8827e-02, 5.1956e-04, 1.5076e-02, 1.6954e-01, 9.7590e-02, 6.1624e-01,\n",
       "           4.2468e-02, 2.8756e-02, 9.7868e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0990, 0.0626, 0.0989, 0.1215, 0.1382, 0.1681, 0.1203, 0.1199, 0.0716]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0973, 0.0422, 0.0887, 0.1193, 0.1558, 0.2064, 0.1202, 0.1118, 0.0582]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1056, 0.0656, 0.1009, 0.1204, 0.1327, 0.1553, 0.1194, 0.1201, 0.0800]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[7.9091e-04, 2.5918e-07, 3.6338e-04, 4.5238e-02, 7.7582e-03, 9.3710e-01,\n",
       "           7.9220e-03, 8.2900e-04, 1.9724e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0519, 0.0100, 0.0541, 0.1644, 0.1357, 0.3764, 0.1084, 0.0829, 0.0162]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0805, 0.0209, 0.0768, 0.1664, 0.1434, 0.2556, 0.1134, 0.1101, 0.0329]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0386, 0.0009, 0.0396, 0.1281, 0.1211, 0.5467, 0.0667, 0.0553, 0.0030]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0857, 0.0291, 0.0894, 0.1441, 0.1522, 0.2217, 0.1219, 0.1105, 0.0454]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0883, 0.0338, 0.0885, 0.1315, 0.1625, 0.2205, 0.1176, 0.1085, 0.0488]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1004, 0.0654, 0.1016, 0.1235, 0.1397, 0.1554, 0.1239, 0.1177, 0.0724]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0925, 0.0364, 0.0936, 0.1440, 0.1509, 0.2156, 0.1199, 0.1020, 0.0452]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0965, 0.0354, 0.0832, 0.1500, 0.1494, 0.1941, 0.1232, 0.1168, 0.0514]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0941, 0.0393, 0.0896, 0.1423, 0.1421, 0.2035, 0.1173, 0.1171, 0.0548]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1009, 0.0592, 0.0969, 0.1320, 0.1367, 0.1599, 0.1203, 0.1231, 0.0712]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0917, 0.0350, 0.0913, 0.1540, 0.1518, 0.1980, 0.1213, 0.1097, 0.0472]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1048, 0.0668, 0.0966, 0.1294, 0.1345, 0.1497, 0.1224, 0.1200, 0.0758]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0926, 0.0430, 0.0890, 0.1346, 0.1670, 0.1963, 0.1263, 0.1074, 0.0438]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0965, 0.0652, 0.0998, 0.1224, 0.1429, 0.1598, 0.1199, 0.1212, 0.0723]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0854, 0.0399, 0.0891, 0.1411, 0.1454, 0.2009, 0.1319, 0.1149, 0.0514]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0972, 0.0701, 0.1017, 0.1220, 0.1427, 0.1473, 0.1213, 0.1177, 0.0800]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1064, 0.0671, 0.1013, 0.1200, 0.1364, 0.1563, 0.1173, 0.1184, 0.0769]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.5655e-02, 3.2035e-04, 2.2072e-02, 2.4972e-01, 1.1190e-01, 5.0702e-01,\n",
       "           4.6187e-02, 4.6268e-02, 8.6893e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0946, 0.0415, 0.0927, 0.1472, 0.1540, 0.1819, 0.1307, 0.1104, 0.0471]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0664, 0.0148, 0.0747, 0.1840, 0.1586, 0.2340, 0.1326, 0.1171, 0.0178]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0570, 0.0145, 0.0674, 0.1869, 0.1593, 0.2763, 0.1160, 0.1033, 0.0192]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1000, 0.0541, 0.1000, 0.1302, 0.1487, 0.1525, 0.1286, 0.1228, 0.0632]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0572, 0.0087, 0.0727, 0.2008, 0.1602, 0.2693, 0.1206, 0.0949, 0.0155]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1032, 0.0588, 0.0988, 0.1264, 0.1356, 0.1523, 0.1237, 0.1283, 0.0729]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0335, 0.0005, 0.0285, 0.2217, 0.0972, 0.4954, 0.0775, 0.0449, 0.0009]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1036, 0.0600, 0.0989, 0.1303, 0.1424, 0.1565, 0.1253, 0.1182, 0.0649]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1026, 0.0653, 0.1017, 0.1276, 0.1390, 0.1363, 0.1257, 0.1238, 0.0779]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0965, 0.0558, 0.0907, 0.1376, 0.1429, 0.1544, 0.1295, 0.1250, 0.0677]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0925, 0.0462, 0.0983, 0.1395, 0.1583, 0.1646, 0.1308, 0.1154, 0.0543]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0893, 0.0373, 0.0910, 0.1714, 0.1434, 0.1796, 0.1362, 0.1134, 0.0384]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0950, 0.0507, 0.1033, 0.1387, 0.1462, 0.1564, 0.1285, 0.1175, 0.0637]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0760, 0.0232, 0.0782, 0.2018, 0.1547, 0.2021, 0.1238, 0.1094, 0.0308]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0600, 0.0059, 0.0523, 0.2549, 0.1246, 0.2702, 0.1220, 0.1017, 0.0085]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0523, 0.0074, 0.0539, 0.2532, 0.1362, 0.2557, 0.1171, 0.1116, 0.0126]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0761, 0.0244, 0.0715, 0.1918, 0.1558, 0.2260, 0.1221, 0.1048, 0.0275]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0790, 0.0195, 0.0671, 0.1949, 0.1485, 0.1970, 0.1451, 0.1191, 0.0298]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0881, 0.0298, 0.0855, 0.1645, 0.1387, 0.1819, 0.1356, 0.1365, 0.0394]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0795, 0.0179, 0.0731, 0.1998, 0.1444, 0.2181, 0.1358, 0.1083, 0.0231]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0816, 0.0195, 0.0733, 0.1854, 0.1539, 0.2108, 0.1301, 0.1149, 0.0306]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0703, 0.0175, 0.0750, 0.1973, 0.1480, 0.2084, 0.1375, 0.1230, 0.0230]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0330, 0.0012, 0.0297, 0.3097, 0.1287, 0.3218, 0.1213, 0.0525, 0.0020]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.5077e-02, 2.4557e-04, 1.5038e-02, 3.8496e-01, 9.9823e-02, 3.4351e-01,\n",
       "           9.0183e-02, 4.0070e-02, 1.0899e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0737, 0.0162, 0.0753, 0.1998, 0.1478, 0.2200, 0.1484, 0.0994, 0.0194]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0697, 0.0141, 0.0651, 0.2239, 0.1763, 0.1961, 0.1397, 0.0997, 0.0155]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0892, 0.0323, 0.0880, 0.1826, 0.1406, 0.1777, 0.1347, 0.1166, 0.0383]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0755, 0.0231, 0.0807, 0.1830, 0.1559, 0.2375, 0.1112, 0.1035, 0.0295]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0796, 0.0367, 0.0800, 0.1660, 0.1548, 0.1898, 0.1238, 0.1277, 0.0418]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0549, 0.0077, 0.0560, 0.2657, 0.1400, 0.2457, 0.1217, 0.0981, 0.0102]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0710, 0.0212, 0.0700, 0.1988, 0.1751, 0.2104, 0.1273, 0.1014, 0.0249]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0688, 0.0119, 0.0641, 0.2145, 0.1809, 0.2167, 0.1322, 0.0962, 0.0148]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0433, 0.0036, 0.0499, 0.2571, 0.1281, 0.3426, 0.0994, 0.0689, 0.0072]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0691, 0.0102, 0.0648, 0.2303, 0.1474, 0.2431, 0.1199, 0.1014, 0.0138]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0301, 0.0013, 0.0322, 0.2836, 0.1697, 0.3262, 0.0946, 0.0596, 0.0026]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0669, 0.0059, 0.0522, 0.2034, 0.1638, 0.2870, 0.1267, 0.0855, 0.0085]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0838, 0.0209, 0.0709, 0.2050, 0.1428, 0.2147, 0.1149, 0.1167, 0.0305]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0698, 0.0147, 0.0762, 0.1901, 0.1700, 0.2224, 0.1213, 0.1135, 0.0222]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0750, 0.0193, 0.0795, 0.1833, 0.1567, 0.2144, 0.1336, 0.1115, 0.0266]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0544, 0.0037, 0.0465, 0.2536, 0.1680, 0.2854, 0.1176, 0.0658, 0.0049]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0881, 0.0285, 0.0769, 0.1750, 0.1536, 0.1929, 0.1308, 0.1195, 0.0346]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0888, 0.0254, 0.0796, 0.1715, 0.1429, 0.2209, 0.1136, 0.1213, 0.0358]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0482, 0.0049, 0.0406, 0.2957, 0.1460, 0.3095, 0.0748, 0.0733, 0.0069]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0605, 0.0071, 0.0484, 0.2406, 0.1402, 0.2890, 0.1247, 0.0801, 0.0093]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0614, 0.0055, 0.0584, 0.1786, 0.1452, 0.3711, 0.0948, 0.0762, 0.0087]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0953, 0.0329, 0.0837, 0.1579, 0.1475, 0.1974, 0.1277, 0.1199, 0.0378]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0323, 0.0028, 0.0451, 0.2532, 0.2038, 0.2999, 0.1134, 0.0446, 0.0049]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0247, 0.0013, 0.0298, 0.2518, 0.1156, 0.4448, 0.0865, 0.0428, 0.0027]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.9489e-03, 7.8343e-06, 2.3157e-03, 2.9443e-01, 5.0124e-02, 6.1496e-01,\n",
       "           2.7495e-02, 6.7044e-03, 1.7184e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0690, 0.0103, 0.0576, 0.1627, 0.2089, 0.2771, 0.1173, 0.0797, 0.0174]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0670, 0.0167, 0.0679, 0.1900, 0.1670, 0.2374, 0.1318, 0.0986, 0.0236]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0499, 0.0061, 0.0446, 0.2175, 0.1666, 0.2907, 0.1137, 0.1008, 0.0101]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0907, 0.0294, 0.0792, 0.1641, 0.1806, 0.2213, 0.1223, 0.0886, 0.0238]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0319, 0.0046, 0.0392, 0.2143, 0.1791, 0.3728, 0.0967, 0.0537, 0.0077]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0850, 0.0083, 0.0476, 0.1795, 0.1638, 0.3067, 0.1262, 0.0736, 0.0093]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0755, 0.0262, 0.0880, 0.1538, 0.1648, 0.2380, 0.1096, 0.1090, 0.0351]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0526, 0.0035, 0.0328, 0.2001, 0.1617, 0.4071, 0.0830, 0.0555, 0.0037]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0672, 0.0129, 0.0592, 0.1814, 0.1602, 0.2971, 0.1076, 0.0923, 0.0221]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0388, 0.0006, 0.0263, 0.2817, 0.1812, 0.3852, 0.0569, 0.0275, 0.0018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[4.1932e-03, 3.0251e-05, 4.1978e-03, 2.0855e-01, 7.6807e-02, 6.6607e-01,\n",
       "           3.4957e-02, 5.1268e-03, 6.4327e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0449, 0.0013, 0.0252, 0.2201, 0.1512, 0.4467, 0.0573, 0.0494, 0.0040]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0747, 0.0131, 0.0645, 0.1725, 0.1570, 0.3226, 0.0859, 0.0909, 0.0188]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0827, 0.0209, 0.0646, 0.1664, 0.1782, 0.2566, 0.1083, 0.0981, 0.0242]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0807, 0.0126, 0.0763, 0.1681, 0.1522, 0.2814, 0.1052, 0.1045, 0.0189]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0910, 0.0228, 0.0703, 0.1475, 0.1908, 0.2436, 0.1089, 0.0889, 0.0362]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0438, 0.0020, 0.0294, 0.1859, 0.1261, 0.4987, 0.0564, 0.0548, 0.0029]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0728, 0.0192, 0.0687, 0.1279, 0.1931, 0.2781, 0.1291, 0.0869, 0.0243]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0414, 0.0030, 0.0459, 0.1436, 0.1881, 0.4299, 0.0942, 0.0483, 0.0055]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0519, 0.0033, 0.0508, 0.1393, 0.1925, 0.4082, 0.0668, 0.0798, 0.0074]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.8290e-03, 5.5726e-06, 3.1003e-03, 1.0511e-01, 8.1381e-02, 7.9835e-01,\n",
       "           6.3338e-03, 3.8572e-03, 2.7878e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0601, 0.0074, 0.0593, 0.1523, 0.1959, 0.3633, 0.0945, 0.0555, 0.0117]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0726, 0.0114, 0.0637, 0.1558, 0.1436, 0.3409, 0.0891, 0.1055, 0.0174]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0873, 0.0243, 0.0857, 0.1418, 0.1802, 0.2543, 0.0916, 0.1006, 0.0343]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[5.4432e-03, 3.1443e-06, 1.3684e-03, 3.3509e-02, 2.4225e-02, 9.2877e-01,\n",
       "           4.5620e-03, 2.1069e-03, 1.3580e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.7651e-02, 4.8778e-04, 2.5753e-02, 1.4609e-01, 1.1653e-01, 6.3369e-01,\n",
       "           4.1731e-02, 1.7033e-02, 1.0313e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0428, 0.0027, 0.0305, 0.1323, 0.1782, 0.4999, 0.0663, 0.0436, 0.0037]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0652, 0.0049, 0.0672, 0.1455, 0.2048, 0.3686, 0.0772, 0.0586, 0.0080]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0716, 0.0075, 0.0725, 0.1613, 0.1747, 0.3259, 0.0804, 0.0916, 0.0146]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0857, 0.0205, 0.0808, 0.1478, 0.1823, 0.2649, 0.1076, 0.0818, 0.0286]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0615, 0.0104, 0.0843, 0.1266, 0.2101, 0.3197, 0.1021, 0.0679, 0.0174]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0896, 0.0287, 0.0818, 0.1375, 0.1690, 0.2618, 0.1067, 0.0910, 0.0339]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.4251e-03, 6.7285e-07, 1.2397e-03, 6.1020e-02, 3.8445e-02, 8.9126e-01,\n",
       "           4.0551e-03, 1.5471e-03, 6.2119e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0462, 0.0034, 0.0555, 0.1592, 0.1651, 0.4412, 0.0699, 0.0523, 0.0072]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.7823e-03, 1.2831e-06, 9.3926e-04, 6.5138e-02, 3.5684e-02, 8.9302e-01,\n",
       "           1.7761e-03, 1.6490e-03, 5.0643e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0394, 0.0007, 0.0340, 0.1188, 0.1455, 0.5704, 0.0527, 0.0362, 0.0022]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[4.3101e-04, 1.2084e-07, 1.4915e-04, 2.3956e-02, 1.6401e-02, 9.5714e-01,\n",
       "           1.7196e-03, 1.9850e-04, 4.6423e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0475, 0.0025, 0.0407, 0.1173, 0.1317, 0.5566, 0.0617, 0.0385, 0.0036]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[2.1328e-04, 1.4467e-08, 6.4575e-05, 9.2537e-03, 6.8090e-03, 9.8306e-01,\n",
       "           5.1251e-04, 8.3288e-05, 9.5502e-08]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0473, 0.0040, 0.0426, 0.1189, 0.1858, 0.4644, 0.0819, 0.0473, 0.0079]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0819, 0.0062, 0.0463, 0.1274, 0.1874, 0.3756, 0.1071, 0.0564, 0.0117]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0872, 0.0256, 0.0828, 0.1201, 0.1657, 0.2829, 0.1147, 0.0922, 0.0288]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0624, 0.0050, 0.0574, 0.1241, 0.1905, 0.3693, 0.1118, 0.0671, 0.0123]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0926, 0.0270, 0.0936, 0.1188, 0.1702, 0.2624, 0.1178, 0.0842, 0.0334]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0573, 0.0041, 0.0429, 0.1181, 0.2143, 0.4228, 0.0806, 0.0518, 0.0081]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.6853e-02, 5.6298e-04, 1.5784e-02, 9.1545e-02, 8.6926e-02, 7.3007e-01,\n",
       "           4.0239e-02, 1.7176e-02, 8.4273e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0900, 0.0081, 0.0639, 0.1238, 0.1747, 0.3919, 0.0763, 0.0585, 0.0128]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0354, 0.0015, 0.0308, 0.0847, 0.1599, 0.5967, 0.0559, 0.0333, 0.0020]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0966, 0.0293, 0.0932, 0.1156, 0.1698, 0.2276, 0.1187, 0.1082, 0.0410]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0264, 0.0010, 0.0198, 0.1171, 0.1896, 0.5609, 0.0596, 0.0238, 0.0018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0621, 0.0039, 0.0553, 0.0914, 0.2162, 0.4195, 0.0761, 0.0675, 0.0081]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0844, 0.0139, 0.0769, 0.1191, 0.2203, 0.2753, 0.1077, 0.0797, 0.0227]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0823, 0.0142, 0.0801, 0.1173, 0.2054, 0.3069, 0.0908, 0.0799, 0.0232]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0401, 0.0032, 0.0538, 0.1006, 0.2025, 0.4880, 0.0681, 0.0384, 0.0053]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0616, 0.0052, 0.0500, 0.0940, 0.1745, 0.4974, 0.0670, 0.0456, 0.0045]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0300, 0.0008, 0.0190, 0.0875, 0.2364, 0.5720, 0.0383, 0.0149, 0.0010]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0442, 0.0028, 0.0469, 0.1383, 0.1988, 0.4525, 0.0654, 0.0472, 0.0039]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0577, 0.0072, 0.0481, 0.1170, 0.2191, 0.4102, 0.0842, 0.0487, 0.0078]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0483, 0.0061, 0.0510, 0.1506, 0.1720, 0.4289, 0.0691, 0.0604, 0.0137]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.8162e-06, 2.2930e-12, 2.4271e-06, 7.3854e-04, 6.3580e-03, 9.9284e-01,\n",
       "           4.9737e-05, 7.2994e-06, 8.6266e-11]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0900, 0.0158, 0.0745, 0.1332, 0.1811, 0.2944, 0.0986, 0.0899, 0.0224]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0280, 0.0009, 0.0272, 0.0911, 0.2100, 0.5481, 0.0631, 0.0302, 0.0015]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0653, 0.0072, 0.0520, 0.1201, 0.2212, 0.3826, 0.0820, 0.0555, 0.0141]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0387, 0.0011, 0.0416, 0.1048, 0.2073, 0.5245, 0.0504, 0.0290, 0.0026]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0385, 0.0013, 0.0392, 0.0870, 0.1951, 0.5612, 0.0493, 0.0267, 0.0018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[5.9525e-03, 2.3720e-05, 4.3264e-03, 5.3099e-02, 1.7454e-01, 7.4670e-01,\n",
       "           1.1343e-02, 3.9583e-03, 6.0971e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0727, 0.0128, 0.0817, 0.1091, 0.1898, 0.3361, 0.0970, 0.0834, 0.0175]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0224, 0.0007, 0.0299, 0.1060, 0.1797, 0.5910, 0.0426, 0.0264, 0.0012]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0788, 0.0083, 0.0716, 0.1133, 0.1656, 0.3962, 0.0828, 0.0693, 0.0140]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0492, 0.0055, 0.0525, 0.1076, 0.2319, 0.3965, 0.0886, 0.0562, 0.0120]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[1.3127e-02, 1.9658e-04, 1.1524e-02, 1.3729e-01, 9.5579e-02, 7.0825e-01,\n",
       "           1.5768e-02, 1.7914e-02, 3.5064e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0640, 0.0061, 0.0541, 0.1266, 0.2086, 0.3989, 0.0905, 0.0429, 0.0083]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0554, 0.0026, 0.0346, 0.1478, 0.1811, 0.4774, 0.0481, 0.0496, 0.0034]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0683, 0.0113, 0.0666, 0.1368, 0.2092, 0.3226, 0.0850, 0.0800, 0.0202]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0600, 0.0046, 0.0578, 0.0987, 0.2086, 0.4085, 0.0789, 0.0706, 0.0123]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0534, 0.0050, 0.0486, 0.1256, 0.2325, 0.4091, 0.0851, 0.0357, 0.0050]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0465, 0.0007, 0.0284, 0.1410, 0.1566, 0.5308, 0.0583, 0.0360, 0.0018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0516, 0.0071, 0.0494, 0.1450, 0.2047, 0.4208, 0.0728, 0.0422, 0.0064]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0708, 0.0081, 0.0577, 0.1591, 0.1901, 0.3212, 0.1049, 0.0754, 0.0127]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.9246e-02, 4.0045e-04, 1.6510e-02, 1.3925e-01, 1.5192e-01, 6.2869e-01,\n",
       "           2.9120e-02, 1.3993e-02, 8.6685e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0427, 0.0012, 0.0278, 0.1234, 0.1351, 0.5840, 0.0495, 0.0344, 0.0018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0596, 0.0059, 0.0555, 0.1270, 0.2159, 0.3922, 0.0878, 0.0470, 0.0091]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0744, 0.0061, 0.0632, 0.1468, 0.2060, 0.3316, 0.0879, 0.0701, 0.0140]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0734, 0.0030, 0.0536, 0.1711, 0.1535, 0.4289, 0.0582, 0.0518, 0.0064]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1003, 0.0225, 0.0981, 0.1131, 0.1903, 0.2365, 0.1083, 0.0979, 0.0332]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0311, 0.0016, 0.0341, 0.1274, 0.1440, 0.5745, 0.0541, 0.0313, 0.0019]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0909, 0.0091, 0.0629, 0.1358, 0.1974, 0.3340, 0.0914, 0.0656, 0.0130]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.2209e-02, 7.0802e-05, 1.0742e-02, 1.1461e-01, 1.0202e-01, 7.2496e-01,\n",
       "           2.8516e-02, 6.6424e-03, 2.2536e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0625, 0.0098, 0.0788, 0.1307, 0.1963, 0.3609, 0.0744, 0.0705, 0.0160]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0351, 0.0017, 0.0331, 0.1567, 0.1640, 0.5482, 0.0387, 0.0207, 0.0018]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0960, 0.0295, 0.1042, 0.1177, 0.1644, 0.2488, 0.1003, 0.0975, 0.0416]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0891, 0.0189, 0.0914, 0.1362, 0.1746, 0.2815, 0.0900, 0.0899, 0.0284]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0768, 0.0055, 0.0714, 0.1610, 0.1315, 0.3973, 0.0687, 0.0794, 0.0084]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.9307e-03, 3.2678e-06, 5.2637e-03, 7.3315e-02, 4.7274e-02, 8.5575e-01,\n",
       "           8.6316e-03, 5.7878e-03, 4.3043e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0658, 0.0055, 0.0727, 0.1459, 0.1771, 0.3839, 0.0755, 0.0639, 0.0096]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0791, 0.0131, 0.0765, 0.1558, 0.1660, 0.2916, 0.0997, 0.0957, 0.0225]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1007, 0.0261, 0.0981, 0.1229, 0.1636, 0.2330, 0.1184, 0.1050, 0.0321]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0321, 0.0014, 0.0415, 0.1342, 0.1877, 0.4849, 0.0730, 0.0416, 0.0035]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0909, 0.0283, 0.0978, 0.1340, 0.1710, 0.2381, 0.1125, 0.0966, 0.0308]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.1027, 0.0143, 0.0894, 0.1490, 0.1601, 0.2840, 0.0923, 0.0859, 0.0223]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1001, 0.0118, 0.0957, 0.1332, 0.1661, 0.2885, 0.1059, 0.0799, 0.0188]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.2112e-03, 5.9346e-06, 2.4503e-03, 5.8930e-02, 2.6802e-02, 8.9852e-01,\n",
       "           8.7037e-03, 1.3715e-03, 8.1023e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0712, 0.0056, 0.0546, 0.1786, 0.1697, 0.3722, 0.0782, 0.0605, 0.0095]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0885, 0.0193, 0.0886, 0.1283, 0.1931, 0.2631, 0.1177, 0.0772, 0.0241]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0600, 0.0036, 0.0437, 0.1582, 0.1400, 0.4391, 0.0758, 0.0713, 0.0081]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0888, 0.0280, 0.1025, 0.1346, 0.1739, 0.2109, 0.1232, 0.1061, 0.0321]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.6727e-05, 2.9860e-10, 1.0854e-04, 4.5540e-02, 1.3337e-02, 9.4032e-01,\n",
       "           6.3379e-04, 3.0102e-05, 6.6746e-09]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1036, 0.0473, 0.1112, 0.1233, 0.1517, 0.1913, 0.1136, 0.1024, 0.0556]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0968, 0.0359, 0.1096, 0.1189, 0.1605, 0.2083, 0.1139, 0.1106, 0.0454]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0912, 0.0229, 0.1013, 0.1318, 0.1819, 0.2390, 0.1172, 0.0905, 0.0242]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0721, 0.0104, 0.0794, 0.1469, 0.1671, 0.3230, 0.0807, 0.0999, 0.0206]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1011, 0.0197, 0.0802, 0.1453, 0.1499, 0.2951, 0.1033, 0.0805, 0.0249]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0901, 0.0145, 0.0810, 0.1389, 0.1589, 0.2918, 0.0933, 0.1037, 0.0278]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0913, 0.0356, 0.1094, 0.1257, 0.1709, 0.1959, 0.1206, 0.1080, 0.0427]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0734, 0.0117, 0.0750, 0.1512, 0.1582, 0.3462, 0.0984, 0.0713, 0.0146]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0655, 0.0139, 0.0806, 0.1282, 0.1662, 0.3072, 0.1277, 0.0907, 0.0201]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1038, 0.0335, 0.0986, 0.1334, 0.1564, 0.2097, 0.1107, 0.1136, 0.0402]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0951, 0.0281, 0.1109, 0.1243, 0.1600, 0.2168, 0.1158, 0.1031, 0.0461]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0553, 0.0044, 0.0591, 0.1814, 0.1348, 0.3988, 0.0996, 0.0586, 0.0081]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0880, 0.0231, 0.0907, 0.1390, 0.1798, 0.2378, 0.1350, 0.0817, 0.0250]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0967, 0.0374, 0.0994, 0.1208, 0.1854, 0.1838, 0.1253, 0.1053, 0.0459]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1101, 0.0517, 0.0996, 0.1235, 0.1525, 0.1713, 0.1191, 0.1157, 0.0564]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0913, 0.0354, 0.0927, 0.1192, 0.2079, 0.1921, 0.1282, 0.0938, 0.0394]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0795, 0.0108, 0.1096, 0.1282, 0.1859, 0.2479, 0.1180, 0.1004, 0.0198]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1143, 0.0238, 0.0914, 0.1548, 0.1670, 0.2165, 0.1091, 0.0935, 0.0297]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0908, 0.0334, 0.0983, 0.1245, 0.1749, 0.2033, 0.1228, 0.1112, 0.0409]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0937, 0.0329, 0.0970, 0.1136, 0.1829, 0.2139, 0.1219, 0.0993, 0.0448]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[1.4368e-02, 1.8603e-04, 2.8430e-02, 9.5073e-02, 1.9854e-01, 5.9114e-01,\n",
       "           4.7224e-02, 2.4552e-02, 4.8126e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.3616e-02, 2.1173e-04, 2.0069e-02, 9.8120e-02, 1.3305e-01, 6.8159e-01,\n",
       "           2.9999e-02, 2.2339e-02, 1.0126e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0831, 0.0049, 0.0739, 0.1424, 0.1618, 0.3354, 0.0880, 0.0999, 0.0106]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0335, 0.0017, 0.0505, 0.1622, 0.2086, 0.4059, 0.0899, 0.0447, 0.0029]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[8.1270e-03, 1.4251e-05, 6.2418e-03, 7.6829e-02, 1.4013e-01, 7.4336e-01,\n",
       "           2.0566e-02, 4.6611e-03, 7.9827e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0672, 0.0077, 0.0719, 0.1244, 0.1988, 0.3303, 0.1075, 0.0769, 0.0153]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0858, 0.0190, 0.0893, 0.1184, 0.1784, 0.2515, 0.1311, 0.0982, 0.0283]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0421, 0.0016, 0.0592, 0.1086, 0.2254, 0.4138, 0.0925, 0.0523, 0.0044]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0897, 0.0203, 0.0904, 0.1367, 0.1934, 0.2264, 0.1084, 0.1103, 0.0243]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.5221e-03, 1.0784e-06, 2.6836e-03, 3.5026e-02, 2.5537e-02, 9.2305e-01,\n",
       "           9.7508e-03, 2.4187e-03, 8.3190e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0386, 0.0014, 0.0347, 0.1523, 0.1562, 0.5108, 0.0676, 0.0360, 0.0023]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0957, 0.0277, 0.0949, 0.1212, 0.1625, 0.2000, 0.1339, 0.1227, 0.0415]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[1.6040e-02, 4.0320e-04, 2.5700e-02, 9.1616e-02, 1.6311e-01, 5.9462e-01,\n",
       "           7.7645e-02, 2.9605e-02, 1.2599e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0900, 0.0125, 0.0775, 0.1324, 0.1604, 0.3011, 0.1121, 0.0933, 0.0206]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0282, 0.0010, 0.0385, 0.1336, 0.1744, 0.4848, 0.0900, 0.0471, 0.0024]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0881, 0.0237, 0.0991, 0.1056, 0.1717, 0.2506, 0.1152, 0.1092, 0.0366]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0942, 0.0208, 0.0868, 0.1377, 0.1597, 0.2599, 0.1129, 0.0997, 0.0283]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0523, 0.0061, 0.0636, 0.1073, 0.1848, 0.3957, 0.1132, 0.0687, 0.0084]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0813, 0.0218, 0.0834, 0.1176, 0.1827, 0.2705, 0.1263, 0.0924, 0.0240]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[2.2920e-03, 7.0075e-07, 1.1610e-03, 3.4530e-02, 2.3427e-02, 9.3137e-01,\n",
       "           5.5792e-03, 1.6311e-03, 1.3043e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0949, 0.0228, 0.0876, 0.1214, 0.1609, 0.2543, 0.1225, 0.1046, 0.0309]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.8648e-04, 1.3539e-08, 2.4567e-04, 8.1128e-03, 5.7829e-03, 9.8395e-01,\n",
       "           1.2591e-03, 4.6725e-04, 1.4965e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0497, 0.0077, 0.0768, 0.0965, 0.2390, 0.3268, 0.1116, 0.0773, 0.0147]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0749, 0.0098, 0.0833, 0.0913, 0.2275, 0.2995, 0.1207, 0.0785, 0.0145]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0907, 0.0283, 0.1041, 0.1088, 0.1709, 0.2404, 0.1229, 0.1008, 0.0331]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[8.8445e-04, 9.0254e-08, 4.5316e-04, 9.0519e-03, 1.2230e-02, 9.7114e-01,\n",
       "           5.1886e-03, 1.0500e-03, 9.6520e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0978, 0.0341, 0.1009, 0.1137, 0.1774, 0.1842, 0.1268, 0.1181, 0.0472]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0716, 0.0060, 0.0622, 0.1219, 0.1873, 0.3514, 0.1098, 0.0789, 0.0110]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[1.1165e-03, 3.5691e-07, 1.0297e-03, 4.1795e-02, 5.3991e-02, 8.8261e-01,\n",
       "           1.7276e-02, 2.1749e-03, 1.6193e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0924, 0.0259, 0.0911, 0.1146, 0.1910, 0.2289, 0.1306, 0.0970, 0.0286]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0771, 0.0098, 0.0710, 0.1312, 0.1606, 0.3237, 0.1181, 0.0898, 0.0187]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1029, 0.0215, 0.0837, 0.0926, 0.2343, 0.2124, 0.1314, 0.0925, 0.0288]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0860, 0.0093, 0.0734, 0.1401, 0.1603, 0.3204, 0.1033, 0.0952, 0.0121]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.6616e-02, 1.8077e-04, 1.9768e-02, 1.0641e-01, 5.5606e-02, 6.9727e-01,\n",
       "           5.7520e-02, 2.6165e-02, 4.6786e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0319, 0.0011, 0.0308, 0.1040, 0.1343, 0.5680, 0.0968, 0.0310, 0.0022]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0931, 0.0218, 0.0888, 0.1192, 0.1627, 0.2609, 0.1367, 0.0905, 0.0264]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0772, 0.0116, 0.0766, 0.1201, 0.2022, 0.2728, 0.1182, 0.1019, 0.0194]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0651, 0.0070, 0.0716, 0.0984, 0.2632, 0.2868, 0.1346, 0.0631, 0.0101]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.2308e-02, 5.8348e-05, 7.9575e-03, 9.3742e-02, 1.3380e-01, 6.8125e-01,\n",
       "           5.3034e-02, 1.7641e-02, 2.1243e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0871, 0.0146, 0.0689, 0.1200, 0.2116, 0.3092, 0.1024, 0.0725, 0.0137]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0826, 0.0184, 0.0968, 0.1009, 0.2198, 0.2225, 0.1277, 0.1041, 0.0273]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0573, 0.0052, 0.0597, 0.1242, 0.1557, 0.4121, 0.0953, 0.0803, 0.0102]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.7785e-02, 3.0777e-04, 1.5647e-02, 1.0680e-01, 1.0254e-01, 6.4832e-01,\n",
       "           7.3165e-02, 3.4354e-02, 1.0917e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1065, 0.0250, 0.0906, 0.1138, 0.1608, 0.2316, 0.1201, 0.1148, 0.0366]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1114, 0.0280, 0.0837, 0.1219, 0.1617, 0.2195, 0.1243, 0.1141, 0.0353]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0893, 0.0089, 0.0637, 0.1392, 0.1666, 0.3086, 0.1081, 0.0980, 0.0176]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0280, 0.0007, 0.0249, 0.1260, 0.1733, 0.5370, 0.0656, 0.0428, 0.0015]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0679, 0.0062, 0.0675, 0.1069, 0.1693, 0.3913, 0.0990, 0.0805, 0.0115]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0813, 0.0158, 0.0756, 0.1159, 0.1934, 0.2754, 0.1223, 0.0981, 0.0222]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0833, 0.0204, 0.0826, 0.1153, 0.1840, 0.2727, 0.1225, 0.0910, 0.0283]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0997, 0.0264, 0.0904, 0.1211, 0.1681, 0.2302, 0.1060, 0.1126, 0.0455]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1008, 0.0277, 0.0948, 0.1017, 0.1758, 0.2188, 0.1246, 0.1187, 0.0371]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0946, 0.0106, 0.0807, 0.1145, 0.1624, 0.3020, 0.1246, 0.0970, 0.0137]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[5.9159e-03, 3.1939e-05, 3.2650e-03, 4.4915e-02, 4.8543e-02, 8.6180e-01,\n",
       "           2.5486e-02, 9.9636e-03, 7.7341e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0866, 0.0078, 0.0879, 0.1106, 0.1666, 0.3190, 0.0988, 0.1074, 0.0153]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0966, 0.0297, 0.0966, 0.0951, 0.1782, 0.2379, 0.1281, 0.1068, 0.0308]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[7.6997e-03, 2.2290e-04, 1.2393e-02, 7.0858e-02, 1.3513e-01, 7.0835e-01,\n",
       "           4.6153e-02, 1.8424e-02, 7.6963e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0372, 0.0013, 0.0302, 0.1089, 0.1280, 0.5358, 0.1070, 0.0484, 0.0033]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0531, 0.0035, 0.0573, 0.0906, 0.2166, 0.3889, 0.0934, 0.0873, 0.0092]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0375, 0.0010, 0.0335, 0.0910, 0.1614, 0.5576, 0.0625, 0.0533, 0.0022]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0983, 0.0368, 0.0993, 0.1125, 0.1694, 0.2006, 0.1142, 0.1149, 0.0539]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0876, 0.0091, 0.0595, 0.1375, 0.1562, 0.3253, 0.1110, 0.1012, 0.0126]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0474, 0.0026, 0.0443, 0.1269, 0.1676, 0.4418, 0.0940, 0.0701, 0.0053]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[3.7353e-07, 5.7695e-15, 1.0336e-07, 2.8528e-04, 7.6066e-05, 9.9959e-01,\n",
       "           4.4816e-05, 1.5243e-06, 6.5039e-13]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0675, 0.0038, 0.0539, 0.1063, 0.1885, 0.3558, 0.1003, 0.1103, 0.0136]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0995, 0.0250, 0.0956, 0.1101, 0.1707, 0.2182, 0.1256, 0.1175, 0.0377]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0656, 0.0037, 0.0416, 0.1190, 0.1999, 0.3590, 0.1052, 0.0992, 0.0068]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0876, 0.0219, 0.0947, 0.1114, 0.1831, 0.2267, 0.1312, 0.1068, 0.0365]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0543, 0.0045, 0.0533, 0.1147, 0.1583, 0.4423, 0.0998, 0.0630, 0.0098]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.4268e-03, 4.6720e-07, 6.4393e-04, 4.8895e-02, 1.9255e-02, 9.1924e-01,\n",
       "           8.0745e-03, 2.4584e-03, 4.1139e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.6752e-03, 6.7114e-06, 3.1123e-03, 4.7285e-02, 5.0628e-02, 8.6070e-01,\n",
       "           2.1109e-02, 1.4370e-02, 1.0898e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0575, 0.0054, 0.0569, 0.1321, 0.1611, 0.3555, 0.1199, 0.0991, 0.0126]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1105, 0.0285, 0.0935, 0.1228, 0.1536, 0.2125, 0.1295, 0.1104, 0.0388]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1043, 0.0389, 0.0991, 0.1172, 0.1491, 0.1947, 0.1284, 0.1178, 0.0504]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0810, 0.0213, 0.0881, 0.1213, 0.1952, 0.2409, 0.1332, 0.0983, 0.0207]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0508, 0.0034, 0.0536, 0.1153, 0.1663, 0.4315, 0.0991, 0.0717, 0.0082]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0593, 0.0042, 0.0640, 0.1269, 0.1498, 0.4084, 0.1177, 0.0620, 0.0077]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0600, 0.0024, 0.0524, 0.1190, 0.1119, 0.4918, 0.0841, 0.0711, 0.0073]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0646, 0.0033, 0.0551, 0.1108, 0.1715, 0.4211, 0.1005, 0.0673, 0.0059]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0897, 0.0062, 0.0582, 0.1438, 0.1668, 0.3545, 0.0973, 0.0721, 0.0115]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0907, 0.0202, 0.0863, 0.1322, 0.1588, 0.2712, 0.1089, 0.1006, 0.0312]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0604, 0.0049, 0.0409, 0.1596, 0.1217, 0.4481, 0.0850, 0.0711, 0.0083]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0872, 0.0059, 0.0705, 0.1339, 0.1288, 0.3612, 0.1120, 0.0884, 0.0123]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0900, 0.0170, 0.0906, 0.1354, 0.1851, 0.2276, 0.1156, 0.1070, 0.0317]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0542, 0.0032, 0.0503, 0.1350, 0.1460, 0.4586, 0.0889, 0.0590, 0.0050]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[1.0811e-02, 5.4054e-05, 9.3744e-03, 7.5009e-02, 4.6837e-02, 8.2909e-01,\n",
       "           2.0704e-02, 7.9453e-03, 1.7038e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0788, 0.0169, 0.0931, 0.1320, 0.1947, 0.2553, 0.1225, 0.0839, 0.0227]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[8.1149e-03, 3.7612e-05, 8.5657e-03, 1.0992e-01, 7.6846e-02, 7.6137e-01,\n",
       "           2.7724e-02, 7.2835e-03, 1.4314e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0474, 0.0035, 0.0610, 0.1263, 0.2177, 0.3624, 0.1013, 0.0722, 0.0082]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0458, 0.0020, 0.0538, 0.0997, 0.1549, 0.4961, 0.0810, 0.0591, 0.0076]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0326, 0.0017, 0.0421, 0.1260, 0.1518, 0.5121, 0.0867, 0.0435, 0.0034]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0580, 0.0022, 0.0523, 0.1693, 0.1790, 0.3799, 0.0882, 0.0662, 0.0049]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0868, 0.0212, 0.0971, 0.1320, 0.1741, 0.2455, 0.1187, 0.0947, 0.0299]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0470, 0.0068, 0.0688, 0.1024, 0.2194, 0.3640, 0.1191, 0.0608, 0.0117]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0840, 0.0206, 0.1038, 0.1120, 0.1990, 0.2355, 0.1094, 0.1012, 0.0343]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.3623e-02, 2.0746e-04, 1.5912e-02, 1.2704e-01, 6.0358e-02, 7.0189e-01,\n",
       "           4.1678e-02, 2.8704e-02, 5.8630e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[4.8285e-02, 4.6788e-04, 2.7925e-02, 1.9006e-01, 1.2382e-01, 5.0009e-01,\n",
       "           7.7816e-02, 3.0545e-02, 9.9719e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0408, 0.0022, 0.0753, 0.1063, 0.2753, 0.3488, 0.0930, 0.0524, 0.0060]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0913, 0.0198, 0.0920, 0.1306, 0.1878, 0.2445, 0.1163, 0.0882, 0.0295]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[1.4708e-02, 9.7714e-05, 2.5191e-02, 1.0275e-01, 1.7510e-01, 5.9959e-01,\n",
       "           5.9874e-02, 2.2239e-02, 4.4758e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[1.7086e-02, 1.9330e-04, 2.2845e-02, 9.5299e-02, 1.4435e-01, 6.5512e-01,\n",
       "           4.5925e-02, 1.8714e-02, 4.6421e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0655, 0.0044, 0.0665, 0.1320, 0.1935, 0.3731, 0.0886, 0.0695, 0.0071]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0541, 0.0012, 0.0564, 0.1515, 0.1735, 0.4067, 0.0835, 0.0685, 0.0046]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0870, 0.0172, 0.1112, 0.1045, 0.2208, 0.2164, 0.1062, 0.1059, 0.0310]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0578, 0.0055, 0.0875, 0.1037, 0.2693, 0.2970, 0.1110, 0.0567, 0.0115]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.6911e-02, 2.1569e-04, 2.2580e-02, 1.0265e-01, 1.5388e-01, 6.3877e-01,\n",
       "           4.4006e-02, 2.0296e-02, 6.9228e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.0367e-02, 6.4999e-05, 2.0096e-02, 1.0162e-01, 1.6315e-01, 6.4748e-01,\n",
       "           4.4464e-02, 1.2581e-02, 1.7173e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0489, 0.0054, 0.0684, 0.1446, 0.2475, 0.3029, 0.1096, 0.0639, 0.0089]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0445, 0.0025, 0.0707, 0.1124, 0.2406, 0.3667, 0.0835, 0.0739, 0.0052]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0879, 0.0169, 0.0929, 0.1282, 0.2049, 0.2344, 0.1295, 0.0826, 0.0227]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1024, 0.0124, 0.0779, 0.1230, 0.2291, 0.2415, 0.1130, 0.0789, 0.0217]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[5.4176e-07, 2.2320e-14, 2.1612e-07, 2.2857e-03, 3.9561e-04, 9.9718e-01,\n",
       "           1.3615e-04, 9.0908e-07, 2.8579e-12]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0732, 0.0155, 0.0884, 0.1119, 0.2564, 0.2384, 0.1152, 0.0794, 0.0217]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0525, 0.0035, 0.0526, 0.1157, 0.2092, 0.3967, 0.1084, 0.0554, 0.0061]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0407, 0.0023, 0.0645, 0.1212, 0.2824, 0.3357, 0.0901, 0.0563, 0.0068]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0418, 0.0012, 0.0620, 0.1112, 0.2219, 0.4241, 0.0940, 0.0395, 0.0043]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0545, 0.0055, 0.0708, 0.1190, 0.2465, 0.3078, 0.1246, 0.0631, 0.0083]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0828, 0.0134, 0.0967, 0.1160, 0.2438, 0.2168, 0.0990, 0.1085, 0.0230]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0871, 0.0204, 0.1035, 0.1170, 0.1966, 0.2119, 0.1236, 0.1058, 0.0342]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[1.7175e-03, 5.0588e-07, 2.7210e-03, 4.2988e-02, 4.5778e-02, 8.9225e-01,\n",
       "           1.1728e-02, 2.8122e-03, 6.6120e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0505, 0.0036, 0.0699, 0.1168, 0.2406, 0.3397, 0.1062, 0.0640, 0.0086]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0294, 0.0023, 0.0603, 0.1146, 0.2229, 0.4158, 0.0976, 0.0507, 0.0063]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0694, 0.0092, 0.0997, 0.1049, 0.2453, 0.2497, 0.1277, 0.0772, 0.0169]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0679, 0.0097, 0.0766, 0.1200, 0.2186, 0.2785, 0.1183, 0.0917, 0.0188]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0737, 0.0147, 0.0915, 0.1195, 0.2124, 0.2506, 0.1245, 0.0893, 0.0238]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[9.3109e-03, 4.9946e-05, 1.4204e-02, 1.0392e-01, 1.2136e-01, 6.8483e-01,\n",
       "           4.8451e-02, 1.7622e-02, 2.4035e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0623, 0.0041, 0.0659, 0.1426, 0.1763, 0.3341, 0.1279, 0.0778, 0.0091]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0646, 0.0041, 0.0729, 0.1470, 0.2122, 0.3149, 0.0930, 0.0814, 0.0099]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.0691e-04, 7.3386e-08, 1.6676e-03, 5.7655e-02, 1.0786e-01, 8.1624e-01,\n",
       "           1.5558e-02, 7.1582e-04, 1.2455e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0895, 0.0204, 0.1057, 0.1211, 0.1971, 0.1972, 0.1341, 0.1077, 0.0272]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0706, 0.0077, 0.0819, 0.1185, 0.2045, 0.2999, 0.1314, 0.0702, 0.0153]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[3.3165e-02, 2.6503e-04, 2.5067e-02, 1.9928e-01, 1.0835e-01, 5.3649e-01,\n",
       "           6.9466e-02, 2.7250e-02, 6.7056e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.6869e-02, 3.1362e-04, 3.9930e-02, 1.2672e-01, 1.4428e-01, 5.2683e-01,\n",
       "           1.0357e-01, 3.0718e-02, 7.7290e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.5203e-07, 4.8981e-16, 5.2992e-08, 3.4080e-03, 2.9636e-04, 9.9627e-01,\n",
       "           2.4790e-05, 1.6476e-07, 1.5931e-13]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[6.2410e-04, 1.1237e-06, 2.4186e-03, 7.8492e-02, 1.3182e-01, 7.6124e-01,\n",
       "           2.4108e-02, 1.2977e-03, 4.4133e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0636, 0.0087, 0.0857, 0.1317, 0.2155, 0.2617, 0.1243, 0.0929, 0.0159]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0927, 0.0154, 0.0907, 0.1137, 0.2110, 0.2354, 0.1344, 0.0873, 0.0193]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0550, 0.0027, 0.0760, 0.1145, 0.2386, 0.3446, 0.0991, 0.0644, 0.0051]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0755, 0.0078, 0.0773, 0.1164, 0.2363, 0.2573, 0.1337, 0.0836, 0.0120]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0485, 0.0035, 0.0603, 0.0942, 0.2802, 0.3142, 0.1328, 0.0603, 0.0060]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0515, 0.0037, 0.0771, 0.1538, 0.2065, 0.3104, 0.1042, 0.0837, 0.0090]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0688, 0.0095, 0.0857, 0.1257, 0.2455, 0.2429, 0.1154, 0.0874, 0.0192]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0474, 0.0023, 0.0540, 0.1004, 0.2744, 0.3492, 0.1047, 0.0635, 0.0041]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.5990e-04, 2.3059e-08, 7.0870e-04, 2.7269e-02, 3.5484e-02, 9.2689e-01,\n",
       "           8.7109e-03, 5.7417e-04, 3.1722e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0512, 0.0041, 0.0684, 0.1127, 0.2463, 0.3206, 0.1209, 0.0691, 0.0067]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[2.7664e-02, 2.4165e-04, 1.8883e-02, 1.5936e-01, 1.8246e-01, 4.8703e-01,\n",
       "           6.8008e-02, 5.5708e-02, 6.3770e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0802, 0.0162, 0.0864, 0.0907, 0.3034, 0.1775, 0.1420, 0.0856, 0.0180]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0730, 0.0091, 0.0953, 0.1072, 0.2929, 0.2063, 0.1137, 0.0899, 0.0126]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0925, 0.0307, 0.1038, 0.1072, 0.2107, 0.1792, 0.1328, 0.1081, 0.0351]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1041, 0.0224, 0.1001, 0.1221, 0.2127, 0.1781, 0.1244, 0.1015, 0.0345]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0674, 0.0051, 0.0873, 0.1222, 0.2626, 0.2407, 0.1150, 0.0898, 0.0099]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0400, 0.0021, 0.0499, 0.1202, 0.2565, 0.3433, 0.1190, 0.0637, 0.0052]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0743, 0.0209, 0.1102, 0.0890, 0.2707, 0.1765, 0.1153, 0.1107, 0.0322]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0525, 0.0051, 0.0873, 0.0740, 0.4145, 0.1572, 0.1152, 0.0845, 0.0096]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0995, 0.0065, 0.0819, 0.1037, 0.2572, 0.2027, 0.1146, 0.1229, 0.0109]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1044, 0.0443, 0.1151, 0.1025, 0.1870, 0.1543, 0.1227, 0.1174, 0.0524]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1008, 0.0392, 0.1028, 0.1133, 0.1899, 0.1473, 0.1259, 0.1319, 0.0489]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.2144e-02, 9.3604e-05, 3.2464e-02, 1.0779e-01, 2.8476e-01, 3.6789e-01,\n",
       "           9.0771e-02, 9.3553e-02, 5.2131e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0799, 0.0221, 0.1025, 0.1063, 0.2586, 0.1704, 0.1281, 0.1066, 0.0254]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1139, 0.0308, 0.1086, 0.1024, 0.2047, 0.1524, 0.1369, 0.1150, 0.0352]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1013, 0.0247, 0.1003, 0.0941, 0.2439, 0.1566, 0.1228, 0.1185, 0.0378]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1052, 0.0227, 0.1109, 0.1034, 0.2232, 0.1575, 0.1170, 0.1232, 0.0370]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1076, 0.0342, 0.1073, 0.1022, 0.2175, 0.1379, 0.1468, 0.1081, 0.0386]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1300, 0.0199, 0.0981, 0.1081, 0.2442, 0.1508, 0.1144, 0.1129, 0.0217]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0982, 0.0401, 0.1048, 0.0976, 0.2231, 0.1396, 0.1315, 0.1162, 0.0489]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1020, 0.0351, 0.1094, 0.0973, 0.1898, 0.1650, 0.1243, 0.1286, 0.0486]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0715, 0.0044, 0.0771, 0.0924, 0.3027, 0.2382, 0.1270, 0.0796, 0.0071]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1091, 0.0262, 0.0895, 0.1027, 0.2236, 0.1629, 0.1305, 0.1253, 0.0303]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0860, 0.0165, 0.0950, 0.0920, 0.2505, 0.1919, 0.1283, 0.1094, 0.0305]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.1473e-02, 3.6097e-04, 2.5544e-02, 6.2497e-02, 3.9972e-01, 3.4227e-01,\n",
       "           9.3792e-02, 4.2964e-02, 1.3820e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1023, 0.0287, 0.0897, 0.1129, 0.2052, 0.1818, 0.1316, 0.1136, 0.0341]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0788, 0.0116, 0.0873, 0.0886, 0.3048, 0.1936, 0.1345, 0.0851, 0.0156]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0820, 0.0104, 0.0971, 0.1084, 0.2319, 0.2197, 0.1354, 0.1010, 0.0139]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[2.7931e-03, 7.7134e-07, 1.9165e-03, 9.4313e-02, 1.9546e-01, 6.4798e-01,\n",
       "           4.5701e-02, 1.1830e-02, 1.6143e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1074, 0.0388, 0.0999, 0.0953, 0.2073, 0.1503, 0.1299, 0.1249, 0.0462]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.9926e-03, 8.9203e-07, 6.4528e-03, 6.8655e-02, 3.0564e-01, 5.5360e-01,\n",
       "           5.0974e-02, 1.1681e-02, 1.0795e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1199, 0.0207, 0.1091, 0.1056, 0.2126, 0.1614, 0.1268, 0.1176, 0.0263]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0859, 0.0060, 0.0896, 0.0936, 0.3138, 0.1739, 0.1177, 0.1087, 0.0109]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0647, 0.0073, 0.0857, 0.0734, 0.3632, 0.1645, 0.1277, 0.1008, 0.0126]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[5.1832e-03, 3.8668e-06, 8.0238e-03, 1.0945e-01, 2.0991e-01, 6.0686e-01,\n",
       "           4.2355e-02, 1.8199e-02, 1.0463e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0447, 0.0012, 0.0564, 0.0799, 0.2565, 0.3989, 0.1116, 0.0476, 0.0033]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0910, 0.0345, 0.1097, 0.1133, 0.1781, 0.1864, 0.1197, 0.1198, 0.0475]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1041, 0.0175, 0.1058, 0.0966, 0.2018, 0.1944, 0.1205, 0.1277, 0.0316]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0404, 0.0010, 0.0326, 0.1266, 0.2324, 0.4058, 0.0946, 0.0639, 0.0027]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0859, 0.0058, 0.1056, 0.0881, 0.2488, 0.2574, 0.1185, 0.0781, 0.0119]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0620, 0.0031, 0.0453, 0.1210, 0.2414, 0.3461, 0.1220, 0.0543, 0.0049]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.5385e-03, 3.2538e-06, 2.7868e-03, 8.8315e-02, 8.8349e-02, 7.8382e-01,\n",
       "           2.5610e-02, 7.5539e-03, 2.2208e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1083, 0.0129, 0.1104, 0.0986, 0.2079, 0.2245, 0.1277, 0.0889, 0.0209]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0973, 0.0081, 0.0951, 0.1134, 0.2204, 0.2235, 0.1156, 0.1087, 0.0180]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0529, 0.0042, 0.0698, 0.1448, 0.2025, 0.3266, 0.1106, 0.0811, 0.0076]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1059, 0.0296, 0.1001, 0.1185, 0.1698, 0.2046, 0.1193, 0.1103, 0.0420]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0612, 0.0056, 0.0899, 0.1213, 0.2204, 0.3134, 0.1000, 0.0783, 0.0100]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.5863e-02, 9.5941e-05, 1.2847e-02, 1.1690e-01, 8.6257e-02, 7.0125e-01,\n",
       "           3.7886e-02, 1.8558e-02, 3.5094e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[1.8516e-02, 4.6675e-04, 3.8391e-02, 1.1118e-01, 2.3426e-01, 4.9378e-01,\n",
       "           6.8653e-02, 3.3754e-02, 9.9404e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0427, 0.0010, 0.0415, 0.1075, 0.2132, 0.4515, 0.0851, 0.0543, 0.0031]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0639, 0.0039, 0.0647, 0.1084, 0.2331, 0.3476, 0.1100, 0.0619, 0.0065]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0759, 0.0072, 0.0843, 0.1186, 0.1784, 0.3123, 0.1105, 0.0979, 0.0148]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0669, 0.0050, 0.0819, 0.1149, 0.2157, 0.3069, 0.1226, 0.0788, 0.0072]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[9.8415e-03, 2.4956e-05, 8.3376e-03, 1.1613e-01, 8.3731e-02, 7.1423e-01,\n",
       "           3.8752e-02, 2.8769e-02, 1.7953e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0775, 0.0138, 0.0885, 0.1363, 0.1913, 0.2534, 0.1087, 0.1061, 0.0244]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0258, 0.0007, 0.0360, 0.1198, 0.1083, 0.5989, 0.0657, 0.0434, 0.0013]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[3.5079e-03, 1.3220e-05, 5.1300e-03, 6.7412e-02, 4.2691e-02, 8.5199e-01,\n",
       "           2.3475e-02, 5.7262e-03, 5.6945e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[7.0444e-10, 7.1713e-18, 1.0387e-08, 6.2350e-05, 2.5873e-06, 9.9993e-01,\n",
       "           2.2927e-06, 2.7043e-08, 7.5059e-16]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.3887e-03, 2.1214e-06, 1.8871e-03, 5.4368e-02, 1.9224e-02, 9.0862e-01,\n",
       "           9.9172e-03, 3.5748e-03, 1.4472e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[4.0677e-03, 6.5503e-06, 2.6923e-03, 1.0706e-01, 3.2269e-02, 8.3219e-01,\n",
       "           1.5061e-02, 6.6265e-03, 3.4436e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[1.0769e-02, 4.5637e-05, 1.3453e-02, 7.0605e-02, 8.9452e-02, 7.6650e-01,\n",
       "           3.0379e-02, 1.8569e-02, 2.3133e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0595, 0.0036, 0.0619, 0.1607, 0.1371, 0.3992, 0.0901, 0.0807, 0.0072]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0597, 0.0058, 0.0884, 0.1346, 0.1748, 0.3503, 0.0958, 0.0815, 0.0091]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0329, 0.0013, 0.0413, 0.1183, 0.1452, 0.5466, 0.0668, 0.0447, 0.0030]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.0311e-05, 2.2504e-10, 4.2295e-05, 3.0573e-02, 1.2043e-03, 9.6769e-01,\n",
       "           3.1589e-04, 1.5360e-04, 6.3623e-09]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.0998e-03, 3.3322e-07, 9.9497e-04, 3.7305e-02, 8.7372e-03, 9.3760e-01,\n",
       "           8.9852e-03, 4.2697e-03, 4.9726e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.4477e-02, 6.7981e-05, 1.1033e-02, 1.0739e-01, 8.0783e-02, 7.3643e-01,\n",
       "           3.5594e-02, 1.4048e-02, 1.7565e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[2.6062e-03, 8.7317e-06, 3.4537e-03, 1.1920e-01, 1.0175e-01, 7.5274e-01,\n",
       "           1.4403e-02, 5.8138e-03, 2.3115e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0956, 0.0177, 0.0891, 0.1390, 0.1702, 0.2504, 0.1185, 0.0962, 0.0231]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0878, 0.0184, 0.0819, 0.1199, 0.1863, 0.2860, 0.1082, 0.0877, 0.0239]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[1.3884e-02, 9.1714e-05, 1.4851e-02, 9.2978e-02, 8.9825e-02, 7.2477e-01,\n",
       "           3.2364e-02, 3.1019e-02, 2.2142e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0889, 0.0122, 0.0992, 0.1552, 0.1549, 0.2637, 0.1074, 0.0984, 0.0202]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0678, 0.0017, 0.0465, 0.1390, 0.1059, 0.4918, 0.0757, 0.0674, 0.0043]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0880, 0.0172, 0.0978, 0.1167, 0.1898, 0.2734, 0.1090, 0.0866, 0.0214]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0664, 0.0043, 0.0778, 0.1582, 0.1355, 0.3470, 0.1076, 0.0944, 0.0089]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[4.1102e-03, 3.6902e-06, 5.7054e-03, 8.4879e-02, 1.9997e-02, 8.6807e-01,\n",
       "           1.0963e-02, 6.2410e-03, 2.8610e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0467, 0.0044, 0.0728, 0.1476, 0.2165, 0.3461, 0.0963, 0.0620, 0.0076]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0260, 0.0005, 0.0236, 0.2170, 0.1107, 0.4953, 0.0757, 0.0503, 0.0009]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0760, 0.0071, 0.0692, 0.1618, 0.1886, 0.2763, 0.1071, 0.1006, 0.0133]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1049, 0.0353, 0.1085, 0.1148, 0.1838, 0.1859, 0.1180, 0.1115, 0.0372]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0989, 0.0049, 0.0919, 0.1223, 0.1992, 0.2821, 0.1006, 0.0903, 0.0099]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0418, 0.0011, 0.0343, 0.1372, 0.1247, 0.5458, 0.0694, 0.0424, 0.0033]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[6.0434e-04, 6.9120e-08, 4.9615e-04, 8.6754e-02, 7.7581e-03, 8.9701e-01,\n",
       "           4.2065e-03, 3.1731e-03, 1.3034e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0980, 0.0108, 0.1059, 0.1130, 0.2006, 0.2390, 0.1200, 0.0931, 0.0195]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1023, 0.0249, 0.1054, 0.1197, 0.1953, 0.1806, 0.1194, 0.1180, 0.0344]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.1065, 0.0245, 0.1171, 0.1052, 0.1876, 0.1903, 0.1243, 0.1069, 0.0377]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[2.2891e-03, 9.2138e-07, 2.2220e-03, 1.7685e-01, 3.5359e-02, 7.6637e-01,\n",
       "           1.3373e-02, 3.5212e-03, 6.4389e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1156, 0.0227, 0.1192, 0.1147, 0.1734, 0.1992, 0.1079, 0.1125, 0.0348]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.9055e-04, 3.5681e-08, 3.5296e-04, 6.6401e-02, 1.7277e-02, 9.1192e-01,\n",
       "           2.5999e-03, 1.1568e-03, 4.5870e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0923, 0.0104, 0.0904, 0.1401, 0.1626, 0.2781, 0.1101, 0.0914, 0.0246]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1119, 0.0166, 0.1344, 0.0987, 0.2165, 0.1741, 0.1091, 0.1057, 0.0330]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0905, 0.0119, 0.1102, 0.1103, 0.2200, 0.2196, 0.1201, 0.0980, 0.0195]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0974, 0.0174, 0.1123, 0.1072, 0.2046, 0.2004, 0.1306, 0.0987, 0.0314]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0977, 0.0253, 0.1059, 0.1207, 0.1875, 0.1938, 0.1097, 0.1193, 0.0401]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.4275e-05, 3.0579e-10, 1.2933e-05, 1.5366e-02, 1.3090e-03, 9.8279e-01,\n",
       "           4.5582e-04, 3.1928e-05, 5.5483e-09]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1012, 0.0064, 0.0806, 0.1239, 0.2296, 0.2703, 0.1006, 0.0756, 0.0118]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[3.0595e-02, 5.1301e-04, 2.4407e-02, 1.8251e-01, 1.0728e-01, 5.4869e-01,\n",
       "           7.7425e-02, 2.6856e-02, 1.7343e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0947, 0.0112, 0.1060, 0.1270, 0.2148, 0.2550, 0.1059, 0.0691, 0.0165]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0767, 0.0048, 0.0586, 0.1772, 0.1474, 0.3645, 0.0936, 0.0681, 0.0092]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[3.7302e-03, 1.2483e-05, 6.1699e-03, 1.2581e-01, 1.0991e-01, 7.2828e-01,\n",
       "           2.0612e-02, 5.4066e-03, 7.4213e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0926, 0.0286, 0.1057, 0.1244, 0.1925, 0.2050, 0.1274, 0.0901, 0.0337]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0476, 0.0011, 0.0357, 0.1753, 0.1493, 0.4538, 0.0736, 0.0596, 0.0040]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0615, 0.0030, 0.0590, 0.1332, 0.1977, 0.3816, 0.0933, 0.0634, 0.0075]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0745, 0.0038, 0.0582, 0.1569, 0.1946, 0.3484, 0.0922, 0.0655, 0.0060]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0393, 0.0008, 0.0313, 0.2029, 0.1268, 0.4891, 0.0557, 0.0510, 0.0033]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.8835e-05, 2.2652e-11, 1.2516e-05, 5.2833e-02, 1.7567e-03, 9.4496e-01,\n",
       "           3.6673e-04, 5.2643e-05, 2.9691e-10]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0285, 0.0005, 0.0215, 0.2284, 0.1090, 0.5140, 0.0655, 0.0308, 0.0017]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[4.4803e-03, 6.8495e-05, 5.3047e-03, 2.2135e-01, 6.2316e-02, 6.7630e-01,\n",
       "           1.9128e-02, 1.0881e-02, 1.7490e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0823, 0.0138, 0.0877, 0.1367, 0.1824, 0.2584, 0.1185, 0.0972, 0.0231]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1009, 0.0249, 0.1013, 0.1394, 0.1533, 0.2303, 0.1118, 0.1013, 0.0368]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0748, 0.0148, 0.0756, 0.1519, 0.1888, 0.2677, 0.1132, 0.0916, 0.0217]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0679, 0.0144, 0.0894, 0.1526, 0.1733, 0.2665, 0.1187, 0.0905, 0.0266]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[2.4722e-02, 5.6117e-04, 2.7263e-02, 1.6292e-01, 1.3630e-01, 5.7504e-01,\n",
       "           4.1107e-02, 3.0220e-02, 1.8711e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0790, 0.0100, 0.0847, 0.1648, 0.1829, 0.2798, 0.1026, 0.0837, 0.0125]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[2.1835e-02, 3.2765e-04, 1.8945e-02, 2.9743e-01, 9.6197e-02, 4.9233e-01,\n",
       "           4.5319e-02, 2.6783e-02, 8.3265e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0731, 0.0104, 0.0799, 0.1666, 0.1622, 0.3226, 0.0876, 0.0784, 0.0193]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[6.1646e-03, 4.6419e-05, 6.8653e-03, 2.6123e-01, 6.9545e-02, 6.2841e-01,\n",
       "           1.9535e-02, 8.0310e-03, 1.7041e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0602, 0.0071, 0.0730, 0.1485, 0.2006, 0.3394, 0.0886, 0.0674, 0.0150]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.8084e-02, 4.4121e-04, 3.1435e-02, 2.0229e-01, 1.5840e-01, 4.9253e-01,\n",
       "           5.1216e-02, 3.4356e-02, 1.2547e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0324, 0.0014, 0.0414, 0.1923, 0.1490, 0.4790, 0.0548, 0.0464, 0.0034]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.0323, 0.0014, 0.0271, 0.2367, 0.1668, 0.4393, 0.0581, 0.0350, 0.0032]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[3.8600e-03, 1.0620e-05, 4.4141e-03, 2.0484e-01, 5.5908e-02, 7.0997e-01,\n",
       "           1.2309e-02, 8.6411e-03, 4.3176e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[6.0688e-03, 6.5275e-05, 1.1643e-02, 1.7902e-01, 8.3932e-02, 6.6886e-01,\n",
       "           3.3561e-02, 1.6514e-02, 3.3803e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0412, 0.0015, 0.0502, 0.1829, 0.2399, 0.3693, 0.0632, 0.0467, 0.0053]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.2636e-02, 2.6852e-04, 1.2798e-02, 3.3461e-01, 1.2990e-01, 4.6446e-01,\n",
       "           2.1808e-02, 2.2880e-02, 6.3752e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.9411e-02, 3.5399e-04, 1.1088e-02, 2.2676e-01, 6.7245e-02, 6.0513e-01,\n",
       "           4.8413e-02, 2.0955e-02, 6.4775e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[1.8343e-03, 4.5441e-06, 3.7663e-03, 2.8216e-01, 2.1070e-02, 6.7757e-01,\n",
       "           9.7356e-03, 3.8480e-03, 9.9684e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0728, 0.0105, 0.0872, 0.1682, 0.1864, 0.2849, 0.0933, 0.0804, 0.0162]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0644, 0.0106, 0.0701, 0.1930, 0.1720, 0.2824, 0.0987, 0.0872, 0.0215]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.0478, 0.0026, 0.0502, 0.1787, 0.1921, 0.3732, 0.0896, 0.0601, 0.0057]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0566, 0.0056, 0.0639, 0.1912, 0.1543, 0.3559, 0.0910, 0.0718, 0.0098]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[2.0984e-02, 3.9326e-04, 2.9128e-02, 1.8745e-01, 1.5587e-01, 5.3281e-01,\n",
       "           5.0279e-02, 2.1983e-02, 1.0968e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0763, 0.0182, 0.0782, 0.1866, 0.1624, 0.2515, 0.1162, 0.0853, 0.0252]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[2.3975e-08, 8.5826e-17, 1.3355e-08, 3.6971e-02, 6.5444e-06, 9.6302e-01,\n",
       "           1.5335e-06, 7.1980e-08, 1.2645e-14]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0852, 0.0153, 0.0892, 0.1575, 0.1917, 0.2471, 0.1004, 0.0880, 0.0256]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[7.5030e-03, 6.3248e-05, 1.1026e-02, 1.8980e-01, 7.3889e-02, 6.6412e-01,\n",
       "           2.9785e-02, 2.3600e-02, 2.1140e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[1.1595e-04, 1.8085e-08, 9.5959e-05, 1.0947e-01, 1.1182e-02, 8.7767e-01,\n",
       "           1.2545e-03, 2.1418e-04, 6.6928e-08]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0770, 0.0061, 0.0607, 0.1781, 0.1608, 0.3532, 0.0801, 0.0736, 0.0104]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[4.4726e-04, 1.4753e-07, 9.9070e-04, 1.6566e-01, 1.4706e-02, 8.0544e-01,\n",
       "           1.0052e-02, 2.6990e-03, 2.6216e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[6.3584e-03, 2.0956e-05, 6.4765e-03, 2.1117e-01, 7.9289e-02, 6.5709e-01,\n",
       "           2.8121e-02, 1.1342e-02, 1.3634e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[9.4993e-04, 1.4701e-07, 9.3432e-04, 2.1226e-01, 1.5681e-02, 7.6726e-01,\n",
       "           2.1420e-03, 7.7323e-04, 8.5606e-07]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0800, 0.0063, 0.1000, 0.1383, 0.2353, 0.2372, 0.0949, 0.0929, 0.0151]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1103, 0.0313, 0.1097, 0.1252, 0.1997, 0.1782, 0.1139, 0.0931, 0.0386]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0674, 0.0024, 0.0701, 0.1442, 0.2412, 0.3390, 0.0799, 0.0502, 0.0055]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1084, 0.0321, 0.1118, 0.1134, 0.1867, 0.1789, 0.1122, 0.1115, 0.0450]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[5.0090e-03, 1.0226e-05, 4.5788e-03, 1.3396e-01, 4.4911e-02, 7.8960e-01,\n",
       "           1.7192e-02, 4.6910e-03, 4.8637e-05]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1116, 0.0213, 0.1091, 0.1105, 0.2228, 0.1866, 0.1214, 0.0901, 0.0266]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[1.0156e-02, 1.5859e-05, 8.4047e-03, 2.3805e-01, 1.0142e-01, 6.0195e-01,\n",
       "           2.3603e-02, 1.6301e-02, 1.0082e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1142, 0.0407, 0.1081, 0.1129, 0.1899, 0.1655, 0.1123, 0.1082, 0.0481]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0969, 0.0257, 0.0933, 0.1391, 0.1658, 0.2187, 0.1135, 0.1085, 0.0385]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[1.6885e-02, 8.0813e-05, 1.1198e-02, 2.2169e-01, 1.4521e-01, 5.3291e-01,\n",
       "           5.2568e-02, 1.9218e-02, 2.4215e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[0.1308, 0.0453, 0.1123, 0.1042, 0.1874, 0.1430, 0.1096, 0.1059, 0.0614]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1.]])),\n",
       " (tensor([[3.7562e-02, 4.0708e-04, 2.5219e-02, 1.6415e-01, 1.0293e-01, 5.9702e-01,\n",
       "           4.4986e-02, 2.6374e-02, 1.3527e-03]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[1.6135e-02, 1.1230e-04, 9.9799e-03, 1.9414e-01, 3.9284e-02, 6.9766e-01,\n",
       "           2.8173e-02, 1.4284e-02, 2.2789e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[8.7449e-05, 1.0089e-09, 6.0170e-05, 4.6628e-02, 3.7353e-03, 9.4876e-01,\n",
       "           5.8848e-04, 1.4144e-04, 6.8248e-08]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0990, 0.0210, 0.1035, 0.1240, 0.2146, 0.1947, 0.1051, 0.1018, 0.0364]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[2.0682e-02, 1.5268e-04, 1.6666e-02, 2.2732e-01, 8.4266e-02, 5.7524e-01,\n",
       "           3.9840e-02, 3.5054e-02, 7.7801e-04]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1152, 0.0510, 0.1121, 0.1078, 0.1682, 0.1541, 0.1177, 0.1125, 0.0612]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0787, 0.0067, 0.0843, 0.1309, 0.2153, 0.2919, 0.1072, 0.0717, 0.0135]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.1095, 0.0217, 0.0939, 0.1220, 0.1810, 0.2245, 0.1176, 0.0974, 0.0325]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[1.6393e-08, 2.0252e-17, 1.0312e-08, 4.4779e-03, 6.8078e-06, 9.9551e-01,\n",
       "           4.5188e-06, 8.9195e-08, 7.5604e-15]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[7.9107e-04, 2.9215e-07, 1.0523e-03, 2.1543e-01, 3.6378e-02, 7.3537e-01,\n",
       "           9.8032e-03, 1.1776e-03, 2.0309e-06]], grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.1165, 0.0279, 0.1145, 0.1044, 0.1898, 0.1823, 0.1165, 0.1069, 0.0411]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1025, 0.0170, 0.0985, 0.1038, 0.2261, 0.2123, 0.1038, 0.1042, 0.0318]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0672, 0.0062, 0.0688, 0.1384, 0.1629, 0.3662, 0.1097, 0.0665, 0.0141]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1223, 0.0398, 0.1158, 0.1046, 0.1719, 0.1648, 0.1119, 0.1110, 0.0580]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0720, 0.0063, 0.0712, 0.1394, 0.1626, 0.3484, 0.1112, 0.0758, 0.0131]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0.]])),\n",
       " (tensor([[0.0550, 0.0016, 0.0497, 0.1734, 0.1453, 0.4565, 0.0694, 0.0455, 0.0036]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1102, 0.0470, 0.1072, 0.1123, 0.1582, 0.1661, 0.1210, 0.1175, 0.0604]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.1042, 0.0129, 0.1061, 0.1161, 0.1834, 0.2613, 0.0972, 0.0955, 0.0234]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0.]])),\n",
       " (tensor([[0.0495, 0.0010, 0.0336, 0.1784, 0.1146, 0.5267, 0.0573, 0.0349, 0.0041]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0.]])),\n",
       " (tensor([[0.0601, 0.0048, 0.0557, 0.1652, 0.1365, 0.4045, 0.0998, 0.0636, 0.0099]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " (tensor([[0.1153, 0.0128, 0.1055, 0.1125, 0.1849, 0.2492, 0.0963, 0.1032, 0.0203]],\n",
       "         grad_fn=<SoftmaxBackward0>),\n",
       "  tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.]])),\n",
       " ...]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcn = GCN()\n",
    "# gcn.load_state_dict(torch.load('gcn_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode of Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 321 verilog files \n",
    "* only 3 features             [type, operation_type, num_of_connections]\n",
    "* no edge attribute\n",
    "* 18 classes \n",
    "* 200 epochs \n",
    "* learning rate = 0.01\n",
    "* Dropoout = 0.4\n",
    "* Adam Optimizer\n",
    "* train 70, test 30 (on whole dataset, not each class)\n",
    "* time of training = seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train acc:  0.2902\n",
    "* Test Acc: 0.1959\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested Modifications for upcoming experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Clean dataset (by removing unnecessay, uninformative or wrong code files)\n",
    "2) remove reduntant parsing (different files but same parsing)\n",
    "3) include more informative features\n",
    "4) improve encoding format\n",
    "5) try using less classes (most important ones, so that less classes but more balanced dataset)\n",
    "6) adding more files\n",
    "7) adjusting hyperparameters such as learning rate, dropout, ...etc\n",
    "8) splitting train, val, test\n",
    "9) using equal percentages of each class (adjusting splitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode of Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested Modifications for upcoming experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr = 0.001\n",
    "\n",
    "droput 0.4\n",
    "\n",
    "314 files\n",
    "\n",
    "17 features (node_type)\n",
    "\n",
    "16 classes\n",
    "\n",
    "conv relu conv relu conv relu conv linear\n",
    "\n",
    "train = 40, test = 27\n",
    "\n",
    "200 epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experiment 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same as 5 but 100 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train = 43, test = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr = 0.001\n",
    "\n",
    "conv relu conv relu conv dropout linear\n",
    "\n",
    "9 classes\n",
    "\n",
    "164 file\n",
    "\n",
    "train = 34, test = 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr = 0.001\n",
    "\n",
    "9 classes\n",
    "\n",
    "conv relu conv relu conv dropout linear \n",
    "\n",
    "train = 64, test = 52\n",
    "\n",
    "164 \n",
    "\n",
    "17 features (node type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
