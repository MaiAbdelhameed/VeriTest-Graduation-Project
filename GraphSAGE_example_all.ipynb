{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in c:\\users\\mai\\appdata\\roaming\\python\\python39\\site-packages (2.5.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch_geometric) (4.64.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\mai\\appdata\\roaming\\python\\python39\\site-packages (from torch_geometric) (3.0.9)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch_geometric) (2.11.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\mai\\appdata\\roaming\\python\\python39\\site-packages (from torch_geometric) (5.9.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch_geometric) (2022.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch_geometric) (1.22.4)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch_geometric) (3.8.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch_geometric) (1.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch_geometric) (2.27.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\mai\\anaconda3\\lib\\site-packages (from torch_geometric) (1.7.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (21.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (2.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (4.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (5.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from async-timeout<5.0,>=4.0.0a3->aiohttp->torch_geometric) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp->torch_geometric) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from jinja2->torch_geometric) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (1.26.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from scikit-learn->torch_geometric) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\mai\\anaconda3\\lib\\site-packages (from scikit-learn->torch_geometric) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mai\\appdata\\roaming\\python\\python39\\site-packages (from tqdm->torch_geometric) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "%pip install torch_geometric\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import os\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import warnings\n",
    "import math\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n",
      "['done_all\\\\adder10_synth.txt', 'done_all\\\\adder11_synth.txt', 'done_all\\\\adder12_synth.txt', 'done_all\\\\adder13_synth.txt', 'done_all\\\\adder14_synth.txt', 'done_all\\\\adder15_synth.txt', 'done_all\\\\adder16_synth.txt', 'done_all\\\\adder17_synth.txt', 'done_all\\\\adder18_synth.txt', 'done_all\\\\adder19_synth.txt', 'done_all\\\\adder1_synth.txt', 'done_all\\\\adder20_synth.txt', 'done_all\\\\adder21_synth.txt', 'done_all\\\\adder22_synth.txt', 'done_all\\\\adder23_synth.txt', 'done_all\\\\adder24_synth.txt', 'done_all\\\\adder25_synth.txt', 'done_all\\\\adder26_synth.txt', 'done_all\\\\adder27_synth.txt', 'done_all\\\\adder28_synth.txt', 'done_all\\\\adder2_synth.txt', 'done_all\\\\adder3_synth.txt', 'done_all\\\\adder4_synth.txt', 'done_all\\\\adder5_synth.txt', 'done_all\\\\adder6_synth.txt', 'done_all\\\\adder7_synth.txt', 'done_all\\\\adder8_synth.txt', 'done_all\\\\adder9_synth.txt', 'done_all\\\\and10_gate_synth.txt', 'done_all\\\\and11_gate_synth.txt', 'done_all\\\\and12_gate_synth.txt', 'done_all\\\\and13_synth.txt', 'done_all\\\\and14_synth.txt', 'done_all\\\\and15_synth.txt', 'done_all\\\\and16_synth.txt', 'done_all\\\\and17_synth.txt', 'done_all\\\\and18_gate_synth.txt', 'done_all\\\\and19_synth.txt', 'done_all\\\\and1_synth.txt', 'done_all\\\\and20_synth.txt', 'done_all\\\\and21_synth.txt', 'done_all\\\\and22_synth.txt', 'done_all\\\\and23_synth.txt', 'done_all\\\\and24_synth.txt', 'done_all\\\\and25_synth.txt', 'done_all\\\\and26_synth.txt', 'done_all\\\\and27_synth.txt', 'done_all\\\\and28_synth.txt', 'done_all\\\\and29_synth.txt', 'done_all\\\\and2_gate_synth.txt', 'done_all\\\\and30_synth.txt', 'done_all\\\\and3_gate_synth.txt', 'done_all\\\\and4_gate_synth.txt', 'done_all\\\\and5_gate_synth.txt', 'done_all\\\\and6_gate_synth.txt', 'done_all\\\\and7_gate_synth.txt', 'done_all\\\\and8_gate_synth.txt', 'done_all\\\\and9_gate_synth.txt', 'done_all\\\\comparator10_synth.txt', 'done_all\\\\comparator11_synth.txt', 'done_all\\\\comparator12_synth.txt', 'done_all\\\\comparator13_synth.txt', 'done_all\\\\comparator14_synth.txt', 'done_all\\\\comparator15_synth.txt', 'done_all\\\\comparator16_synth.txt', 'done_all\\\\comparator17_synth.txt', 'done_all\\\\comparator18_synth.txt', 'done_all\\\\comparator19_synth.txt', 'done_all\\\\comparator1_synth.txt', 'done_all\\\\comparator20_synth.txt', 'done_all\\\\comparator21_synth.txt', 'done_all\\\\comparator22_synth.txt', 'done_all\\\\comparator2_synth.txt', 'done_all\\\\comparator3_synth.txt', 'done_all\\\\comparator4_synth.txt', 'done_all\\\\comparator5_synth.txt', 'done_all\\\\comparator6_synth.txt', 'done_all\\\\comparator7_synth.txt', 'done_all\\\\comparator8_synth.txt', 'done_all\\\\comparator9_synth.txt', 'done_all\\\\decoder10_synth.txt', 'done_all\\\\decoder11_synth.txt', 'done_all\\\\decoder12_synth.txt', 'done_all\\\\decoder13_synth.txt', 'done_all\\\\decoder14_synth.txt', 'done_all\\\\decoder15_synth.txt', 'done_all\\\\decoder16_synth.txt', 'done_all\\\\decoder17_synth.txt', 'done_all\\\\decoder18_synth.txt', 'done_all\\\\decoder19_synth.txt', 'done_all\\\\decoder1_synth.txt', 'done_all\\\\decoder20_synth.txt', 'done_all\\\\decoder21_synth.txt', 'done_all\\\\decoder22_synth.txt', 'done_all\\\\decoder23_synth.txt', 'done_all\\\\decoder24_synth.txt', 'done_all\\\\decoder25_synth.txt', 'done_all\\\\decoder26_synth.txt', 'done_all\\\\decoder27_synth.txt', 'done_all\\\\decoder28_synth.txt', 'done_all\\\\decoder29_synth.txt', 'done_all\\\\decoder2_synth.txt', 'done_all\\\\decoder30_synth.txt', 'done_all\\\\decoder31_synth.txt', 'done_all\\\\decoder32_synth.txt', 'done_all\\\\decoder3_synth.txt', 'done_all\\\\decoder4_synth.txt', 'done_all\\\\decoder5_synth.txt', 'done_all\\\\decoder6_synth.txt', 'done_all\\\\decoder7_synth.txt', 'done_all\\\\decoder8_synth.txt', 'done_all\\\\decoder9_synth.txt', 'done_all\\\\encoder10_synth.txt', 'done_all\\\\encoder11_synth.txt', 'done_all\\\\encoder12_synth.txt', 'done_all\\\\encoder13_synth.txt', 'done_all\\\\encoder14_synth.txt', 'done_all\\\\encoder15_synth.txt', 'done_all\\\\encoder16_synth.txt', 'done_all\\\\encoder17_synth.txt', 'done_all\\\\encoder18_synth.txt', 'done_all\\\\encoder19_synth.txt', 'done_all\\\\encoder1_synth.txt', 'done_all\\\\encoder20_synth.txt', 'done_all\\\\encoder21_synth.txt', 'done_all\\\\encoder22_synth.txt', 'done_all\\\\encoder23_synth.txt', 'done_all\\\\encoder24_synth.txt', 'done_all\\\\encoder25_synth.txt', 'done_all\\\\encoder2_synth.txt', 'done_all\\\\encoder3_synth.txt', 'done_all\\\\encoder4_synth.txt', 'done_all\\\\encoder5_synth.txt', 'done_all\\\\encoder6_synth.txt', 'done_all\\\\encoder7_synth.txt', 'done_all\\\\encoder8_synth.txt', 'done_all\\\\encoder9_synth.txt', 'done_all\\\\mult10_synth.txt', 'done_all\\\\mult11_synth.txt', 'done_all\\\\mult12_synth.txt', 'done_all\\\\mult13_synth.txt', 'done_all\\\\mult14_synth.txt', 'done_all\\\\mult15_synth.txt', 'done_all\\\\mult16_synth.txt', 'done_all\\\\mult17_synth.txt', 'done_all\\\\mult18_synth.txt', 'done_all\\\\mult19_synth.txt', 'done_all\\\\mult1_synth.txt', 'done_all\\\\mult20_synth.txt', 'done_all\\\\mult21_synth.txt', 'done_all\\\\mult22_synth.txt', 'done_all\\\\mult23_synth.txt', 'done_all\\\\mult25_synth.txt', 'done_all\\\\mult26_synth.txt', 'done_all\\\\mult27_synth.txt', 'done_all\\\\mult28_synth.txt', 'done_all\\\\mult29_synth.txt', 'done_all\\\\mult2_synth.txt', 'done_all\\\\mult30_synth.txt', 'done_all\\\\mult3_synth.txt', 'done_all\\\\mult4_synth.txt', 'done_all\\\\mult5_synth.txt', 'done_all\\\\mult6_synth.txt', 'done_all\\\\mult7_synth.txt', 'done_all\\\\mult8_synth.txt', 'done_all\\\\mult9_synth.txt', 'done_all\\\\mux10_synth.txt', 'done_all\\\\mux11_synth.txt', 'done_all\\\\mux12_synth.txt', 'done_all\\\\mux13_synth.txt', 'done_all\\\\mux15_synth.txt', 'done_all\\\\mux16_synth.txt', 'done_all\\\\mux17_synth.txt', 'done_all\\\\mux18_synth.txt', 'done_all\\\\mux19_synth.txt', 'done_all\\\\mux1_synth.txt', 'done_all\\\\mux20_synth.txt', 'done_all\\\\mux21_synth.txt', 'done_all\\\\mux22_synth.txt', 'done_all\\\\mux23_synth.txt', 'done_all\\\\mux24_synth.txt', 'done_all\\\\mux25_synth.txt', 'done_all\\\\mux26_synth.txt', 'done_all\\\\mux27_synth.txt', 'done_all\\\\mux28_synth.txt', 'done_all\\\\mux2_synth.txt', 'done_all\\\\mux3_synth.txt', 'done_all\\\\mux4_synth.txt', 'done_all\\\\mux5_synth.txt', 'done_all\\\\mux6_synth.txt', 'done_all\\\\mux7_synth.txt', 'done_all\\\\mux8_synth.txt', 'done_all\\\\mux9_synth.txt', 'done_all\\\\nand10_synth.txt', 'done_all\\\\nand11_synth.txt', 'done_all\\\\nand12_gate_synth.txt', 'done_all\\\\nand13_synth.txt', 'done_all\\\\nand14_synth.txt', 'done_all\\\\nand15_synth.txt', 'done_all\\\\nand16_synth.txt', 'done_all\\\\nand17_synth.txt', 'done_all\\\\nand18_synth.txt', 'done_all\\\\nand19_synth.txt', 'done_all\\\\nand1_synth.txt', 'done_all\\\\nand20_gate_synth.txt', 'done_all\\\\nand21_synth.txt', 'done_all\\\\nand22_synth.txt', 'done_all\\\\nand23_synth.txt', 'done_all\\\\nand24_synth.txt', 'done_all\\\\nand25_synth.txt', 'done_all\\\\nand26_synth.txt', 'done_all\\\\nand27_synth.txt', 'done_all\\\\nand28_synth.txt', 'done_all\\\\nand29_synth.txt', 'done_all\\\\nand2_gate_synth.txt', 'done_all\\\\nand30_synth.txt', 'done_all\\\\nand31_synth.txt', 'done_all\\\\nand3_gate_synth.txt', 'done_all\\\\nand4_gate_synth.txt', 'done_all\\\\nand5_gate_synth.txt', 'done_all\\\\nand6_gate_synth.txt', 'done_all\\\\nand7_gate_synth.txt', 'done_all\\\\nand8_gate_synth.txt', 'done_all\\\\nand9_gate_synth.txt', 'done_all\\\\nor10_synth.txt', 'done_all\\\\nor11_synth.txt', 'done_all\\\\nor12_gate_synth.txt', 'done_all\\\\nor13_synth.txt', 'done_all\\\\nor14_synth.txt', 'done_all\\\\nor15_synth.txt', 'done_all\\\\nor16_synth.txt', 'done_all\\\\nor17_synth.txt', 'done_all\\\\nor18_synth.txt', 'done_all\\\\nor19_synth.txt', 'done_all\\\\nor1_synth.txt', 'done_all\\\\nor20_synth.txt', 'done_all\\\\nor21_synth.txt', 'done_all\\\\nor22_synth.txt', 'done_all\\\\nor23_synth.txt', 'done_all\\\\nor24_synth.txt', 'done_all\\\\nor25_synth.txt', 'done_all\\\\nor26_synth.txt', 'done_all\\\\nor27_gate_synth.txt', 'done_all\\\\nor28_synth.txt', 'done_all\\\\nor29_synth.txt', 'done_all\\\\nor2_gate_synth.txt', 'done_all\\\\nor30_synth.txt', 'done_all\\\\nor3_gate_synth.txt', 'done_all\\\\nor4_gate_synth.txt', 'done_all\\\\nor5_gate_synth.txt', 'done_all\\\\nor6_gate_synth.txt', 'done_all\\\\nor7_synth.txt', 'done_all\\\\nor8_gate_synth.txt', 'done_all\\\\nor9_synth.txt', 'done_all\\\\not10_synth.txt', 'done_all\\\\not11_synth.txt', 'done_all\\\\not12_synth.txt', 'done_all\\\\not13_synth.txt', 'done_all\\\\not14_synth.txt', 'done_all\\\\not15_synth.txt', 'done_all\\\\not16_synth.txt', 'done_all\\\\not1_synth.txt', 'done_all\\\\not2_synth.txt', 'done_all\\\\not3_synth.txt', 'done_all\\\\not4_synth.txt', 'done_all\\\\not5_synth.txt', 'done_all\\\\not6_synth.txt', 'done_all\\\\not7_synth.txt', 'done_all\\\\not8_synth.txt', 'done_all\\\\not9_synth.txt', 'done_all\\\\or11_synth.txt', 'done_all\\\\or13_synth.txt', 'done_all\\\\or14_synth.txt', 'done_all\\\\or15_synth.txt', 'done_all\\\\or16_synth.txt', 'done_all\\\\or17_gate_synth.txt', 'done_all\\\\or18_synth.txt', 'done_all\\\\or19_synth.txt', 'done_all\\\\or1_synth.txt', 'done_all\\\\or20_synth.txt', 'done_all\\\\or21_synth.txt', 'done_all\\\\or22_synth.txt', 'done_all\\\\or23_synth.txt', 'done_all\\\\or24_synth.txt', 'done_all\\\\or25_synth.txt', 'done_all\\\\or26_synth.txt', 'done_all\\\\or27_synth.txt', 'done_all\\\\or28_synth.txt', 'done_all\\\\or29_synth.txt', 'done_all\\\\or2_gate_synth.txt', 'done_all\\\\or3_gate_synth.txt', 'done_all\\\\or4_gate_synth.txt', 'done_all\\\\or5_gate_synth.txt', 'done_all\\\\or6_gate_synth.txt', 'done_all\\\\or7_synth.txt', 'done_all\\\\or8_gate_synth.txt', 'done_all\\\\or9_synth.txt', 'done_all\\\\pe10_synth.txt', 'done_all\\\\pe11_synth.txt', 'done_all\\\\pe12_synth.txt', 'done_all\\\\pe13_synth.txt', 'done_all\\\\pe14_synth.txt', 'done_all\\\\pe15_synth.txt', 'done_all\\\\pe16_synth.txt', 'done_all\\\\pe17_synth.txt', 'done_all\\\\pe18_synth.txt', 'done_all\\\\pe19_synth.txt', 'done_all\\\\pe1_synth.txt', 'done_all\\\\pe20_synth.txt', 'done_all\\\\pe21_synth.txt', 'done_all\\\\pe22_synth.txt', 'done_all\\\\pe2_synth.txt', 'done_all\\\\pe3_synth.txt', 'done_all\\\\pe4_synth.txt', 'done_all\\\\pe5_synth.txt', 'done_all\\\\pe6_synth.txt', 'done_all\\\\pe8_synth.txt', 'done_all\\\\pe9_synth.txt', 'done_all\\\\seg1_synth.txt', 'done_all\\\\seg2_synth.txt', 'done_all\\\\seg3_synth.txt', 'done_all\\\\seg4_synth.txt', 'done_all\\\\seg5_synth.txt', 'done_all\\\\seg6_synth.txt', 'done_all\\\\seg7_synth.txt', 'done_all\\\\seg8_synth.txt', 'done_all\\\\seg9_synth.txt', 'done_all\\\\sub10_synth.txt', 'done_all\\\\sub11_synth.txt', 'done_all\\\\sub12_synth.txt', 'done_all\\\\sub1_synth.txt', 'done_all\\\\sub2_synth.txt', 'done_all\\\\sub4_synth.txt', 'done_all\\\\sub5_synth.txt', 'done_all\\\\sub6_synth.txt', 'done_all\\\\sub7_synth.txt', 'done_all\\\\sub8_synth.txt', 'done_all\\\\sub9_synth.txt', 'done_all\\\\xnor10_synth.txt', 'done_all\\\\xnor11_synth.txt', 'done_all\\\\xnor12_synth.txt', 'done_all\\\\xnor13_synth.txt', 'done_all\\\\xnor14_synth.txt', 'done_all\\\\xnor15_synth.txt', 'done_all\\\\xnor16_synth.txt', 'done_all\\\\xnor17_synth.txt', 'done_all\\\\xnor18_synth.txt', 'done_all\\\\xnor19_synth.txt', 'done_all\\\\xnor1_synth.txt', 'done_all\\\\xnor20_synth.txt', 'done_all\\\\xnor21_synth.txt', 'done_all\\\\xnor22_synth.txt', 'done_all\\\\xnor23_synth.txt', 'done_all\\\\xnor24_synth.txt', 'done_all\\\\xnor25_synth.txt', 'done_all\\\\xnor26_synth.txt', 'done_all\\\\xnor27_synth.txt', 'done_all\\\\xnor28_synth.txt', 'done_all\\\\xnor29_synth.txt', 'done_all\\\\xnor2_synth.txt', 'done_all\\\\xnor30_synth.txt', 'done_all\\\\xnor3_synth.txt', 'done_all\\\\xnor4_synth.txt', 'done_all\\\\xnor5_synth.txt', 'done_all\\\\xnor6_synth.txt', 'done_all\\\\xnor7_synth.txt', 'done_all\\\\xnor8_synth.txt', 'done_all\\\\xnor9_synth.txt', 'done_all\\\\xor10_synth.txt', 'done_all\\\\xor11_synth.txt', 'done_all\\\\xor12_synth.txt', 'done_all\\\\xor13_synth.txt', 'done_all\\\\xor14_synth.txt', 'done_all\\\\xor15_synth.txt', 'done_all\\\\xor16_synth.txt', 'done_all\\\\xor17_synth.txt', 'done_all\\\\xor18_synth.txt', 'done_all\\\\xor19_synth.txt', 'done_all\\\\xor1_synth.txt', 'done_all\\\\xor20_synth.txt', 'done_all\\\\xor21_synth.txt', 'done_all\\\\xor22_synth.txt', 'done_all\\\\xor23_synth.txt', 'done_all\\\\xor24_synth.txt', 'done_all\\\\xor25_synth.txt', 'done_all\\\\xor26_synth.txt', 'done_all\\\\xor27_synth.txt', 'done_all\\\\xor28_synth.txt', 'done_all\\\\xor29_synth.txt', 'done_all\\\\xor2_synth.txt', 'done_all\\\\xor3_synth.txt', 'done_all\\\\xor4_synth.txt', 'done_all\\\\xor5_synth.txt', 'done_all\\\\xor6_synth.txt', 'done_all\\\\xor7_synth.txt', 'done_all\\\\xor8_synth.txt']\n"
     ]
    }
   ],
   "source": [
    "def get_files_in_folder(input_folder):\n",
    "    file_list = []\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            file_list.append(file_path)\n",
    "    return file_list\n",
    "\n",
    "# Example usage:\n",
    "folder_path = 'done_all'\n",
    "verilog_files = get_files_in_folder(folder_path)\n",
    "print(len(verilog_files))\n",
    "print(verilog_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracting_attributes(verilog_file):\n",
    "    try:\n",
    "        if os.path.isfile(verilog_file):\n",
    "            with open(verilog_file, \"r\") as file:\n",
    "                loaded_data = json.load(file)\n",
    "                nodes = loaded_data[0]\n",
    "                edges = loaded_data[1]\n",
    "                label = loaded_data[2]\n",
    "                \n",
    "                x = torch.tensor(nodes, dtype=torch.float)\n",
    "                edge_index = torch.tensor(edges, dtype=torch.long)\n",
    "                y = torch.tensor(label, dtype=torch.float)\n",
    "                num_nodes = x.size(0)\n",
    "                \n",
    "                # Create batch assignment vector (assuming one graph per file)\n",
    "                batch = torch.zeros(num_nodes, dtype=torch.long)\n",
    "                data = Data(x=x, edge_index=edge_index, y = y, batch = batch)\n",
    "                return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 396 Verilog files.\n",
      "396\n"
     ]
    }
   ],
   "source": [
    "class VerilogDataset(Dataset):  # Using Dataset from torch_geometric\n",
    "    def __init__(self, verilog_files):\n",
    "        print(f\"Loaded {len(verilog_files)} Verilog files.\")\n",
    "        self.verilog_files = verilog_files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.verilog_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        verilog_file = self.verilog_files[idx]\n",
    "        data = extracting_attributes(verilog_file)\n",
    "        return data\n",
    "\n",
    "dataset = VerilogDataset(verilog_files)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[54, 7], edge_index=[2, 72], y=[1, 16], batch=[54])\n",
      "done_all\\adder10_synth.txt\n",
      "done_all\\adder10_synth.txt\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])\n",
    "print(verilog_files[0])\n",
    "print(dataset.verilog_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data objects are unique.\n"
     ]
    }
   ],
   "source": [
    "def are_all_data_objects_unique(dataset):\n",
    "    data_objects = []\n",
    "    for data in dataset:\n",
    "        if data in data_objects:\n",
    "            return False\n",
    "        data_objects.append(data)\n",
    "    return True\n",
    "\n",
    "# Example usage:\n",
    "is_unique = are_all_data_objects_unique(dataset)\n",
    "if is_unique:\n",
    "    print(\"All data objects are unique.\")\n",
    "else:\n",
    "    print(\"Duplicate data objects found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = []\n",
    "for data in dataset:\n",
    "    # print(data)\n",
    "    # print(data.y.tolist())\n",
    "    y_labels.append(np.argmax(data.y.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    if isinstance(batch[0], Data):\n",
    "        return batch\n",
    "    else:\n",
    "        return default_collate(batch)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, y_labels, test_size=0.2, stratify = y_labels, random_state=41)\n",
    "train_loader = DataLoader(X_train, batch_size=16, shuffle=True, collate_fn=custom_collate)\n",
    "test_loader = DataLoader(X_test, batch_size=16, shuffle = False, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[82, 7], edge_index=[2, 109], y=[1, 16], batch=[82])\n"
     ]
    }
   ],
   "source": [
    "# len(train_loader.dataset)\n",
    "print(train_loader.dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_iter = iter(train_loader)\n",
    "batch = next(loader_iter)\n",
    "# print(batch)\n",
    "# print(batch.num_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import global_mean_pool\n",
    "class GraphSAGE1(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphSAGE1, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        emb = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(emb, batch=None)\n",
    "        return x, emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.6831860542297363\n",
      "Epoch 10, Loss: 0.1753063201904297\n",
      "Epoch 20, Loss: 0.032157398760318756\n",
      "Epoch 30, Loss: 0.013998419046401978\n",
      "Epoch 40, Loss: 0.007112658582627773\n",
      "Epoch 50, Loss: 0.004827866796404123\n",
      "Epoch 60, Loss: 0.0024541281163692474\n",
      "Epoch 70, Loss: 0.0015282867243513465\n",
      "Epoch 80, Loss: 0.0013799677835777402\n",
      "Epoch 90, Loss: 0.000982397934421897\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "in_channels = 7\n",
    "hidden_channels = 16\n",
    "out_channels = 16\n",
    "model1 = GraphSAGE1(in_channels, hidden_channels, out_channels)\n",
    "\n",
    "# Create a simple training loop\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Training the model\n",
    "model1.train()\n",
    "for epoch in range(100):\n",
    "    for data in X_train:\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        #forward pass\n",
    "        out, emb = model1(data.x, data.edge_index)\n",
    "        # print(out.shape)\n",
    "        # print(data.y.shape)\n",
    "        target = torch.argmax(data.y, dim=1)\n",
    "        # calculate the loss\n",
    "        loss = loss_fn(out, target)\n",
    "        # zero the gradients of the weights so that the gradients are not accumulated\n",
    "        # calculate the gradients using backpropagation\n",
    "        loss.backward()\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9272151898734177"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.eval()\n",
    "correct = 0\n",
    "for data in X_train:\n",
    "    out, emb = model1(data.x, data.edge_index)  \n",
    "    pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    y_label = (data.y.tolist())\n",
    "    y_label = y_label[0].index(1.0)\n",
    "    pred_label = (pred.tolist())[0]\n",
    "    # print(pred_label)\n",
    "    # print(y_label)\n",
    "    if y_label == pred_label:\n",
    "        correct += 1            \n",
    "    # correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "acc = correct / len(X_train)  # Derive ratio of correct predictions.\n",
    "\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8625"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.eval()\n",
    "correct = 0\n",
    "for data in X_test:\n",
    "    out, emb = model1(data.x, data.edge_index)  \n",
    "    pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    y_label = (data.y.tolist())\n",
    "    y_label = y_label[0].index(1.0)\n",
    "    pred_label = (pred.tolist())[0]\n",
    "    # print(pred_label)\n",
    "    # print(y_label)\n",
    "    if y_label == pred_label:\n",
    "        correct += 1            \n",
    "    # correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "test_acc = correct / len(X_test)  # Derive ratio of correct predictions.\n",
    "\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model1.state_dict(), 'grahpSAGE_92_86_graph_embeddings.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(z_i, z_j, temperature=0.5):\n",
    "    z_i = F.normalize(z_i, p=2, dim=1)\n",
    "    z_j = F.normalize(z_j, p=2, dim=1)\n",
    "    \n",
    "    # print(z_i)\n",
    "    # print(z_j)\n",
    "    sim_matrix = torch.mm(z_i, z_j.t()) / temperature\n",
    "    # print(sim_matrix)\n",
    "    sim_exp = torch.exp(sim_matrix)\n",
    "    # print(sim_exp)\n",
    "    sim_sum = sim_exp.sum(dim=1)\n",
    "    # print(sim_sum)\n",
    "    \n",
    "    loss = -torch.log(sim_exp.diagonal())\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def augment_graph(graph):\n",
    "    # Example augmentation: randomly drop edges\n",
    "    edge_index = graph.edge_index.numpy()\n",
    "    num_edges = edge_index.shape[1]\n",
    "    keep_edges = random.sample(range(num_edges), k=int(0.9 * num_edges))\n",
    "    edge_index = torch.tensor(edge_index[:, keep_edges], dtype=torch.long)\n",
    "    return Data(x=graph.x, edge_index=edge_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
